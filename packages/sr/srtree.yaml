all-versions:
- 0.1.1.0
- 0.1.2.0
- 0.1.2.1
- 1.0.0.0
- 1.0.0.1
- 1.0.0.2
- 1.0.0.3
- 1.0.0.4
- 1.0.0.5
- 2.0.0.0
- 2.0.0.1
author: Fabricio Olivetti de FranÃ§a
basic-deps:
  attoparsec: '>=0.14.4 && <0.15'
  attoparsec-expr: '>=0.1.1.2 && <0.2'
  base: '>=4.16 && <5'
  bytestring: '>=0.11 && <0.13'
  containers: '>=0.6.7 && <0.8'
  dlist: '>=1.0 && <1.1'
  exceptions: '>=0.10.7 && <0.11'
  filepath: '>=1.4.0.0 && <1.6'
  hashable: '>=1.4.4.0 && <1.6'
  ieee754: '>=0.8.0 && <0.9'
  lens: '>=5.2.3 && <5.4'
  list-shuffle: '>=1.0.0.1 && <1.1'
  massiv: '>=1.0.4.0 && <1.1'
  mtl: '>=2.2 && <2.4'
  normaldistribution: '>=1.1.0.3 && <1.2'
  optparse-applicative: '>=0.17 && <0.19'
  random: '>=1.2 && <1.3'
  split: '>=0.2.5 && <0.3'
  srtree: '>=0'
  statistics: '>=0.16.2.1 && <0.17'
  transformers: '>=0.6.1.0 && <0.7'
  unordered-containers: '>=0.2 && <0.3'
  vector: '>=0.12 && <0.14'
  zlib: '>=0.6.3 && <0.8'
changelog: "# Changelog for srtree\n\n## 2.0.0.0 \n\n- Complete refactoring of the
  library\n- Integration of other tools such as: srtree-opt, srtree-tools, srsimplify\n-
  Implementation of Equality Saturation and support to e-graph \n- Using Massiv for
  performance \n- Using NLOpt as the optimization library \n\n## 1.1.0.0\n\n- Reorganization
  of modules\n- Renaming AD functions\n- Inclusion of reverse mode that calculates
  the diagonal of and the full Hessian matrices\n\n## 1.0.0.5\n\n- Changed `base`
  and `mtl` versions\n\n## 1.0.0.4\n\n- Removed benchmarking code that demanded more
  dependencies\n\n## 1.0.0.3\n\n- Fixed issue with HUnit test\n\n## 1.0.0.2\n\n- Export
  `Fix` from `Data.SRTRee`\n- `paramsToConst` function\n\n## 1.0.0.1\n\n- Fix `vector`
  version bounds\n- Included benchmarking of `ad` package\n\n## 1.0.0.0\n\n- Complete
  refactoring of source\n- We now work with the SRTree data type fixed point\n- Symbolic
  derivative by Param or Var\n- Forward mode autodiff\n- Optimized gradient calculation
  of parameters if each parameter occurs only once in the expression\n\n## 0.1.3.0\n\n-
  `countParams` function\n\n## 0.1.2.1\n\n- Better bounds for base (compatible with
  stackage nightly)\n\n## 0.1.2.0\n\n- Implemented `deriveParamBy` to calculate the
  derivative by the parameters indexed by `ix`\n\n## 0.1.1.0\n\n- Fixed compilation
  bug\n\n## 0.1.0.0\n\n- Initial version\n"
changelog-type: markdown
description: "# srtree: A supporting library for tree-based symbolic regression \n\n`srtree`
  is a Haskell library that implements a tree-based structure for expressions and
  supporting functions to be used in the context of **symbolic regression**.\n\nThe
  expression structure is defined as a fixed-point of a mix of unary and binary tree.
  This makes it easier to implement supporting functions that requires the traversal
  of the trees. Also, since it is a parameterized structure, we can creating partial
  trees to pattern math structures of interest.\nThis structure may contain four types
  of nodes:\n\n- `Bin Op l r` that represents a binary operator `Op` with two children.\n-
  `Uni Function t` that represents an unary function `Function` with a single child.\n-
  `Var Int` representing the index of a variable (i.e., x0, x1, etc.).\n- `Param Int`
  representing the index of a adjustable parameter (i.e., theta0, theta1, etc.).\n-
  `Const Double`  representing a constant value.\n\n\nThe `SRTree` structure has instances
  for `Num, Fractional, Floating, IsString` which allows to create an expression as
  a valid Haskell expression such as (remember to turn on OverloadedStrings extension):\n\n```haskell\nexpr
  = \"x0\" * 2 + sin(\"x1\" * pi + \"x0\") :: Fix SRTree\n```\n\nThis library comes
  with support to many quality of life functions to handle this data structure. Such
  as:\n\n- getting the arity of a node\n- getting the children of a node as a list\n-
  count the number of nodes \n- number of nodes of a specific type\n- counting unique
  tokens \n- number of variables and parameters \n- relabeling the parameters from
  0 to p \n- converting floating point constants to parameters \n\nAdditionally, the
  library provides supporting function to work with datasets, evaluating the expressions,
  \ncalculating the derivatives, printing, generating random trees, simplifying the
  expression, calculating overall statistics,\noptimizing parameters, and model selection
  metrics. \n\nTogether with this library, we provide example applications (please
  refer to their corresponding README files):\n\n- [srsimplify](apps/srsimplify/README.md):
  a parser and simplification tool supporting the output of many popular SR algorithms.\n-
  [srtools](apps/srtools/README.md): a tool that can be used to evaluate symbolic
  regression expressions and create nice reports with confidence intervals. \n- [tinygp](apps/tinygp/README.md):
  a simple GP implementation based on tinyGP.\n\n## Organization\n\nThe library is
  organized as `Data`, `Algorithm`, and `Text` modules where the `Data` modules implement
  functions directly tied to the data structure and the `Algorithm` modules implement
  algorithms related to symbolic regression, finally, the `Text` modules parse string
  expressions from different formats and apply simplification, when requested.\n\n###
  `Data` modules\n\nThe `Data` modules is split into $5$ submodules:\n\n- `Data.SRTree`
  contains the data strucuture and basic supporting functions.\n- `Data.SRTree.Datasets`
  contains functions supporting loading datasets into Massiv.Arrays (aka numpy arrays).\n-
  `Data.SRTree.Derivative` contains the symbolic derivatives of the functions and
  operators.\n- `Data.SRTree.Eval` contains functions to evaluate the tree given a
  dataset and parameters.\n- `Data.SRTree.Print` contains supporting functions for
  converting trees to different string representation.\n- `Data.SRTree.Random`  contains
  functions to generate random trees.\n\n#### `Data.SRTree`\n\nThe `SRTree val` data
  structure is a sum type structure that can be either a variable index, a parameter
  index, a constant value (of type `Double`), an univariate function or a binary operator.
  The data type is implemented as a fixed point so all the algorithms act on `Fix
  SRTree`:\n\n```haskell \nt = \"x0\" + \"t0\" * sin(\"x1\" + \"t1\"**2) :: Fix SRTree
  \n```\n\nWhen creating the expression in a more natural notation, the variables
  and parameters are `String` composed of the first letter either `x`, for variables,
  or `t` for parameters (as in theta), and an integer corresponding to the index of
  the variable or parameter. The fixed point notation, allows us to implment recursive
  processing of a tree without many of the common boilerplate:\n\n```haskell\ncountNodes
  = \n  \\case \n    Var _     = 1\n    Const _   = 1\n    Param _   = 1\n    Uni
  _ t   = 1 + t \n    Bin _ l r = 1 + l + r\n```\n\nThe children are parameterized
  by the `val` type parameter. This allows us to create convenient partial structures,
  such as:\n\n```haskell\n-- + operator pointing to some structure\n-- with index
  1 and 2\nBin Add 1 2 \n\n-- canonical representation of + operator \nBin Add ()
  ()\n```\n\nThe main functions of this module are:\n\n- `arity`: returns the arity
  of an operator.\n- `getChildren`: returns the children of a `Fix SRTree` as a list
  \n- `countNodes`: returns the number of nodes \n- `countOccurrences`: counts the
  occurence of a given variable \n- `countVars`: returns the number of unique variables
  appearing the expression \n- `relabelParams`: relabels the parameters from the left
  leaves to the right \n- `constsToParams`: replace `Const` nodes with `Param` nodes.\n\n####
  `Data.SRTree.Datasets` module \n\nThis module exports only the `loadDataset` function
  which takes a filename and \nreturns the training and test sets together with the
  column labels.\nThe filename must follow the format:\n\n`filename.ext:start_row:end_row:target:features`\n\nwhere
  each ':' field is optional. The fields are:\n\n- **start_row:end_row** is the range
  of the training rows (default 0:nrows-1).\n   every other row not included in this
  range will be used as validation\n- **target** is either the name of the PVector
  (if the datafile has headers) or the index\n   of the target variable\n- **features**
  is a comma separated list of SRMatrix names or indices to be used as\n  input variables
  of the regression model.\n\nExample of valid names: `dataset.csv`, `mydata.tsv`,
  `dataset.csv:20:100`, `dataset.tsv:20:100:price:m2,rooms,neighborhood`, `dataset.csv:::5:0,1,2`.\n\n####
  `Data.SRTree.Derivative` module \n\nCalculates symbolic derivatives of the expression
  w.r.t. the variables or the parameters.\nThe main functions of this module are:\n\n-
  `deriveBy`: returns the symbolic derivative w.r.t. a certain variable or a certain
  parameter.\n- `deriveByVar`: shortcut to `deriveBy` to derive by a variable.\n-
  `deriveByParam`: shortcut to `deriveBy` to derive by a parameter.\n\n#### `Data.SRTree.Eval`
  module \n\nEvaluates an expression given a dataset.\nThe main functions of this
  module are:\n\n- `evalTree`: given a data matrix and a vector of parameters, evaluates
  the expression tree.\n- `evalInverse`: evaluates the inverse of a function. \n-
  `invright`: evaluates the right inverse of an operator.\n- `invleft`: evaluates
  the left inverse of an operator.\n\n#### `Data.SRTree.Print` module \n\nSupport
  functions to convert an expression tree into a `String`.\nThe main functions of
  this module are: \n\n- `showExpr` and `printExpr`: converts/print the expression
  into math notation .\n- `showPython` and `printPython`: converts/print to a numpy
  notation.\n- `showLatex` and `printLatex`: converts/print to a LaTeX notation.\n-
  `showTikz` and `printTikz`: converts/print to a TikZ notation.\n\n#### `Data.SRTree.Random`
  module \n\nAuxiliary functions to create random trees. \nThe main functions of this
  module are:\n\n- `randomTree`: creates a random tree with a certain number of nodes.\n-
  `randomTreeBalanced`: creates a (almost) balanced random tree with a certain number
  of nodes.\n\n### `Text` modules \n\nThe `Text` module is split into $2$ modules:\n\n-
  `Text.ParseSR`: contains the main parsers for different SR algorithms output.\n-
  `Text.ParseSR.IO`: auxiliary functions to handle files containing many expressions.\n\n####
  `Text.ParseSR` module \n\nThe only important function of this module is `parseSR`
  that  parses an string expression from a given algorithm to a certain output. It
  also converts variable names to x0, x1,...\n\n#### `Text.ParseSR.IO` module \n\nThe
  two main functions of this module are: \n\n- `withInput`: that reads the stdin or
  a text file and parse all expressions \n- `withOutput`: that writes the parsed expression
  into stdout or a file with one of the choices of output format. \n\nThese functions
  handle any errors with an `Either` type and they can be safely pipelined together.
  Any invalid expression will be printed as \"invalid expression <error message>\".\n\n###
  `Algorithm` modules \n\nThe `Algorithm` modules are split into $5$ submodules:\n\n-
  `Algorithm.SRTree.AD` contains automatic differentiation functions.\n- `Algorithm.SRTree.ConfidenceIntervals`
  contains functions to calculate the confidence intervals of parameters and predictions
  of a symbolic expression using Laplace approximation or profile likelihood.\n- `Algorithm.SRTree.Likelihood`
  contains functions support different likelihood functions and their derivatives
  (gradient and hessian).\n- `Algorithm.SRTree.ModelSelection` implements different
  model selection criteria such as AIC, BIC, MDL.\n- `Algorithm.SRTree.Opt` implements
  functions to optimize the parameters of an expression supporting different likelihood
  functions.\n\n#### `Algorithm.SRTree.AD` module \n\nThe main functions of this module
  are:\n\n- `forwardMode`: returns the prediction errors vector multiplied by the
  Jacobian matrix using forward mode AD.\n- `forwardModeUnique`: same as above, but
  assuming each parameter index appear only once in the tree. \n- `reverseModeUnique`:
  same as above, but using reverse mode \n- `forwardModeUniqueJac`: same as `forwardModeUnique`
  but returns the Jacobian (does not mutiply by the error).\n\n#### `Algorithm.SRTree.Likelihood`
  module \n\nThe main functions of this module are: \n\n- `sse, mse, rmse`: calculates
  the sum-of-square, mean squared, root of mean squared errors.\n- `nll`: returns
  the negative log-likelihood given a distribution and the associated error (`Nothing`
  if unknown)\n- `gradNLL`: returns the gradient of the negative log-likelihood. \n-
  `gradNLLNonUnique`: same as above but assumes non-unique parameters \n- `hessianNLL`:
  returns the hessian of the neg log-likelihood.\n\n#### `Algorithm.SRTree.Opt` module
  \n\nThe main functions of this module are:\n\n- `minimizeNLL`: minimizes the negative
  log-likelihood of a distribution.\n- `minimizeNLLNonUnique`: same as above but assumes
  repeated occurrences of parameters.\n- `minimizeNLLWithFixedParam`: minimizes the
  neg log-likelihood but fixing the value of a single parameter.\n- `minimizeGaussian`,
  `minimizePoisson`, `minimizeBinomial`: shortcut to minimize these three distributions.\n\n####
  `Algorithm.SRTree.ModelSelection` module \n\nThe main functions of this module are:\n\n-
  `bic`: Bayesian Information Criteria \n- `aic`: Akaike Information Criteria \n-
  `mdl`: Minimum Description Length as described in Bartlett, Deaglan J., Harry Desmond,
  and Pedro G. Ferreira. \"Exhaustive symbolic regression.\" IEEE Transactions on
  Evolutionary Computation (2023)\n- `mdlLattice`: as described in Bartlett, Deaglan,
  Harry Desmond, and Pedro Ferreira. \"Priors for symbolic regression.\" Proceedings
  of the Companion Conference on Genetic and Evolutionary Computation. 2023.\n- `mdlFreq`
  : MDL weighted by the frequency of occurrence of functions \n\n#### `Algorithm.SRTree.ConfidenceIntervals`
  module \n\nThe main functions of this module are: \n\n- `paramCI`: calculates the
  parameters confidence intervals. \n- `predictionCI`: calculates the predictions
  confidence intervals \n\n### `EqSat` modules \n\nThe `EqSat` modules are split into
  $4$ submodules:\n\n- `Algorithm.EqSat.Simplify` contains function supporting algebraic
  simplification with equality saturation.\n- `Algorithm.EqSat` contains the main
  equality saturation function.\n- `Algorithm.EqSat.EGraph` contains the e-graph data
  structure and supporting functions.\n- `Algorithm.EqSat.EqSatDB` contains supporting
  functions to pattern matching and insert equivalent expressions into an e-graph.
  \n\n#### `Algorithm.EqSat` module\n\nThe main functions of this module are: \n\n-
  `eqSat` : runs equality saturation over a single expression. \n- `getBest` : returns
  the best expression given the cost function used to generate the e-graph \n- `recalculateBest`
  : recalculates the cost of each e-class using a new cost function \n- `runEqSat`
  : runs equality saturation inside `EGraphST` monad. Use this if you want to return
  the e-graph. \n\n#### `Algorithm.EqSat.EGraph` module\n\nThe main functions of this
  module are: \n\n- `fromTree` : creates an e-graph from an expression tree.\n- `fromTrees`
  : creates an e-graph from multiple expressions \n- `fromTreeWith` : inserts a new
  expression into the e-graph \n- `findRootClasses` : returns the roots of the e-graph,
  if any .\n- `getExpressionFrom` : returns a single expression from a given e-class
  always picking the first e-node as the path \n- `getAllExpressionsFrom` : returns
  all expressions from the given e-class \n- `getRndExpressionFrom` : returns a random
  expression from this e-class \n\n\n#### `Algorithm.EqSat.EqSatDB` module\n\nThe
  main functions of this module are: \n\n- TODO: create auxiliary functions to apply
  substution rules inside an EGraphST monad . \n\n#### `Algorithm.EqSat.Simplify`
  module\n\nThe main functions of this module are: \n\n- `simplifyEqSatDefault` :
  simplifies an expression using the default parameters \n- `simplifyEqSat` : simplifies
  with custom parameters\n\n## TODO:\n\n- support more advanced functions\n- support
  conditional branching (`IF-THEN-ELSE`)\n\n"
description-type: markdown
hash: d2adb6448b467980df9d388163cebaabe57b439378cf928123b6f578dc3b52bf
homepage: https://github.com/folivetti/srtree#readme
latest: 2.0.0.1
license-name: BSD-3-Clause
maintainer: fabricio.olivetti@gmail.com
synopsis: A general library to work with Symbolic Regression expression trees.
test-bench-deps:
  HUnit: '>=0'
  ad: '>=0'
  attoparsec: '>=0.14.4 && <0.15'
  attoparsec-expr: '>=0.1.1.2 && <0.2'
  base: '>=4.16 && <5'
  bytestring: '>=0.11 && <0.13'
  containers: '>=0.6.7 && <0.8'
  dlist: '>=1.0 && <1.1'
  exceptions: '>=0.10.7 && <0.11'
  filepath: '>=1.4.0.0 && <1.6'
  hashable: '>=1.4.4.0 && <1.6'
  ieee754: '>=0.8.0 && <0.9'
  lens: '>=5.2.3 && <5.4'
  list-shuffle: '>=1.0.0.1 && <1.1'
  massiv: '>=1.0.4.0 && <1.1'
  mtl: '>=2.2 && <2.4'
  random: '>=1.2 && <1.3'
  split: '>=0.2.5 && <0.3'
  srtree: '>=0'
  statistics: '>=0.16.2.1 && <0.17'
  transformers: '>=0.6.1.0 && <0.7'
  unordered-containers: '>=0.2 && <0.3'
  vector: '>=0.12 && <0.14'
  zlib: '>=0.6.3 && <0.8'
