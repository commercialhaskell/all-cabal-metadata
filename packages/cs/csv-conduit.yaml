homepage: http://github.com/ozataman/csv-conduit
changelog-type: markdown
hash: a10b802e6326a8738b6962ec35924c3b22effbbc545d4cc671731d8ececb02a5
test-bench-deps:
  test-framework-hunit: -any
  bytestring: -any
  test-framework: -any
  base: ! '>=4 && <5'
  text: -any
  HUnit: ! '>=1.2'
  containers: ! '>=0.3'
  mtl: -any
  csv-conduit: -any
  transformers: -any
  primitive: -any
  vector: -any
  directory: -any
maintainer: Ozgun Ataman <ozataman@gmail.com>
synopsis: A flexible, fast, conduit-based CSV parser library for Haskell.
changelog: |
  0.7.1.0
  * Add MonadFail instance for Parser. [PR 38](https://github.com/ozataman/csv-conduit/pull/38)

  0.7.0.0
  * BREAKING: Switch from partial Monoid instance on Parser to total Semigroup instance.
  * Compatibility with GHC 8.4.x/base-4.11.1.0

  0.6.8.1
  * Fix documentation mistake in FromNamedRecord/ToNamedRecord examples.

  0.6.8
  * Haddocks improvements
  * Fix inlining and specialization rules around formatDecimal
  * Updates to permit newest conduit/resourcet packages

  0.6.7
  * Fix build for GHC 8.0.1
basic-deps:
  exceptions: ! '>=0.3'
  bytestring: -any
  base: ! '>=4 && <5'
  unordered-containers: -any
  text: -any
  monad-control: -any
  conduit: ! '>=1.2.8 && <2.0'
  data-default: -any
  semigroups: -any
  array: -any
  conduit-extra: -any
  containers: ! '>=0.3'
  blaze-builder: -any
  ghc-prim: ! '>=0.2 && <0.6'
  mtl: -any
  mmorph: -any
  attoparsec: ! '>=0.10'
  transformers: -any
  resourcet: ! '>=1.1.2.1'
  primitive: -any
  vector: -any
all-versions:
- '0.1'
- '0.2'
- 0.2.1.1
- '0.3'
- 0.3.0.1
- 0.3.0.2
- 0.3.0.3
- 0.4.1
- 0.5.0
- 0.5.1
- 0.6.2
- 0.6.2.1
- 0.6.3
- 0.6.5
- 0.6.6
- 0.6.7
- 0.6.8
- 0.6.8.1
- 0.7.0.0
- 0.7.1.0
author: Ozgun Ataman
latest: 0.7.1.0
description-type: markdown
description: "# README [![Build Status](https://travis-ci.org/ozataman/csv-conduit.svg?branch=master)](https://travis-ci.org/ozataman/csv-conduit)\n\n##
  CSV Files and Haskell\n\nCSV files are the de-facto standard in many cases of data
  transfer,\nparticularly when dealing with enterprise application or disparate database\nsystems.\n\nWhile
  there are a number of csv libraries in Haskell, at the time of\nthis project's start,
  there wasn't one that provided all of the\nfollowing:\n\n* Full flexibility in quote
  characters, separators, input/output\n* Constant space operation\n* Robust parsing
  and error resiliency\n* Battle-tested reliability in real-world datasets\n* Fast
  operation\n* Convenient interface that supports a variety of use cases\n\nOver time,
  people created other plausible CSV packages like cassava.\nThe major benefit from
  this library remains to be:\n\n* Direct participation in the conduit ecosystem,
  which is now quite\n  large, and all the benefits that come with it.\n* Flexibility
  in CSV format definition.\n* Resiliency to errors in the input data.\n\n\n## This
  package\n\ncsv-conduit is a conduit-based CSV parsing library that is easy to\nuse,
  flexible and fast. It leverages the conduit infrastructure to\nprovide constant-space
  operation, which is quite critical in many real\nworld use cases.\n\nFor example,
  you can use http-conduit to download a CSV file from the\ninternet and plug its
  Source into intoCSV to stream-convert the\ndownload into the Row data type and do
  something with it as the data\nstreams, that is without having to download the entire
  file to disk\nfirst.\n\n\n## Author & Contributors\n\n- Ozgun Ataman (@ozataman)\n-
  Daniel Bergey (@bergey)\n- BJTerry (@BJTerry)\n- Mike Craig (@mkscrg)\n- Daniel
  Corson (@dancor)\n- Dmitry Dzhus (@dzhus)\n- Niklas Hambüchen (@nh2)\n- Facundo
  Domínguez (@facundominguez)\n\n\n### Introduction\n\n* The CSVeable typeclass implements
  the key operations.\n* CSVeable is parameterized on both a stream type and a target
  CSV row type.\n* There are 2 basic row types and they implement *exactly* the same
  operations,\n  so you can chose the right one for the job at hand:\n  - `type MapRow
  t = Map t t`\n  - `type Row t = [t]`\n* You basically use the Conduits defined in
  this library to do the\n  parsing from a CSV stream and rendering back into a CSV
  stream.\n* Use the full flexibility and modularity of conduits for sources and sinks.\n\n###
  Speed\n\nWhile fast operation is of concern, I have so far cared more about correct\noperation
  and a flexible API. Please let me know if you notice any performance\nregressions
  or optimization opportunities.\n\n\n### Usage Examples\n\n\n#### Example #1: Basics
  Using Convenience API\n\n```haskell\n{-# LANGUAGE OverloadedStrings #-}\n\nimport
  Data.Conduit\nimport Data.Conduit.Binary\nimport Data.Conduit.List as CL\nimport
  Data.CSV.Conduit\nimport Data.Text (Text)\n\n-- Just reverse te columns\nmyProcessor
  :: Monad m => Conduit (Row Text) m (Row Text)\nmyProcessor = CL.map reverse\n\ntest
  :: IO ()\ntest = runResourceT $ \n  transformCSV defCSVSettings \n               (sourceFile
  \"input.csv\") \n               myProcessor\n               (sinkFile \"output.csv\")\n```\n\n####
  Example #2: Basics Using Conduit API\n\n```haskell\n{-# LANGUAGE OverloadedStrings
  #-}\n\nimport Data.Conduit\nimport Data.Conduit.Binary\nimport Data.CSV.Conduit\nimport
  Data.Text (Text)\n\nmyProcessor :: Monad m => Conduit (Row Text) m (Row Text)\nmyProcessor
  = awaitForever $ yield\n\n-- Let's simply stream from a file, parse the CSV, reserialize
  it\n-- and push back into another file.\ntest :: IO ()\ntest = runResourceT $ \n
  \ sourceFile \"test/BigFile.csv\" $= \n  intoCSV defCSVSettings $=\n  myProcessor
  $=\n  fromCSV defCSVSettings $$\n  sinkFile \"test/BigFileOut.csv\"\n```\n\n"
license-name: BSD-3-Clause
