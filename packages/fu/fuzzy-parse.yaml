all-versions:
- 0.1.0.0
- 0.1.2.0
author: Dmitry Zuikov
basic-deps:
  attoparsec: '>=0.13'
  base: '>=4.11 && <5'
  containers: '>=0'
  mtl: '>=2.2'
  safe: '>=0'
  text: '>=1.2'
  time: '>=1.8'
changelog: |
  # Revision history for fuzzy-parse

  ## 0.1.2.0

   - Techical release
   - Added some missed things

  ## 0.1.0.0 -- YYYY-mm-dd

  * First version. Released on an unsuspecting world.
changelog-type: markdown
description: |+
  # About

  # Data.Text.Fuzzy.Tokenize

  The lightweight and multi-functional text tokenizer allowing different types of text tokenization
  depending on it's settings.

  It may be used in different sutiations, for DSL, text markups or even for parsing simple grammars
  easier and sometimes faster than in case of usage mainstream parsing combinators or parser
  generators.

  The primary goal of this package  is to parse unstructured text data, however it may be  used for
  parsing  such data formats as CSV with ease.

  Currently it supports the following types of entities: atoms, string literals (currently with the
  minimal set of escaped characters), punctuation characters and delimeters.

  ## Examples

  ### Simple CSV-like tokenization

  ```haskell
  tokenize (delims ":") "aaa : bebeb : qqq ::::" :: [Text]

  ["aaa "," bebeb "," qqq "]
  ```

  ```haskell
  tokenize (delims ":"<>sq<>emptyFields ) "aaa : bebeb : qqq ::::" :: [Text]

  ["aaa "," bebeb "," qqq ","","","",""]
  ```

  ```haskell
  tokenize (delims ":"<>sq<>emptyFields ) "aaa : bebeb : qqq ::::" :: [Maybe Text]

  [Just "aaa ",Just " bebeb ",Just " qqq ",Nothing,Nothing,Nothing,Nothing]
  ```

  ```haskell
  tokenize (delims ":"<>sq<>emptyFields ) "aaa : 'bebeb:colon inside' : qqq ::::" :: [Maybe Text]

  [Just "aaa ",Just " ",Just "bebeb:colon inside",Just " ",Just " qqq ",Nothing,Nothing,Nothing,Nothing]
  ```

  ```haskell
  let spec = sl<>delims ":"<>sq<>emptyFields<>noslits
  tokenize spec "   aaa :   'bebeb:colon inside' : qqq ::::" :: [Maybe Text]

  [Just "aaa ",Just "bebeb:colon inside ",Just "qqq ",Nothing,Nothing,Nothing,Nothing]
  ```

  ```haskell
  let spec = delims ":"<>sq<>emptyFields<>uw<>noslits
  tokenize spec "  a  b  c  : 'bebeb:colon inside' : qqq ::::"  :: [Maybe Text]

  [Just "a b c",Just "bebeb:colon inside",Just "qqq",Nothing,Nothing,Nothing,Nothing]
  ```

  ### Primitive lisp-like language

  ```haskell
  {-# LANGUAGE QuasiQuotes, ExtendedDefaultRules #-}

  import Text.InterpolatedString.Perl6 (q)
  import Data.Text.Fuzzy.Tokenize

  data TTok = TChar Char
            | TSChar Char
            | TPunct Char
            | TText Text
            | TStrLit Text
            | TKeyword Text
            | TEmpty
            deriving(Eq,Ord,Show)

  instance IsToken TTok where
   mkChar = TChar
   mkSChar = TSChar
   mkPunct = TPunct
   mkText = TText
   mkStrLit = TStrLit
   mkKeyword = TKeyword
   mkEmpty = TEmpty

  main = do

     let spec = delims " \n\t" <> comment ";"
                               <> punct "{}()[]<>"
                               <> sq <> sqq
                               <> uw
                               <> keywords ["define","apply","+"]
       let code = [q|
         (define add (a b ) ; define simple function
           (+ a b) )
         (define r (add 10 20))
  |]
       let toks = tokenize spec code :: [TTok]

     print toks
  ```

  ## Notes

  ### About the delimeter tokens
  This type of tokens appears during a "delimited" formats processing and disappears in results.
  Currenly you will never see it unless normalization is turned off by 'nn' option.

  The delimeters make sense in case of processing the CSV-like formats, but in this case you probably
  need only values in results.

  This behavior may be changed later. But right now delimeters seem pointless in results. If you
  process some sort of grammar where delimeter character is important, you may use punctuation
  instead, i.e:

  ```haskell
  let spec = delims " \t"<>punct ",;()" <>emptyFields<>sq
  tokenize spec "( delimeters , are , important, 'spaces are not');" :: [Text]

  ["(","delimeters",",","are",",","important",",","spaces are not",")",";"]
  ```

  ### Other
  For CSV-like formats it makes sense to split text to lines first, otherwise newline characters may
  cause to weird results


  # Authors

  This library is written and maintained by Dmitry Zuikov, dzuikov@gmail.com

description-type: markdown
hash: b5ca37678ab0c13fa8eff84aa166230e0f5bea8bfb4ce7b9afda38f1e6e38b15
homepage: https://github.com/hexresearch/fuzzy-parse
latest: 0.1.2.0
license-name: MIT
maintainer: dzuikov@gmail.com
synopsis: Tools for processing unstructured text data
test-bench-deps:
  base: '>=4 && <5'
  fuzzy-parse: '>=0'
  hspec: '>=0'
  hspec-discover: '>=0'
  interpolatedstring-perl6: '>=0'
  text: '>=0'
