all-versions:
- 0.2.0.0
- 0.3.0.0
- 0.3.1.0
- 0.3.2.0
- 0.3.3.0
- 0.4.1.0
- 0.4.1.1
- 0.4.2.0
- 0.4.7.0
- 0.4.8.0
- 0.5.0.0
- 0.5.1.0
author: Andy Georges
basic-deps:
  aeson: '>=0'
  aeson-pretty: '>=0'
  attoparsec: '>=0'
  attoparsec-iso8601: '>=0'
  base: '>=4.7 && <5'
  bytestring: '>=0'
  conduit: '>=0'
  conduit-combinators: '>=0'
  conduit-extra: '>=0'
  containers: '>=0'
  deepseq: '>=0'
  directory: '>=0'
  extra: '>=0'
  hnormalise: '>=0'
  ip: '>=0'
  lifted-base: '>=0'
  monad-control: '>=0'
  monad-loops: '>=0'
  monad-par: '>=0'
  mtl: '>=0'
  optparse-applicative: '>=0'
  permute: '>=0'
  resourcet: '>=0'
  stm-conduit: '>=0'
  text: '>=0'
  time: '>=0'
  transformers-base: '>=0'
  unix: '>=0'
  unordered-containers: '>=0'
  word8: '>=0'
  yaml: '>=0'
  zeromq4-conduit: '>=0'
  zeromq4-haskell: '>=0'
changelog: ''
changelog-type: ''
description: "hNormalise\n==========\n\n[![Build Status](https://secure.travis-ci.org/hpcugent/hnormalise.svg?branch=master)](http://travis-ci.org/hpcugent/hnormalise)\n\n`hNormalise`
  is a small tool and accompanying library for the conversion of regular [rsyslog](http://www.rsyslog.com)
  to\nstructured log messages, i.e., turning the `msg` payload into (a nested) JSON
  object.\n\nFeatures:\n\n- accepts incoming data on a regular TCP port or a ZeroMQ
  `pull` type port.\n- accepts JSON-style rsyslog data (sent as %jsonmesg% in the
  rsyslog template)\n- accepts legacy encoded rsyslog data (currently sent with the
  fixed template\n  <%PRI%>1 %TIMEGENERATED% %HOSTNAME% %SYSLOGTAG% - %APPNAME%: %msg%)\n-
  sends out successfull converted results on a TCP or ZeroMQ port, allowing communication
  back to a wide range of services,\n  including rsyslog, [logstash](http://www.elastic.co/products/logstash),
  ...\n- sends out original messages to a (different) TCP or ZeroMQ port in case the
  parsing fails, allowing other services to process the\n  information.\n- can process
  up to 18K Torque log messages/s on a 2.7GHz 2015 Corei5 (mid 2015 MacBook Pro) when
  streaming from an to a file.\n\nUsage and configuration\n-----------------------\n\nTo
  run and build `hNormalise`, clone this repository and run `stack build` followed
  by `stack install` inside it.\nTo start just run `hnormalise`. If you need help,
  use the `-h` flag. To run the included tests, run `stack test`.\nTo run the included
  benchmarks, run `stack bench` (with the `--output target.html` flag to get a nice
  web page with\nthe results).\n\nPorts and machines can be tweaked through a configuration
  file. See `data/hnormalise.yaml.full` for an example.\n\nTesting the actual setup
  can be done trivially via `nc`, provided you have data to throw at `hNormalise`.
  A test example\nis also provided below, or you can get useful examples from the
  tests, under `test/HNormalise/*/ParserSpec.hs`\n\nFor ZeroMQ, the development libraries
  for czmq are required. We use ZeroMQ >= 4.1.\n\nSupported log messages\n----------------------\n\nCurrently,
  hNormalise supports several log messages out of the box (i.e., the ones we need
  :)\n- [Torque](http://www.adaptivecomputing.com/products/open-source/torque/) accounting
  logs for a job exit.\n- [Shorewall](http://shorewall.org) firewall log messages
  for TCP, UDP and ICMP connections\n- [Lmod](https://www.tacc.utexas.edu/research-development/tacc-projects/lmod)
  module load messages\n- [Snoopy](https://github.com/a2o/snoopy) log messages\n\nMore
  are forthcoming soon, e.g., (in no particular order)\n- GPFS\n- Icinga\n- NFS\n-
  OpenNebula\n- SSH\n- Jube\n\nParsing\n-------\n\n`hNormalise` uses the [Attoparsec](https://github.com/bos/attoparsec)
  package to have fast and efficient parsing.\n`Attoparsec` offers a clean and relatively
  simple DSL that allows getting the relevant data from the message and\ndiscarding
  the rest. We also rely on [permute]() to deal with log lines that may contain e.g.,
  key-value pairs in\nno definite ordering. Note that this _will_ slow down the parsing.\n\n\nCaveat:
  at this point, we do not a priori restrict the possible parsers we\nunleash on each
  message. However, if the inbound data can be tagged properly,\nwe could reduce the
  maximal number of parsers tried and avoid extensive\nbacktracking.  Using ZeroMQ,
  this could be done by using topics to tag inbound\ninformation.\n\n### Adding a
  new parser\n\nTo add a new parser for log lines from tool `Tool`, several actions
  must be taken:\n\n- A `src/HNormalise/Tool` directory must be created, under which
  all specific code and data types for the new\n  log lines will reside. Note that
  `Tool` can provide multiple types of log lines, but they should all be coded under\n
  \ the same location.\n- Define a data type that holds the relevant data from the
  log line you wish to keep/forward in `HNOrmalise.Tool.Internal`.\n  Make sure that
  the type derives `Generic` (and add the require language extentions on top of the
  file).\n- The parser goes in the `HNormalise.Tool.Parser` module.\n- Conversion
  of the data type that was defined to hold the data to JSON is done in `HNormalise.Tool.JSON`.\n-
  Finally, the `HNormalise` module defines a sum-type container to which you should
  add your own entry. Remember to also\n  add a line for the corresponding getJsonKey
  function, which defines the key under whoch the parsed data will be\n  made available
  downstream.\n- Add tests with relevant cases under `test/HNormalise/Tool/ParserSpec.hs`.
  The framework should pick these up\nautomagically.\n- Add en entry for your test
  cases to the set of benchmarks, so we can have a reasonable estimate on how your
  parser is\n  performing. Update the HTML page under `benchmarks` with the complete
  set of tests you ran.\n\n\nExample\n-------\n\nThe original (anonymised) message
  sent by rsyslog (as JSON) for a Torque job exit event is\n\n~~~~\n{\"msg\":\"05/14/2017
  00:00:02;E;3275189.master.mycluster.mydomain.com;user=someuser group=somegroup jobname=myjob
  queue=long ctime=1494689613 qtime=1494689613 etime=1494689613 start=1494689684 owner=someuser@login.mycluster.mydomain.com
  exec_host=mynode.mycluster.mydomain.com/1 Resource_List.neednodes=mynode:ppn=1 Resource_List.nice=0
  Resource_List.nodect=1 Resource_List.nodes=mynode:ppn=1 Resource_List.vmem=4720302336b
  Resource_List.walltime=71:59:59 session=102034 total_execution_slots=1 unique_node_count=1
  end=1494712802 Exit_status=0 resources_used.cput=23076 resources_used.energy_used=0
  resources_used.mem=64480kb resources_used.vmem=314996kb resources_used.walltime=06:25:15\",
  \"rawmsg\": \"redacted\", \"timereported\": \"2017-05-15T18:16:16.724002+02:00\",
  \"hostname\": \"master.mydomain.com\", \"syslogtag\": \"hnormalise\", \"inputname\":
  \"imfile\", \"fromhost\": \"\", \"fromhost-ip\": \"\", \"pri\": \"133\", \"syslogfacility\":
  \"16\", \"syslogseverity\": \"5\", \"timegenerated\": \"2017-05-15T18:16:16.724002+02:00\",
  \"programname\": \"hnormalise\", \"protocol-version\": \"0\", \"structured-data\":
  \"-\", \"app-name\": \"hnormalise\", \"procid\": \"-\", \"msgid\": \"-\", \"uuid\":
  null, \"$!\": null }\n~~~~\n\nThe resulting JSON is sent to logstash, which forwarded
  it to ES, e.g. with the following configuration\n\n~~~~\ninput {\n    tcp {\n        type
  => \"normalised_syslog\"\n        port => 26002\n        codec => \"json\"\n    }\n}\n\nfilter
  {\n    if [type] == 'normalised_syslog' {\n        mutate {\n            add_field
  => {\n                \"[@metadata][target_index]\" => \"rsyslog-test\"\n            }\n
  \       }\n    }\n}\n\noutput {\n    elasticsearch {\n        template_overwrite
  => true\n        document_type => \"%{@type}\"\n        index => \"%{[@metadata][target_index]}\"\n
  \       hosts => [ \"127.0.0.1\" ]\n        flush_size => 50\n\t}\n}\n~~~~\n\nThe
  following information can be retrieved from Elasticsearch. The interesting part
  is the `torque` entry, which is what we\naimed to get.\n\n~~~~{.json}\n{\n  \"took\"
  : 1,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 5,\n    \"successful\"
  : 5,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : 1,\n    \"max_score\"
  : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"rsyslog-test\",\n        \"_type\"
  : \"%{@type}\",\n        \"_id\" : \"AVwWnWEqQ4ADFiA38GPp\",\n        \"_score\"
  : 1.0,\n        \"_source\" : {\n          \"@timestamp\" : \"2017-05-17T13:33:51.690Z\",\n
  \         \"port\" : 58031,\n          \"@version\" : \"1\",\n          \"host\"
  : \"0:0:0:0:0:0:0:1\",\n          \"torque\" : {\n            \"owner\" : \"someuser@login.mycluster.mydomain.com\",\n
  \           \"startCount\" : null,\n            \"resourceUsage\" : {\n              \"mem\"
  : 66027520,\n              \"vmem\" : 322555904,\n              \"cputime\" : 23076,\n
  \             \"walltime\" : {\n                \"hours\" : 6,\n                \"seconds\"
  : 15,\n                \"minutes\" : 25,\n                \"days\" : 0\n              },\n
  \             \"energy\" : 0\n            },\n            \"execHost\": [\n              {\n
  \               \"name\": \"exec_host=mynode.mycluster.mydomain.com\",\n                \"cores\":
  [\n                  1\n                ]\n              }\n            ],\n            \"resourceRequest\"
  : {\n              \"neednodes\" : {\n                \"Right\" : [\n                  {\n
  \                   \"name\" : \"mynode\",\n                    \"ppn\" : 1\n                  }\n
  \               ]\n              },\n              \"nodes\" : {\n                \"Right\"
  : [\n                  {\n                    \"name\" : \"mynode\",\n                    \"ppn\"
  : 1\n                  }\n                ]\n              },\n              \"vmem\"
  : 4720302336,\n              \"nodeCount\" : 1,\n              \"walltime\" : {\n
  \               \"hours\" : 71,\n                \"seconds\" : 59,\n                \"minutes\"
  : 59,\n                \"days\" : 0\n              },\n              \"nice\" :
  0\n            },\n            \"session\" : 102034,\n            \"times\" : {\n
  \             \"qtime\" : 1494689613,\n              \"etime\" : 1494689613,\n              \"ctime\"
  : 1494689613,\n              \"startTime\" : 1494689684,\n              \"endTime\"
  : 1494712802\n            },\n            \"totalExecutionSlots\" : 1,\n            \"name\"
  : {\n              \"cluster\" : \"mycluster\",\n              \"number\" : 3275189,\n
  \             \"array_id\" : null,\n              \"master\" : \"master\"\n            },\n
  \           \"uniqueNodeCount\" : 1,\n            \"user\" : \"someuser\",\n            \"exitStatus\"
  : 0,\n            \"jobname\" : \"myjob\",\n            \"queue\" : \"long\",\n
  \           \"group\" : \"somegroup\"\n          },\n          \"message\" : \"05/14/2017
  00:00:02;E;3275189.master.mycluster.mydomain.com;user=someuser group=somegroup jobname=myjob
  queue=long ctime=1494689613 qtime=1494689613 etime=1494689613 start=1494689684 owner=someuser@login.mycluster.mydomain.com
  exec_host=mynode.mycluster.mydomain.com/1 Resource_List.neednodes=mynode:ppn=1 Resource_List.nice=0
  Resource_List.nodect=1 Resource_List.nodes=mynode:ppn=1 Resource_List.vmem=4720302336b
  Resource_List.walltime=71:59:59 session=102034 total_execution_slots=1 unique_node_count=1
  end=1494712802 Exit_status=0 resources_used.cput=23076 resources_used.energy_used=0
  resources_used.mem=64480kb resources_used.vmem=314996kb resources_used.walltime=06:25:15\",\n
  \         \"syslog_abspri\" : \"5\",\n          \"type\" : \"normalised_syslog\",\n
  \         \"tags\" : [ ]\n        }\n      }\n    ]\n  }\n}\n~~~~\n"
description-type: markdown
hash: 2403c3995db034c151efd185bc830da62552a5f04d4d1fcbb6d82992b0f9751b
homepage: https://github.com/itkovian/hnormalise#readme
latest: 0.5.1.0
license-name: BSD-3-Clause
maintainer: itkovian@gmail.com
synopsis: Log message normalisation tool producing structured JSON messages
test-bench-deps:
  aeson: '>=0'
  attoparsec: '>=0'
  attoparsec-iso8601: '>=0'
  base: '>=0'
  conduit-extra: '>=0'
  criterion: '>=0'
  hnormalise: '>=0'
  hspec: '>=0'
  hspec-attoparsec: '>=0'
  hspec-core: '>=0'
  hspec-expectations: '>=0'
  ip: '>=0'
  random: '>=0'
  text: '>=0'
  time: '>=0'
