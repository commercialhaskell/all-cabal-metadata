all-versions:
- 0.1.0.0
- 0.3.0.0
- 0.3.0.1
- 0.3.1.0
- 0.3.1.1
- 0.3.1.2
- 0.3.1.3
author: Ivan Lazar Miljenovic
basic-deps:
  base: '>=4 && <5'
  exceptions: '>=0.6 && <0.11'
  lifted-async: '>=0.9.3 && <0.11'
  monad-control: '>=1 && <2'
  stm: '>=2.4 && <2.6'
  streaming: '>=0.1.4.0 && <0.3'
  streaming-with: '>=0.1.0.0 && <0.3'
  transformers-base: '>=0'
changelog: |
  # Revision history for streaming-concurrency

  ## 0.3.1.3 -- 2019-05-13

  * Bump/fix dependencies for:
      - stm
      - hspec
      - lifted-async

  ## 0.3.1.2 -- 2018-05-23

  * Bump lifted-async dependency.

  ## 0.3.1.1 -- 2018-03-23

  * Bump exceptions dependency.

  ## 0.3.1.0 -- 2018-03-14

  * Allow `streaming-0.2.*`

  * Improved performance for `withStreamMap` and `withStreamMapM`.

      - Previously used additional `Stream`s within the concurrent
        buffers which isn't actually needed.

      - A benchmark is available to compare various implementations.

  * Primitives to help defining custom stream-mapping functions are now
    exported.

  ## 0.3.0.1 -- 2017-07-07

  * Allow `streaming-with-0.2.*`

  ## 0.3.0.0 -- 2017-07-05

  * Removed support for streaming `ByteString`s.

      The ByteString-related functions which were previously implemented
      are broken conceptually and should not be used.

      A ByteString consists of a stream of bytes; the meaning of each byte
      is dependent upon its position in the overall stream.

      In terms of implementation, these bytes are accumulated into
      _chunks_, each of which may very well be of a different size.

      As such, if such a chunk is fed into a buffer with multiple readers,
      then there is no guarantee which reader will actually receive it or if
      it makes sense about what it is in isolation (e.g. it could be split
      mid-word, or possibly even in the middle of a Unicode character).

      If, however, multiple ByteStrings are fed into a buffer with a single
      reader, the order it has when coming out is similarly undeterministic:
      it isn't possible to coherently ensure the sanity of the resulting
      ByteString.

      As such, unless you really want to consider it as a stream of
      raw 8-bit numbers, trying to do any concurrency with a ByteString
      will only lead to trouble.  If you do need such functionality, you
      can implement it yourself using buffers containing `Word8` values
      (in which case you can use `Data.ByteString.Streaming.unpack`).

  * Fix lower bound of `lifted-async` (`replicateConcurrently_` was
    added in 0.9.3).

  ## 0.2.0.0 -- 2017-07-05

  * Rename functions to match the `with...` naming scheme:

      - `merge{Streams,ByteStrings}` to `withMerged{Streams,ByteStrings}`
      - `read{Stream,ByteString}Basket` to `with{Stream,ByteString}Basket`

  * Add the ability to use buffers to concurrently transform the stream;
    following functions added:

      - `withBufferedTransform`
      - `withStreamMap`
      - `withStreamMapM`
      - `withStreamTransform`

      (Note: it is not sound in the general case to transform a
      streaming `ByteString`; as such, functions for this are not
      implemented though it is possible to do yourself.)

  ## 0.1.0.0 -- 2017-07-04

  * First version.
changelog-type: markdown
description: |
  streaming-concurrency
  ==============

  [![Hackage](https://img.shields.io/hackage/v/streaming-concurrency.svg)](https://hackage.haskell.org/package/streaming-concurrency) [![Build Status](https://travis-ci.org/haskell-streaming/streaming-concurrency.svg)](https://travis-ci.org/haskell-streaming/streaming-concurrency)

  > Concurrency for the [streaming] ecosystem

  [streaming]: http://hackage.haskell.org/package/streaming

  There are two primary higher-level use-cases for this library:

  1. Merge multiple `Stream`s together.

  2. A conceptual `Stream`-based equivalent to [`parMap`] (albeit
     utilising concurrency rather than true parallelism).

      [`parMap`]: http://hackage.haskell.org/package/parallel/docs/Control-Parallel-Strategies.html#v:parMap

  However, low-level functions are also exposed so you can construct
  your own methods of concurrently using `Stream`s (and there are also
  non-`Stream`-specific functions if you wish to use it with other data
  types).

  Conceptually, the approach taken is to consider a typical
  correspondence system with an in-basket/tray for receiving messages
  for others, and an out-basket/tray to be later dealt with.  Inputs are
  thus provided into the `InBasket` and removed once available from the
  `OutBasket`.

  Thanks and recognition
  ----------------------

  The code here is heavily based upon -- and borrows the underlying
  `Buffer` code from -- Gabriel Gonzalez's [pipes-concurrency].  It
  differs from it primarily in being more bracket-oriented rather than
  providing a `spawn` primitive, thus not requiring explicit garbage
  collection.

  [pipes-concurrency]: http://hackage.haskell.org/package/pipes-concurrency

  Another main difference is that the naming of the `input` and `output`
  types has been switched around: [pipes-concurrency] seems to consider
  them from the point of view of the supplying/consuming `Pipe`s,
  whereas here they are considered from the point of view of the
  `Buffer` itself.
description-type: markdown
hash: b46503a07a2877b71db70e10c10e33577c854904a14b3db0964a91d1d0933f79
homepage: ''
latest: 0.3.1.3
license-name: MIT
maintainer: Ivan.Miljenovic@gmail.com
synopsis: Concurrency support for the streaming ecosystem
test-bench-deps:
  HUnit: '>=0'
  QuickCheck: '>=2 && <3'
  base: '>=0'
  exceptions: '>=0'
  hspec: '>=2.4 && <2.8'
  lifted-async: '>=0'
  monad-control: '>=0'
  quickcheck-instances: '>=0'
  streaming: '>=0'
  streaming-concurrency: '>=0'
  testbench: '>=0.2.1.0 && <0.3'
