all-versions:
- 0.1.0.0
- 0.2.0.0
- 0.2.0.1
- 0.2.0.2
- 0.2.0.3
- 1.0.0.0
- 1.0.1.0
- 1.0.1.1
author: Kyle Beechly
basic-deps:
  base: '>=4.3.0.0 && <=4.20.0.1'
  mtl: '>=2.2.2 && <2.4'
  random: '>=1.0.0.3 && <1.3'
  random-shuffle: '>=0.0.4 && <0.1'
  tensort: '>=0'
changelog: |
  # Revision history for tensort

  ## 0.1.0.0 -- 2024-05-30

  * First version. Released to an eager world!

  ## 0.2.0.0 -- 2024-05-31

  * Add Logarithmic Tensort

  * Rename and update Exchangesort

  * Simplify code and structure

  * Cleanup exports

  * Cleanup Types

  * Improve documentation

  * Add to package file

  * Expand supported dependency versions

  * Add tests

  ## 0.2.0.1 -- 2024-06-12

  * Add guards for short lists in input

  * Improve testing

  * Improve documentation

  * Add very basic benchmarking

  ## 0.2.0.2 -- 2024-06-13

  * Cleanup testing and CI

  ## 0.2.0.3 -- 2024-06-16

  * Improve testing compatibility (fix QuickCheck breaking Stackage build)

  ## 1.0.0.0 -- 2024-08-21

  * Add Recursive Robustsort

  * Add Rotationsort

  * Fix Bubblesort to more closely match Ackley's non-'optimized' version

  * Add Benchmarking

  * Expand README

  * Replace Exchangesort with Rotationsort in Robustsort

  * Use Sortable type in Tensort and Robustsort so they can be used recursively

  * Add top-level Tensort and Robustsort functions wrapped in a type converter so
    they can be easily used to sort Bits (Integers)

  * Add more helper functions

  * Many more updates to the algorithms - see README for details

  ## 1.0.1.0 -- 2024-08-22

  * Export more functions for building custom Tensort variants

  * Cleanup and improve documentation

  * Cleanup code a bit
changelog-type: markdown
description: "# Tensort [![Hackage](https://img.shields.io/hackage/v/tensort.svg)](https://hackage.haskell.org/package/tensort)\n\nTensort
  is a family of sorting algorithms that are tunable to adjust to the\npriorities
  of the task at hand.\n\nThis project started as an exploration of what a sorting
  algorithm that\nprioritizes robustness might look like. As such it also describes
  and provides\nimplementations of Robustsort, a group of Tensort variants designed
  for\nrobustness in conditions described in David H. Ackley's\n[Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf).\n\nSimply
  put, Tensort takes an input list, transforms the list into a\nmulti-dimensional
  tensor field, then transforms that tensor field back into a\nsorted list. These
  transformations provide opportunities to increase redundancy\nfor improved robustness
  and can be leveraged to include any further processing\nwe wish to do on the elements.\n\n<figure>\n
  \   <img src=\"https://raw.githubusercontent.com/kaBeech/tensort/b160df72bdd673b37cbf7b8a5b7d0f4d02af9920/assets/images/deck_shuffle_chart_censored.svg\"\n
  \        alt=\"When sorting a randomly shuffled deck of cards, Quicksort makes\n
  \       202 positional errors, Mergesort makes 201, Bubblesort makes 4, Tensort\n
  \       makes 51, Mundane Robustsort makes 11, and Magic Robustsort makes\n        [SPOILERS]\">\n
  \   <figcaption><i>\n        Read on for the full data, or \n        <a href=\"#comparing-it-all\">\n
  \           click here to jump to the comparison section for spoilers\n        </a>\n
  \   </i></figcaption>\n</figure>\n\n## Table of Contents\n\n- [Introduction](#introduction)\n
  \ - [Inspiration](#inspiration)\n  - [Why?](#why)\n  - [But why would anyone care
  about this in the first\n     place?](#but-why-would-anyone-care-about-this-in-the-first-place)\n
  \ - [Why Haskell?](#why-haskell)\n  - [What's a tensor?](#whats-a-tensor)\n- [Project
  structure](#project-structure)\n- [Algorithms overview](#algorithms-overview)\n
  \ - [Tensort](#tensort)\n    - [Preface](#preface)\n    - [Structure](#structure)\n
  \   - [Algorithm](#algorithm)\n    - [Benefits](#benefits)\n    - [Logarithmic Bytesize](#logarithmic-bytesize)\n
  \ - [Robustsort](#robustsort)\n    - [Preface](#preface-1)\n    - [Overview](#overview)\n
  \   - [Examining Bubblesort](#examining-bubblesort)\n    - [Rotationsort](#rotationsort)\n
  \   - [Introducing Supersort](#introducing-supersort)\n    - [Permutationsort](#permutationsort)\n
  \   - [Supersort Adjudication](#supersort-adjudication)\n    - [Recursion](#recursion)\n
  \ - [Magicsort](#magicsort)\n    - [Magic Robustsort SubAlgorithm\n       alterations](#magic-robustsort-subalgorithm-alterations)\n
  \ - [A note about Mundane Robustsort\n     SubAlgorithms](#a-note-about-mundane-robustsort-subalgorithms)\n-
  [Comparing it all](#comparing-it-all)\n- [Library](#library)\n- [Development Environment](#development-environment)\n-
  [Contact](#contact)\n- [Thank you](#thank-you)\n\n## Introduction\n\n### Inspiration\n\n
  \ - [Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf) by\n
  \ [David H. Ackley](https://livingcomputation.com/)\n\n  - [Beyond Efficiency by
  Dave Ackley](https://futureofcoding.org/episodes/070)\n  by Future of Coding ([Lu
  Wilson](https://www.todepond.com/),\n  [Jimmy Miller](https://jimmyhmiller.github.io/),\n
  \ [Ivan Reese](https://ivanish.ca/))\n\n### Why?\n\nBecause near the end of\n[that
  podcast episode](https://futureofcoding.org/episodes/070),\n[Ivan](https://ivanish.ca/)
  said \"Why are we comparing Bubblesort versus\nQuicksort and Mergesort? Well, because
  no one's made Robustsort yet.\"\n\nAnd I thought, \"Why not?\"\n\n### But why would
  anyone care about this in the first place?\n\nBeing adaptable to different scenarios,
  a tunable sorting algorithm has many\npotential applications. This README will focus
  on robustness in sorting.\n\n[Ackley](https://www.cs.unm.edu/~ackley/be-201301131528.pdf)
  has compelling\nthings to say about why prioritizing robustness is important and
  useful. I'd\nhighly recommend reading that paper!\n\nOr listening to [this podcast](https://futureofcoding.org/episodes/070)!\n\nIf
  you want my elevator pitch, it's because we eventually want to build things\nlike
  [Dyson Spheres](https://en.wikipedia.org/wiki/Dyson_sphere). Doing so will\ninvolve
  massively distributed systems that are constantly pelted by radiation.\nIn such
  circumstances, robustness is key.\n\nAnother example I like to consider is artificial
  cognition. When working\nin a non-deterministic system (or a system so complex as
  to be considered\nnon-deterministic), it can be helpful to have systems in place
  to verify that\nthe answer we come to is valid.\n\nIncidentally, while I was preparing
  for this project, we experienced\n[the strongest solar storm to reach Earth in 2\ndecades](https://science.nasa.gov/science-research/heliophysics/how-nasa-tracked-the-most-intense-solar-storm-in-decades/).\nI
  don't know for certain whether the solar activity caused any computer errors,\nbut
  we had some anomalies at work and certainly joked about them being caused\nby the
  Sun.\n\nAlso during the same period,\n[one of the Internet's root-servers glitched
  out for unexplained\nreasons](https://arstechnica.com/security/2024/05/dns-glitch-that-threatened-internet-stability-fixed-cause-remains-unclear/).\n\nAs
  Ackley asserts, as a culture we have tended to prioritize correctness and\nefficiency
  to the detriment of robustness. The rate of our technological\nprogression precludes
  us from continuing to do so.\n\n### Why Haskell?\n\n1. Tensort can involve a lot
  of recursion, which Haskell handles well\n\n2. All the other benefits we get from
  using a purely functional language, such\nas strict dependency management, which
  even the smartest among us sometimes\nfalter without:\n\n<figure>\n    <img src=\"./assets/images/ackley_deps.png\"\n
  \        alt=\"Comment from Ackley in the Beyond Efficiency code about Perl\n        updates
  breaking their code\">\n    <figcaption><i><a href=\"http://livingcomputation.com/robusort2.tar\">\n
  \           Source\n        </a></i></figcaption>\n</figure>\n\n      \n\n3. [Obviously](https://www.youtube.com/shorts/LGZKXZQeEBg)\n\n###
  What's a tensor?\n\nIf you want an in-depth explanation,\n[Wikipedia](https://en.wikipedia.org/wiki/Tensor)
  is usually a good starting\nplace.\n\nIf you just want to understand Tensort, you
  can think of 'tensor' as a fancy\nword for a multi-dimensional array.\n\nEvery tensor
  has a degree, which is the number of dimensions it has. A 0-degree\ntensor is a
  scalar (like an integer), a 1-degree tensor is a vector (like a\nlist), a 2-degree
  tensor is a matrix, and so on.\n\nEach dimension of a tensor has a rank, which can
  be thought of as the length of\nthat dimension. A tensor's shape can be described
  by another tensor that\ndenotes the ranks of each of its dimensions. For example.
  [1,2,3] is an\ninstance of a 1-degree tensor. Its single dimension is 3 elements
  long, so it\nhas a rank 3. Thus its shape is [3].\n\nFor another example, consider
  the following tensor which has the shape [3,2]:\n\n    [[1,2,3],\n     [4,5,6]]\n\nTensort
  transforms a list into a field of the highest-degree tensors possible\nwhile giving
  its dimensions a specified maximum rank size to achieve the\ndensest possible cluster
  of short lists. This provides opportunities to add\nprocessing tailored to suit
  the current goals while preserving time efficiency.\n\n## Project structure\n\n-
  `src/` contains the Tensort library\n    \n- `app/` contains the suite for comparing
  different sorting algorithms in terms\nof robustness and time efficiency (only in
  the benchmarking branch)\n\n- `data/` contains benchmarking data\n\n## Algorithms
  overview\n\nThis README assumes some general knowledge of basic sorting algoritms.
  If you\nwould like a refresher, I recommend\n[this video](https://www.youtube.com/watch?v=kgBjXUE_Nwc)
  which touches on\nBubblesort and Mergesort, and\n[this video](https://www.youtube.com/watch?v=XE4VP_8Y0BU)
  which discusses\nQuicksort.\n\nIt also assumes you've read\n[Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf)
  by\nDavid H. Ackley. Go read it! It's short!\n\nPlease note that we will discuss
  a few algorithms that I've either made up or\nam just not familiar with by other
  names. If any of these algorithms have\npreviously been named, please [let me know](#contact).
  Prior to this project I\nreally only had a rudimentary understanding of Insertionsort,
  Quicksort,\nMergesort, Bubblesort and Bogosort, so it's entirely possible that I've\nreinvented
  a few things that already exist.\n\nIt may be helpful to note that this project
  was originally undertaken in an\nendeavor to come up with a solution naively, for
  the exercise, before\nresearching other algorithms built to tackle the same problem.
  I did very\nbriefly check out Ackley's [Demon Horde\nSort](https://www.youtube.com/watch?v=helScS3coAE&t=260s),
  but only enough\n(about 5 seconds of that video) to verify that it is different
  from this\nalgorithm. I've been purposefully avoiding learning much about Demon\nHorde
  Sort before publishing v1.0.0.0 of this package, but Ackley is way\nsmarter than
  me so if you do actually want a real, professional approach to\nrobust sorting,
  Demon Horde Sort is likely the place to look.\n\nThe algorithms used here that I
  have made up or renamed are, in order of\nintroduction, Tensort, Robustsort, Rotationsort,
  Permutationsort, and\nMagicsort.\n\nI will also be joined by the spirit of Sir Michael
  Caine, who is here for two\nreasons. One is to keep an eye on me and make sure I
  don't go too overboard.\nMore importantly, he's here as a bit of insurance to make
  sure you've read\n[Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf).
  You\ncan think of him as my version of the M&M's on Van Halen's concert\nrider ([the
  most famously robust rider in rock\nhistory](https://en.wikipedia.org/wiki/Van_Halen#Contract_riders)).
  If you\ncan't figure out why he's here, especially by the end of this README, go
  back\nand re-read the paper!\n\nAlright, let's get started! Ready, Sir Michael?\n\n<figure>\n
  \   <img src=\"https://m.media-amazon.com/images/M/MV5BMzU2Nzk5NjA1M15BMl5BanBnXkFtZTYwNjcyNDU2._V1_.jpg\"\n
  \        alt=\"Sir Michael Caine, ready to go!\">\n    <figcaption><i><a href=\"https://www.imdb.com/name/nm0000323/mediaviewer/rm1782683648/\">\n
  \           Source\n        </a></i></figcaption>\n</figure>\n\n### Tensort\n\n####
  Preface\n\nTensort is my original attempt to write the most robust sorting algorithm\npossible
  with O(n log n) average time efficiency while avoiding anything that\nAckley might
  consider a \"cheap hack.\" Starting out, my hope was that it would\nbe, if not competitive
  with Bubblesort in robustness, at least a major\nimprovement over Quicksort and
  Mergesort.\n\nAfter settling on this algorithm, I looked into several other sorting\nalgorithms
  for comparison and found a few that have some similarities with\nTensort - notably
  Blocksort, Bucketsort, and Patiencesort. If you are familiar\nwith these algorithms,
  you may recognize that they each have a structure that\naids in understanding them.\n\nTensort
  uses an underlying structure as well. We will discuss this structure \nbefore going
  over the algorithm's actual steps. If this doesn't make sense yet,\nfear not!\n\n####
  Structure\n\n  - Bit <- Element of the list to be sorted\n\n  - Byte <- List of
  Bits\n\n  - Bytesize <- Maximum length of a Byte\n\n  - Tensor <- Tuple of a Register
  list and a Memory list\n\n  - Memory <- List of Bytes or other Tensors contained
  in the current Tensor\n\n  - Register <- List of Records, each Record referencing
  one Byte or Tensor\n    in Memory\n\n  - Record <- Tuple of the Address and a copy
  of the TopBit of the referenced\n    Byte or Tensor\n\n  - Address <- Pointer to
  a Byte or Tensor in Memory\n\n  - TopBit <- Value of the Bit at the top of the stack
  in a Byte or Tensor\n\n  - TensorStack <- A top-level Tensor along with all the
  Bits, Bytes, and\n    Tensors contained within it. Structurally equivalent to a
  Tensor\n\n  - TopRegister <- List of Records that is built after all Tensors are
  built.\n    Each Record references one TensorStack. Structurally equivalent to a\n
  \   Register\n\n  - SubAlgorithm <- The sorting sub-algorithm used at various stages\n\nIn
  Tensort, the smallest unit of information is a Bit. Each Bit stores one\nelement
  of the list to be sorted. A group of Bits is known as a Byte.\n\nA Byte is a list
  of Bits. The maximum length of a Byte (known as the Bytesize)\nis set according
  to an argument passed to Tensort. This Bytesize can also be\nthought of as the maximum
  rank (not degree) of a tensor in Tensort.\nIdeally, all Bytes will be of maximum
  length until the final steps of Tensort.\nSeveral Bytes are grouped together in
  a Tensor.\n\nA Tensor is a tuple with two elements: Register and Memory.\n\nMemory
  is the second element in a Tensor tuple. It is a list of Bytes or\nother Tensors.
  The maximum length of this Memory list is equal to the Bytesize.\n\nA Register is
  the first element in a Tensor tuple. It is a list of Records,\neach of which has
  an Address pointing to an element in its Tensor's Memory\nand a copy of the TopBit
  in the referenced element.\n\nEach Record is a simplification of a Byte or Tensor
  in a Tensor's memory. It\nis a tuple comprised of an Address and a TopBit\n\nThe
  Address of a Record is an integer representing the index of the referenced\nByte
  or Tensor in its containing Tensor's memory\n\nThe TopBit of a Byte (which is copied
  into the Byte's referencing Record) is\nthe Bit at the end of the Byte list. If
  everything functions correctly, this\nwill be the highest value Bit in the Byte.\n\nThe
  TopBit of a Tensor (which is copied into the Tensor's referencing Record)\nis the
  TopBit of the Byte referenced by the Record at the end of the Register\nlist of
  the Tensor referenced by the Record at the end of the Register list of\nthe Tensor...
  and so on until the original (containing) Tensor is reached. If \neverything functions
  correctly, this TopBit will be the highest value Bit in\nthe Byte.\n\nA TensorStack
  is a top-level Tensor (i.e. a Tensor not contained within another\nTensor) along
  with all the Bits, Bytes, and Tensors it contains. Once the\nTensors are fully built,
  the total number of TensorStacks will be equal to (or\nsometimes less than) the
  Bytesize, but before that point there will be many\nmore TensorStacks.\n\nOnce all
  Tensors are built, a TopRegister is assembled as a list of Records,\neach Record
  referencing one TensorStack.\n\nThe sorting SubAlgorithm will be used any time we
  sort something within\nTensort. The choice of this SubAlgorithm is very important.
  For reasons that\nwill become clear soon, the SubAlgorithm for Standard Tensort
  will be\nBubblesort, but the major part of Tensort's tunability is the ability to\nsubstitute
  another sorting algorithm based on current priorities.\n\nNow, on to the algorithm!\n\n####
  Algorithm\n\nThe first step in Tensort is to randomize the input list. I'll explain
  why we\ndo this in more detail later - for now just know that it's easier for Tensort\nto
  make mistakes when the list is already nearly sorted.\n\n  1. Randomize the input
  list of Bits.\n\n  2. Assemble Bytes by grouping the Bits into lists of lengths
  equal to the\n     Bytesize, then sorting the Bits in each Byte using the SubAlgorithm.
  After\n     this, we will do no more write operations on the Bits until the final\n
  \    steps. Instead, we will make copies of the Bits and sort the copies\n     alongside
  their pointers.\n\n  3. Assemble TensorStacks by creating Tensors from the Bytes:\n
  \       <ol>\n            <li>\n                Group the Bytes together in Memory
  lists of Bytesize length.\n            </li>\n            <li>Assign each Memory
  to a newly-created Tensor.</li>\n            <li>\n                For each Tensor,
  make Records for each Byte in its Memory\n                by combining the Byte's
  index in Memory list with a copy of its\n                TopBit.\n            </li>\n
  \           <li>\n                Group the Records for each Tensor together and
  form them into\n                their Tensor's Register list.\n            </li>\n
  \           <li>\n                Sort the Records in each Register list in order
  of their\n                TopBits.\n            </li>\n        </ol>\n\n  4. Reduce
  the number of TensorStacks by creating a new layer of Tensors from\n       the Tensors
  created in Step 3:\n        <ol>\n            <li>\n                Group the first
  layer of Tensors together in Memory lists of\n                Bytesize length.\n
  \           </li>\n            <li>Assign each Memory to a newly-created Tensor.</li>\n
  \           <li>\n                For each newly-created Tensor, make Records for
  each Tensor in\n                its Memory by combining the enclosed Tensor's index
  in the\n                Memory list with a copy of its TopBit.\n            </li>\n
  \           <li>\n                Group the Records for each newly-created Tensor
  together and\n                form them into their Tensor's Register list.\n            </li>\n
  \           <li>\n                Sort each Register list in order of its Records'
  TopBits.\n            </li>\n        </ol>\n\n  5. Continue in the same manner as
  in Step 4 until the number of TensorStacks\n     is equal to or less than the Bytesize.\n\n
  \ 6. Assemble a TopRegister by making Records from the Top Bits of each\n     TensorStack
  and sorting the Records.\n\n  7. Remove the TopBit from the top Byte in the top
  TensorStack and add it to\n     the final Sorted List. If the top Byte has more
  than one Bit in it still,\n     re-sort the Byte for good measure\n\n  8. If the
  top Byte in the top TensorStack is empty:\n      <ol>\n          <li>\n              Remove
  the Record that points to the top Byte from its containing\n              Tensor's
  Register.\n          </li>\n          <li>\n              If the Tensor containing
  that byte is empty, remove the Record\n              that points to that Tensor
  from its containing Tensor's Register.\n              Do this recursively until
  finding a Tensor that is not empty or\n              the top of the TensorStack
  is reached.\n          </li>\n          <li>\n              If the entire TensorStack
  is empty of Bits, remove its Record\n              from the TopRegister.\n         </li>\n
  \         <li>\n              If all TensorStacks are empty of Bits, return the
  final Sorted\n              List. Otherwise, re-sort the TopRegister.\n          </li>\n
  \     </ol>\n\n  9. Otherwise (i.e. the top Byte or a Tensor that contains it is
  not empty):\n      <ol>\n          <li>\n              Update the top Byte's (or
  Tensor's) Record with its new TopBit.\n          </li>\n          <li>\n              Re-sort
  the top Byte's (or Tensor's) containing Tensor's\n              Register.\n          </li>\n
  \         <li>\n              Jump up a level to the Tensor that contains that Tensor,
  update\n              the containing Tensor's Record with its new TopBit, and re-sort\n
  \             its Register. Do this recursively until the whole TensorStack is\n
  \             rebalanced.\n          </li>\n          <li>\n              Update
  the TensorStack's Record in the TopRegister with its new\n              TopBit.\n
  \         </li>\n          <li>Re-sort the TopRegister.</li>\n      </ol>\n\n  10.
  Repeat Steps 7-9 until the final Sorted List is returned.\n\nNow that we know all
  the steps, it's easier to see why we randomize the list\nas the beginning step.
  This way, if the list is already nearly sorted, values\nclose to each other don't
  get stuck under each other in their Byte. Ideally, we\nwant the top Bits in all
  the TensorStacks to be close to the same value.\n\nTo illustrate, say that we're
  using a Bytesize of 4 and the first four Bits\nin a list of 1,000,000 to be sorted
  are 121, 122, 123, and 124. If we don't\nrandomize the list, these 4 Bits get grouped
  together in the first Byte.\n\nThat's all well and good if everything performs as
  expected, but if something\nunexpected happens during an operation where we intend
  to add 124 to the final\nlist and we add a different Bit instead, three of the best
  Bits to have\nmistakenly added (121, 122, and 123) are impossible to have been selected.\n\n####
  Benefits\n\nTensort is designed to be adaptable for different purposes. The core
  mechanic\nin Tensort is the breaking down of the input into smaller pieces along
  many\ndimensions to sort the smaller pieces. Once we understand the overall\nstructure
  of Tensort, we can design a SubAlgorithm (and Bytesize) to suit our\nneeds.\n\nStandard
  Tensort leverages the robustness of Bubblesort while reducing runtime\nby never
  Bubblesorting the entire input at once.\n\nWe are able to do this because A) Bubblesort
  is very good at making sure the\nlast element is in the final position of a list,
  and B) at each step in Tensort\nthe only element we *really* care about is the last
  element of a given list (or\nto look at it another way, the TopBit of a given Tensor).\n\n####
  Logarithmic Bytesize\n\nWhen using standard Tensort (i.e. using Bubblesort as the
  SubAlgoritm), as the\nBytesize approaches 1, the length of the input list, or the
  square root of the\nnumber of elements in the input list, its average time efficiency
  approaches\nO(n^2).\n\nStandard Tensort is most time efficient when the Bytesize
  is close to the\nnatural log of the number of elements in the input list. A logarithmic
  Bytesize\nis likely to be ideal for most use cases of standard Tensort.\n\n-------\n\nAlright!
  We now have a sorting algorithm absent of cheap hacks that both\nmaintains O(n log
  n) average time efficiency and is relatively robust. I'm\npretty happy with that!\n\nBut
  now that we understand Tensort's basic structure, let's tune it for even\nmore robustness!\n\n<figure>\n
  \   <img src=\"https://m.media-amazon.com/images/M/MV5BNjk2MTMzNTA4MF5BMl5BanBnXkFtZTcwMTM0OTk1Mw@@._V1_.jpg\"\n
  \        alt=\"Michael Caine sitting at a desk in front of a chalkboard full of\n
  \       mathematical formulae and architectural drawings\">\n    <figcaption><i><a
  href=\"https://www.imdb.com/name/nm0000323/mediaviewer/rm3619586816/\">\n            Source\n
  \       </a></i></figcaption>\n</figure>\n\n### Robustsort\n\n#### Preface\n\nIn
  Beyond Efficiency, Ackley augmented Mergesort and Quicksort with what he\ncalled
  \"cheap hacks\" in order to give them a boost in robustness in an attempt\nto get
  them to compare with Bubblesort. This amounted to adding a quorum system\nto the
  unpredictable comparison operator and choosing the most-agreed-upon\nanswer.\n\nI
  agree that adding a quorum for the unpredictable comparison operator is at\nleast
  a post-hoc solution to a known problem. Instead of retrying a specific\ncomponent
  again because we know it to be unpredictable, let's build redundancy\ninto the system
  at the (sub-)algorithmic level. A simple way to do this is by\nasking different
  components the same question and see if they agree.\n\nRobustsort is my attempt
  to make the most robust sorting algorithm possible,\nutilizing some solution-checking
  on the (sub-)algorithmic level while still:\n\n  - Keeping to O(n log n) average
  time efficiency\n\n  - Never re-running a sub-algorithm that is expected to act
  deterministicly\n    on the same arguments looking for a non-deterministic result
  (i.e. expect\n    that if a component gives a wrong answer, running it again the
  same way\n    won't somehow yield a right answer)\n\n  - Using a minimal number
  of different sub-algorithms (i.e. don't just use\n    every sorting algorithm that
  comes to mind and compare all their results)\n\nWith those ground rules in place,
  let's get to Robustsort!\n\n#### Overview\n\nOnce we have Tensort in our toolbox,
  the road to Robustsort is not long.\n\nRobustsort is a potentially recursive version
  of Tensort, but first we'll look\nat the basic variant: a 3-Bit Tensort with a custom
  SubAlgorithm that compares\nother sub-algorithms. For convenience, we will call
  this custom SubAlgorithm\nSupersort. We use a 3-Bit Tensort here because there's
  something magical that\nhappens around the number 3.\n\nRobust sorting algorithms
  tend to be slow. Bubblesort, for example, having an\naverage time efficiency of
  O(n^2), is practically glacial compared with\nQuicksort and Mergesort (which both
  have an average of O(n log n)).\n\nHere's the trick though: with small numbers the
  difference between these values\nis minimal. For example, when n=4, Mergesort will
  make 6 comparisons, while\nBubblesort will make 12. A Byte holding 4 Bits is both
  small enough to run the\nBubblesort quickly and large enough to allow multiple opportunities
  for a\nmistake to be corrected.\n\nIn Robustsort we choose a Bytesize of 3 because
  a list of 3 Bits has some\nspecial properties. For one thing, sorting at this length
  greatly reduces the\ntime it takes to run our slow-but-robust algorithms. For example,
  at this size,\nBubblesort will make only 6 comparisons. Mergesort still makes 6
  as well.\n\nFurthermore, when making a mistake while sorting a list of 3 elements,
  the\nmistake will displace an element by only 1 or 2 positions at most, no matter\nwhich
  algorithm is used.\n\nThis is all to say that using a 3-Bit Bytesize allows us to
  have our pick of\nsub-algorithms to compare with!\n\n#### Examining Bubblesort\n\nBefore
  moving further, let's talk a little about Bubblesort and why we're\nusing it in
  our SubAlgorithm.\n\nWe've said before that Bubblesort is likely to put the last
  element in the\ncorrect position of a list. Let's examine this in the context of
  Bubblesorting\na 3-element list.\n\nI ran Bubblesort 1000 times on random permutations
  of [1,2,3] using a faulty\ncomparator that gives a random result 10% of the time
  when comparing two\nelements. Here is how often each outcome was returned:\n\n    94.1%
  <- [1,2,3]\n\n    2.5% <- [1,3,2]\n\n    3.0% <- [2,1,3]\n\n    0.0% <- [2,3,1]\n\n
  \   0.4% <- [3,1,2]\n\n    0.0% <- [3,2,1]\n\nIn these results, 97.1% of the time
  the TopBit was returned in the correct\nposition. The only results returned in which
  the TopBit was not in the correct\nposition were [1,3,2] and [3,1,2].\n\n#### Rotationsort\n\nWhen
  choosing an algorithm to compare with Bubblesort, we want something with\nsubstantially
  different logic, for the sake of robustness. We do, however, want\nsomething similar
  to Bubblesort in that it compares our elements multiple\ntimes. And as mentioned
  above, the element that is most important to our\nsorting is the last (i.e. highest
  value) element, by a large degree.\n\nIn terms of the probability of different outcomes,
  if our algorithm returns\nan incorrect result, we want that result to be different
  than what Bubblesort\nis likely to return.\n\nKeeping these priorities in mind,
  the algorithm we will use to compare with\nBubblesort is Rotationsort.\n\nThe steps
  in Rotationsort are relatively simple:\n\n  1. Compare the last element with the
  first element. If the last element is\n     smaller, move it to the beginning of
  the list and repeat Step 1.\n\n  2. Compare the first two elements. If the second
  element is smaller, move it\n     to the beginning of the list and return to Step
  1.\n\n  3. Compare the second and third elements. If the third element is smaller,\n
  \    move it to the beginning of the list and return to Step 1.\n\n  4. Continue
  on in this fashion until the end of the list is reached.\n\n  5. Return the sorted
  list.\n\nThe version we use here will be a Reverse Rotationsort. Instead of starting
  at\nthe beginning of the list and working forward, moving lower-value elements back\nto
  the beginning, a Reverse Rotationsort starts at the end and works backward, \nmoving
  higher-value elements to the end. We do this because it yields a more\nfavorable
  spread of results to combine with Bubblesort than a Forward\nRotationsort does.\n\nHere
  are the results of running (Reverse) Rotationsort 1000 times on random\npermutations
  of [1,2,3] using a faulty comparator that gives a random result\n10% of the time
  when comparing two elements:\n\n    95.3% <- [1,2,3]\n\n    1.5% <- [1,3,2]\n\n
  \   3.1% <- [2,1,3]\n\n    0.1% <- [2,3,1]\n\n    0.0% <- [3,1,2]\n\n    0.0% <-
  [3,2,1]\n\nIn these results, 98.4% of the time the TopBit was returned in the correct\nposition
  The only results returned in which the TopBit was not in the correct\nposition were
  [1,3,2] and [2,3,1].\n\nYou may notice that one of the two problematic results returned
  ([2,3,1]) was\nnever returned by Bubblesort. In turn, Bubblesort returned one result
  ([3,1,2])\nthat Rotationsort did not. This doesn't mean that these algorithms will
  never\nreturn these results, but the chances of them doing so are very low.\n\nOverall,
  there is a modest probability (about 0.04% according to these results)\nthat Bubblesort
  and Rotationsort will agree on [1,3,2] as the result, but it is\nvery unlikely that
  they will agree on any other result that does not have the\nTop Bit in the correct
  position.\n\n##### A note about [1,3,2]\n\nYou may notice that the most common problematic
  result returned by both\nBubblesort and Rotationsort is [1,3,2]. Wouldn't it be
  better to compare with\nan algorithm that doesn't return this result as often?\n\nIt
  would. It seems, however, that any sorting algorithm which has [1,2,3] and\n[2,1,3]
  as its most common results also has [1,3,2] as its third most common.\nThis may
  be inevitable due to [2,1,3] and [1,3,2] being only one adjacent\nelement swap away
  from [1,2,3].\n\nI came up with Rotationsort while attempting to discover a robust
  sorting\nalgorithm that prioritizes non-adjacent swaps (compare\n[Circlesort](https://youtu.be/wqibJMG42Ik?feature=shared&t=222)).
  If anyone\nfinds an algorithm that is comparable with Bubblesort and Rotationsort
  in terms\nof both accuracy in determining the TopBit and adhering to the general
  rules of\nthis project while returning something besides [1,3,2] as its third most
  common\nresult, [I'd love to hear about it](#contact)!\n\n\n      \n\n<figure>\n
  \   <img src=\"https://m.media-amazon.com/images/M/MV5BMjE3NjgyODc4MV5BMl5BanBnXkFtZTcwMDYzMTk2Mw@@._V1_.jpg\"\n
  \        width=\"400\"\n         alt=\"Michael Caine rushing past the Batmobile\">\n
  \   <figcaption><i><a \n        href=\"https://www.imdb.com/name/nm0000323/mediaviewer/rm4040654848/\">\n
  \           Source\n        </a></i></figcaption>\n</figure>\n\n#### Introducing
  Supersort\n\nSupersort is a SubAlgorithm that compares the results of two different\nsorting
  algorithms, in our case Bubblesort and Rotationsort. If both\nalgorithms agree on
  the result, that result is used.\n\nLooking at our analysis of Bubblesort and Rotationsort,
  we can\napproximate the chances that they will agree in similar conditions:\n\n
  \   ~89.68% <- Agree Correctly\n\n    ~10.19% <- Disagree\n\n    ~0.09% <- Agree
  Incorrectly - TopBit correct\n\n    ~0.04% <- Agree Incorectly - TopBit incorrect\n\nHey,
  that's pretty good! If they agree, then return the results from\nRotationsort because
  if for some reason the module that compares the full Bytes\nis also faulty (outside
  the scope of these benchmarks), Rotationsort is more\nlikely to have an accurate
  result.\n\nAround 10% of the time, these sub-algorithms will disagree with each
  other. If\nthis happens, we run our third sub-algorithm: Permutationsort.\n\n####
  Permutationsort\n\nPermutationsort is a simple, brute-force sorting algorithm.\n\nAs
  a first step we generate all the different ways the elements could possibly\nbe
  arranged in the list. Then we loop over this list of permutations until we\nfind
  one that is in the right order.\n\nWe check if a permutation is in the right order
  by comparing the first two\nelements. If the first element is greater, we move to
  the next permutation.\nOtherwise (i.e. the first element is smaller), we compare
  the next two\nelements, and so on until we either find two elements that are out
  of order or\nwe reach the end of the list, confirming that the list is in order.\n\nPermutationsort
  is a good choice for our adjudication algorithm because A) the\nspread of outcomes
  is favorable for our needs and B) it uses logic that is\ncompletely different from
  Bubblesort and Rotationsort. Using different manners\nof reasoning to reach an agreed-upon
  answer increases the robustness of a\nsystem.\n\nHere are the results of running
  Permutationsort 1000 times on random\npermutations of [1,2,3] using a faulty comparator
  that gives a random result\n10% of the time:\n\n    81.9% <- [1,2,3]\n\n    4.1%
  <- [2,1,3]\n\n    4.5% <- [3,1,2]\n\n    5.3% <- [1,3,2]\n\n    3.4% <- [2,3,1]\n\n
  \   0.8% <- [3,2,1]\n\nIn these cases, 86% of the time the Top Bit was in the correct
  position.\nThe least likely outcome is a reverse-sorted Byte and the other possible\nincorrect
  outcomes are in approximately even distribution with each other.\n\n#### Supersort
  Adjudication\n\nSupposing that our results from Bubblesort and Rotationsort disagree
  and we now\nhave our result from Permutationsort, how do we choose which to use?\n\nFirst
  we check to see whether the result from Permutationsort agrees with the\nresults
  from either Bubblesort or Rotationsort. To keep things simple, let's\njust look
  at the raw chances that Permutationsort will agree on results with\nBubblesort or
  Rotationsort.\n\nPermutationsort and Bubblesort:\n\n    ~77.07% <- Agree Correctly\n\n
  \   ~28.13% <- Disagree\n\n    ~0.14% <- Agree Incorrectly - TopBit correct\n\n
  \   ~0.12% <- Agree Incorectly - TopBit incorrect\n\nPermutationsort and Rotationsort:\n\n
  \   ~78.05% <- Agree Correctly\n\n    ~21.74% <- Disagree\n\n    ~0.14% <- Agree
  Incorrectly - TopBit correct\n\n    ~0.07% <- Agree Incorectly - TopBit incorrect\n\nIf
  Permutationsort agrees with either Bubblesort or Rotationsort, then it's\neasy -
  just use that result!\n\nAccording to these results, Permutationsort is likely to
  disagree with both\nBubblesort and Rotationsort about 6.12% of the time if all three
  are run\nindependently. In practice, if Permutationsort is run at all it has a greater\nchance
  than that because in order to reach that point, first either Bubblesort\nor Rotationsort
  must have sorted the list incorrectly, which makes them less\nlikely to agree with
  Permutationsort.\n\nIn any case, if all three sub-algorithms disagree, use the results
  from\nRotationsort.\n\n#### Recursion\n\nYou'll remember that our standard Tensort
  uses a logarithmic Bytesize. Our base\nRobustsort uses a Bytesize of 3, but we can
  use a logarithmic Bytesize by\nadding recursion.\n\n<figure>\n    <img src=\"https://m.media-amazon.com/images/M/MV5BZWUzM2NhMTMtM2U0Yy00MmE4LWI2OGItMWQyZjQ3MmRkMGVlXkEyXkFqcGdeQXVyNTAyODkwOQ@@._V1_.jpg\"\n
  \        alt=\"Michael Caine reaching into a cage to gently retrieve a bird. The\n
  \             cage is in a larger structure of cages. The camera is viewing\n              from
  an adjacent cage and can see into multiple subsequent cages,\n              giving
  the appearance of a recursive picture-in-picture effect\">\n    <figcaption><i><a
  href=\"https://www.imdb.com/name/nm0000323/mediaviewer/rm1461852929/\">\n            Source\n
  \       </a></i></figcaption>\n</figure>\n\n\n      \n\nLet's take our base Robustsort
  example above and make it recursive.\n\nFirst, instead of using a 3-Bit Bytesize,
  we will use a logarithmic Bytesize.\nThen, instead of using our Supersort directly
  as our SubAlgorithm, we will use\nRobustsort itself to sort the records.\n\nAt the
  base case, this Robustsort will have a Bytesize of 3. If the logarithmic\nBytesize
  of the input list is greater than 27, then the SubAlgorithm of the\ntop-level Robustsort
  will be a recursive Robustsort with a logarithmic\nBytesize.\n\nThe number 27 is
  chosen because we want a number that has a natural log that is\nclose to 3 (27's
  is about 3.3) and since 3 ^ 3 = 27, it is easy to sort lists\nof 27 elements in
  groups of 3.\n\nThis recursive version of Robustsort is more tailored to large input
  lists (in\nfact, it doesn't add another layer of recursion until the input list
  is is\nlonger than 500 billion elements), but differences can be noticed when sorting\nsmaller
  lists as well.\n\nWe now have a simple form of Robustsort: a potentially recursive
  Tensort with a\n3-Bit base case using a Supersort adjudicating Bubblesort, Rotationsort,
  and\nPermutationsort as its base SubAlgorithm.\n\nWell that's pretty cool! But I
  wonder... can we make this more robust, if we\nrelax the rules just a little more?\n\nOf
  course we can! And we will. To do so, we will replace Permutationsort with\nanother
  newly-named sorting algorithm: Magicsort!\n\n### Magicsort\n\nFor our most robust
  iteration of Robustsort we will relax the requirement on\nnever re-running the same
  deterministic sub-algorithm in one specific context.\nMagicsort is an algorithm
  that will re-run Permutationsort only if it disagrees\nwith an extremely reliable,
  theoretically non-deterministic algorithm - one\nthat's so good it's robust against
  logic itself...\n\n<figure>\n    <img src=\"https://raw.githubusercontent.com/kaBeech/tensort/main/assets/images/mc_confused.png\"\n
  \        alt=\"Michael Caine and Mike Meyers looking taken aback\">\n    <figcaption><i><a
  href=\"https://www.imdb.com/video/vi3757292825/\">\n            Source\n        </a></i></figcaption>\n</figure>\n\n\n
       \n\n\n...[Bogosort!](https://www.youtube.com/watch?v=kgBjXUE_Nwc&t=583)\n\nMagicsort
  simply runs both Permutationsort and Bogosort on the same input and\nchecks if they
  agree. If they do, the result is used and if not, both\nalgorithms are run again.
  This process is repeated until the two algorithms\nagree on a result.\n\nMagicsort
  is based on the notion that if you happen to pull the right answer\nout of a hat
  once, it might be random chance, but if you do it twice, it might\njust be magic!\n\nObservant
  readers may have already deduced that Permutationsort functions\nnearly identically
  to Bogosort. Here are the results of running Bogosort 1000\ntimes on random permutations
  of [1,2,3] using a faulty comparator that gives a\nrandom result 10% of the time:\n\n
  \   81.3% <- [1,2,3]\n\n    3.0% <- [2,1,3]\n\n    3.8% <- [3,1,2]\n\n    5.8% <-
  [1,3,2]\n\n    5.7% <- [2,3,1]\n\n    0.4% <- [3,2,1]\n\nIn these cases, 84.3% of
  the time the Top Bit was in the correct position.\nEven though both Bogosort and
  Permutationsort were ran with the same random\nseeds, they gave slightly different
  results because their methodology is\nslightly different. Still, the least likely
  outcome for Bogosort is also a\nreverse-sorted Byte and the other possible incorrect
  outcomes are in\napproximately even distribution with each other.\n\nHere are the
  results of running Magicsort 1000 times on random permutations of\n[1,2,3] using
  a faulty comparator that gives a random result 10% of the time\nwhen comparing two
  elements:\n\n    ~94.0% <- [1,2,3] (Correct)\n\n    ~1.5% <- [2,1,3] (Correct TopBit)\n\n
  \   ~1.4% <- [1,3,2] (Incorrect)\n\n    ~1.5% <- [3,1,2] (Incorrect)\n\n    ~1.5%
  <- [2,3,1] (Incorrect)\n\n    ~0.1% <- [3,2,1] (Reverse)\n\nIn total, 95.5% of the
  time we got the TopBit in the correct position, 0.1% of\nthe time we got a reverse-sorted
  list, and the other results are in almost\nexactly even distribution with each other.\n\nYou
  may note that [1,3,2] (the most common problematic result from earlier)\nwas second
  least common result. This is likely a fluke, but it's still pretty\nneat.\n\nThe
  downside here is that Magisort can take a long time to run. Thankfully,\nMagicsort
  will only be run in our algorithm if Bubblesort and Rotationsort\ndisagree on an
  answer, and even then it only has 3 elements to sort. Overall,\nthe Robustsort we're
  building that uses Magicsort will still have an average of\nO(n log n) time efficiency.\n\n####
  Magic Robustsort SubAlgorithm alterations\n\nWe will also make a few adjustments
  to our SubAlgorithms for Magic Robustsort.\n\nFirst, we will make our Reverse Rotationsort
  ambidextrous. This means that after each\nforward comparison (with a chance to rotate
  the smaller element to the front\nof the list), we will make a backward comparison
  (with a chance to rotate the\nlarger element to the back of the list).\n\nSecond,
  we will replace Bubblesort with a Forward Ambidextrous Rotationsort.\n\nFinally,
  we will adjust our adjudication scheme, taking the Forward Ambidextrous\nRotationsort's
  results if there is no agreement within Supersort.\n\n### A note about Mundane Robustsort
  Subalgorithms\n\nIt is perfectly valid to use Bogosort in place of Permutationsort
  in\nRobustsort's standard Supersort SubAlgorithm. It may even be argued that doing\nso
  is more robust, since Bogosort barely even relies on logic. Here are some\nconsiderations
  to keep in mind:\n\n  - Bogosort by nature re-runs on the same input multiple times.
  Depending on\n    viewpoint, this either violates the original rules I set forward
  or is a\n    major benefit\n\n  - In testing, Robustsort with Bogosort tends to
  give more robust results,\n    though Robustsort with Permutationsort tends to run
  slightly faster\n\n  - Permutationsort uses additional space due to computing all
  possible\n    permutations of the input and storing them in a list\n\n  - If Permutaionsort
  incorrectly judges the correct permutation to be\n    incorrect, it must loop back
  over the entire list of permutations again\n    before it has another chance of
  giving the correct result\n\n  - Bogosort could theoretically run forever without
  returning a result, even\n    when no errors occur\n\n## Comparing it all\n\nNow
  let's take a look at how everything compares. Here is a graph showing the\nbenchmarking
  results for average error score for our algorithms:\n\n<figure>\n    <img src=\"https://raw.githubusercontent.com/kaBeech/tensort/b160df72bdd673b37cbf7b8a5b7d0f4d02af9920/assets/images/deck_shuffle_chart_uncensored.svg\"\n
  \        alt=\"When sorting a randomly shuffled deck of cards, Quicksort makes\n
  \       202 positional errors, Mergesort makes 201, Bubblesort makes 4, Tensort\n
  \       makes 51, Mundane Robustsort makes 11, and Magic Robustsort makes 1\">\n</figure>\n\nAs
  shown above, when sorting a randomly shuffled deck of cards, Quicksort makes\n202
  positional errors, Mergesort makes 201, Bubblesort makes 4, Logarithmic\nTensort
  makes 51, Basic Mundane Robustsort with Bogosort adjudicator makes 11,\nand Basic
  Magic Robustsort makes only 1!\n\nI'll note here that the results weren't nearly
  as dramatic when adding in a\nstuck comparator (which gives the same answer it gave
  previously 50% of the\ntime) in addition to the wonky one (which gives a random
  answer 10% of the\ntime). Our Recursive Magic Robustsort made an average of 292
  positional errors\nin these conditions, which well outperformed Mergesort's 747,
  but was still\nbehind Bubblesort's 97.\n\nMore benchmarking data can be found in
  the `data/` directory. Before we wrap\nup, let's look at the runtimes and average
  error scores (with a wonky\ncomparator) for the largest input list (2048) I benchmarked
  before removing\nBubblesort from the comparisons (you may have to scroll to view
  the entire\ninformation):\n\n    ----------------------------------------------------------\n
  \    Algorithm    | Time            | Score    | n = 2048\n     Mergesort    | 0.002706653s
  \   | 319199   |\n     Quicksort    | 0.002206037s    | 269252   |\n     Bubblesort
  \  | 67.229769894s   | 707      |\n     TensortBL    | 0.056649886s    | 34223    |\n
  \    RobustsortP  | 0.036861441s    | 21177    |\n     RobustsortB  | 0.038692015s
  \   | 18025    |\n     RobustsortM  | 0.046679795s    | 3255     |\n     RobustsortRP
  | 0.229615609s    | 15254    |\n     RobustsortRB | 0.22648706s     | 10147    |\n
  \    RobustsortRM | 0.249211013s    | 1824     |\n    ----------------------------------------------------------\n\nWell,
  there it is! I'm pretty happy with the results. What do you think, Sir\nMichael?\n\n<figure>\n
  \   <img src=\"https://raw.githubusercontent.com/kaBeech/tensort/main/assets/images/mc_doors.png\"\n
  \        alt=\"Michael Caine looking upset with Michael Standing\">\n    <figcaption><i><a
  href=\"https://www.imdb.com/video/vi3792027161/\">\n            Source\n        </a></i></figcaption>\n</figure>\n\n##
  Library\n\nThis package provides implementations of the following algorithms wrapped
  for\ninteger sorting:\n\n  - Standard Logarithmic Tensort\n\n  - Basic Robustsort
  with Permutationsort adjudicator\n\n  - Basic Robustsort with Bogosort adjudicator\n\n
  \ - Basic Magic Robustsort\n\n  - Recursive Robustsort with Permutationsort adjudicator\n\n
  \ - Recursive Robustsort with Bogosort adjudicator\n\n  - Recursive Magic Robustsort\n\nIt
  also provides many more algorithms and helper functions wrapped for both Bit\nand
  Record sorting so you can make your own Tensort variants!\n\nCheck the code in `src/`
  or the documentation on Hackage/Hoogle\nfor more details.\n\n## Development Environment\n\nThis
  project is wrapped in a Nix Flake, so it's easy to hack on yourself!\n\nNote that
  (unless otherwise specified) all instructions assume you are in the \nrepository
  root, have Nix installed, and have entered the development shell.\n\n### Entering
  the Dev Shell\n\nNote that these instructions don't make the assumptions listed
  above\n\n  * [Install Nix](https://nixos.org/download/)\n  * [Enable Flakes](https://nixos.wiki/wiki/Flakes)\n
  \ * [Clone this repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository)\n
  \ * Run `nix develop` in the repository root\n\n### Run main test suite (QuickCheck)\n\n
  \ * Run `cabal test`\n\n### Run DocTest\n\n  * Run `cabal repl --with-compiler=doctest`\n\n###
  Print Benchmarking Data\n\n  * [Checkout to the 'benchmarking'\n     branch](https://git-scm.com/docs/git-checkout)\n
  \ * Uncomment the desired benchmarking process(es) in `app/Main.hs`\n  * Tweak any
  settings desired\n  * Run `cabal run`\n\n## Contact\n\nQuestions and feedback are
  welcome!\n\nThe easiest way to contact me is usually via\n[LinkedIn](https://www.linkedin.com/in/kyle-beechly),
  or you can try\n[email](mailto:tensort@kabeech.com).\n\n## Thank you!\n\nThank you
  for reading! I've had so much fun working on this project. I hope\nyou've enjoyed
  our time and that you'll continue thinking about tunable sorting\nand robustness
  in computing.\n\nI'd like to send a special thank you to the following people:\n\n
  \ - [David H. Ackley](https://livingcomputation.com/), obviously\n\n  - [Lu Wilson](https://www.todepond.com/),\n
  \   [Jimmy Miller](https://jimmyhmiller.github.io/), and\n    [Ivan Reese](https://ivanish.ca/)
  of\n    [Future of Coding](https://futureofcoding.org/) (Check it out! They do my\n
  \   favorite tech podcast)\n\n  - The Haskell community at large, specifically the
  \n    [Haskell Subreddit](https://www.reddit.com/r/haskell/) and\n    [Portland
  Has Skill](https://github.com/kabeech/portland-has-skill)\n\n  - Countless family,
  friends, acquaintances, and strangers who've tolerated me\n    blathering on about
  sorting algorithms over the past few months \U0001F499\n"
description-type: markdown
hash: e67455bc77fdc94c98d95e37a652c62712d643628672313bbe5ce9131222185d
homepage: https://github.com/kaBeech/tensort
latest: 1.0.1.1
license-name: MIT
maintainer: contact@kaBeech.com
synopsis: Tunable sorting for responsive robustness and beyond
test-bench-deps:
  QuickCheck: '>=2.14.3 && <2.16'
  base: '>=0'
  mtl: '>=0'
  tensort: '>=0'
