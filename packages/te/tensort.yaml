all-versions:
- 0.1.0.0
- 0.2.0.0
- 0.2.0.1
- 0.2.0.2
- 0.2.0.3
author: Kyle Beechly
basic-deps:
  base: '>=4.3.0.0 && <=4.20.0.1'
  mtl: '>=2.2.2 && <2.4'
  random: '>=1.0.0.3 && <1.3'
  random-shuffle: '>=0.0.4 && <0.1'
  tensort: '>=0'
  time: '>=1.2.0.3 && <1.15'
changelog: |
  # Revision history for tensort

  ## 0.1.0.0 -- 2024-05-30

  * First version. Released to an eager world!

  ## 0.2.0.0 -- 2024-05-31

  * Add Logarithmic Tensort

  * Rename and update Exchangesort

  * Simplify code and structure

  * Cleanup exports

  * Cleanup Types

  * Improve documentation

  * Add to package file

  * Expand supported dependency versions

  * Add tests

  ## 0.2.0.1 -- 2024-06-12

  * Add guards for short lists in input

  * Improve testing

  * Improve documentation

  * Add very basic benchmarking

  ## 0.2.0.2 -- 2024-06-13

  * Cleanup testing and CI

  ## 0.2.0.3 -- 2024-06-16

  * Improve testing compatibility (fix text breaking Stackage build)
changelog-type: markdown
description: "# Tensort [![Hackage](https://img.shields.io/hackage/v/tensort.svg)](https://hackage.haskell.org/package/tensort)\n\nTensort
  is a tensor-based sorting algorithm that is tunable to adjust to \nthe priorities
  of the task at hand.\n\nThis project started as an exploration of what a sorting
  algorithm that \nprioritizes robustness would look like. As such it also describes
  and provides\nimplementations of Robustsort, a group of Tensort variants designed
  to \nprioritize robustness in conditions defined in David H. Ackley's\n[Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf).\n\nNote:
  This project is still under construction. Everything works and according\nto my
  calculations will perform excellently under Ackley's testing conditions.\nStill
  to add: benchmarking to prove how cool it is, documentation \nadditions/revisions,
  memes. There's likely a lot of room for improvement in the\ncode as well.\n\n##
  Table of Contents\n\n- [Introduction](#introduction)\n  - [Inspiration](#inspiration)\n
  \ - [Why?](#why)\n  - [But why would anyone care about this in the first place?](#but-why-would-anyone-care-about-this-in-the-first-place)\n
  \ - [Why Haskell?](#why-haskell)\n- [Project structure](#project-structure)\n- [Algorithms
  overview](#algorithms-overview)\n  - [Tensort](#tensort)\n    - [Preface](#preface)\n
  \   - [Structure](#structure)\n    - [Algorithm](#algorithm)\n    - [What are the
  benefits?](#what-are-the-benefits)\n    - [Logarithmic Tensort](#logarithmic-tensort)\n
  \ - [Robustsort](#robustsort)\n    - [Preface](#preface-1)\n    - [Overview](#overview)\n
  \   - [Examining Bubblesort](#examining-bubblesort)\n    - [Exchangesort](#exchangesort)\n
  \   - [Introducing Supersort](#introducing-supersort)\n    - [Permutationsort](#permutationsort)\n
  \   - [Supersort Adjudication](#supersort-adjudication)\n  - [Magicsort](#magicsort)\n
  \   - [Supersort adjudication with Magic](#supersort-adjudication-with-magic)\n
  \ - [A note on Robustsort and Bogosort](#a-note-on-robustsort-and-bogosort)\n- [Comparing
  it all](#comparing-it-all)\n- [Library](#library)\n\n## Introduction\n\n### Inspiration\n\n
  \ - [Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf) by \n
  \ [David H. Ackley](https://github.com/DaveAckley)\n    \n  - [Beyond Efficiency
  by Dave Ackley](https://futureofcoding.org/episodes/070) \n  by Future of Coding
  ([Lu Wilson](https://github.com/TodePond),\n  [Jimmy Miller](https://github.com/jimmyhmiller),\n
  \ [Ivan Reese](https://github.com/ivanreese))\n\n### Why?\n\nBecause near the end
  of [that podcast episode](https://futureofcoding.org/episodes/070), \n[Ivan](https://github.com/ivanreese)
  said \"Why are we comparing Bubblesort \nversus Quicksort and Mergesort? Well, because
  no one's made Robustsort yet.\"\n\nAnd I thought, \"Why not?\"\n\n### But why would
  anyone care about this in the first place?\n\nWell, a tunable sorting algorithm
  is a really cool thing to have!\n\nThis can have many different uses, one of which
  is prioritizing robustness.\n\n[Ackley](https://www.cs.unm.edu/~ackley/be-201301131528.pdf)
  has some really \ncompelling things to say about why prioritizing robustness is
  important and \nuseful, and I'd highly recommend you read that paper!\n\nOr listen
  to [this podcast](https://futureofcoding.org/episodes/070)!\n\nIf you want my elevator
  pitch, it's because we eventually want to build things\nlike [Dyson Spheres](https://en.wikipedia.org/wiki/Dyson_sphere).
  Doing so will \nlikely involve massively distributed systems being constantly pelted
  by \nradiation. In circumstances like that, robustnesss is key.\n\nAnother example
  I like to consider is artificial cognition. When working \nin a non-deterministic
  system (or a system so complex as to be considered\nnon-deterministic), it can be
  helpful to have systems in place to make sure \nthat the answer we come to is really
  valid.\n\nIncidentally, while I was preparing for this project, we experienced \n[the
  strongest solar storm to reach Earth in 2 decades](https://science.nasa.gov/science-research/heliophysics/how-nasa-tracked-the-most-intense-solar-storm-in-decades/).
  \nI don't know for certain whether the solar activity caused any computer errors,
  \nbut we had some anomalies at work and certainly joked about them being caused
  by\nthe Sun.\n\nAlso during the same period, \n[one of the Internet's root-servers
  glitched out for unexplained reasons](https://arstechnica.com/security/2024/05/dns-glitch-that-threatened-internet-stability-fixed-cause-remains-unclear/).\n\nAs
  Ackley mentions, as a culture we have tended to prioritize correctness and \nefficiency
  to the exclusion of robustness. The rate of our technological \nprogression precludes
  us from continuing to do so.\n\n### Why Haskell?\n\n[Obviously](https://www.youtube.com/shorts/LGZKXZQeEBg).\n\n##
  Project structure\n\n- `src/` contains the Tensort library\n    \n- `app/` contains
  the suite for comparing different sorting algorithms in terms of robustness and
  time efficiency\n\n## Algorithms overview\n\nThis README assumes some general knowledge
  of basic sorting algoritms. If you\nwould like a refresher, I recommend \n[this
  video](https://www.youtube.com/watch?v=kgBjXUE_Nwc) which touches on \nBubblesort,
  MergeSort, and Bogosort, and \n[this video](https://www.youtube.com/watch?v=XE4VP_8Y0BU)
  which discusses\nQuicksort.\n\nIt also assumes you've read \n[Beyond Efficiency](https://www.cs.unm.edu/~ackley/be-201301131528.pdf)
  by \nDavid H. Ackley. Go read it!\n\nPlease note that we will discuss a few algorithms
  that I've either made up or \nam just not familiar with by other names. If any of
  these algorithms have \npreviously been named, please let me know. Prior to this
  project I really \nonly had a rudimentary understanding of Insertionsort, Quicksort,
  Mergesort,\nBubblesort and Bogosort, so it's entirely possible that I've reinvented
  a few \nthings that already exist.\n\nIt also may be helpful to note that this project
  was originally undertaken in\nan endeavor to come up with a solution naively, for
  the practice, before \nresearching other algorithms built to tackle the same problem.
  I did very \nbriefly check out Ackley's \n[Demon Horde Sort](https://www.youtube.com/watch?v=helScS3coAE&t=260s),
  \nbut only enough (about 5 seconds of that video) to verify that it is different
  \nfrom this algorithm. I've been purposefully avoiding learning much about Demon
  \nHorde Sort before publishing v1.0.0.0 of this package, but Ackley is way \nsmarter
  than me so if you do actually want a real, professional approach to \nrobust sorting,
  Demon Horde Sort is likely the place to look.\n\nThe algorithms used here that I
  have made up or renamed are, in order of \nintroduction, Tensort, Robustsort, Permutationsort,
  and Magicsort. Get ready!\n\n### Tensort\n\n#### Preface\n\nTensort is my attempt
  to write the most robust O(n log n) sorting algorithm \npossible while avoiding
  anything that Ackley might consider a \"cheap hack.\" \nMy hope is that it will
  be, if not competitive with Bubblesort in robustness, \nat least a major improvement
  over Quicksort and Mergesort. \n\nAgain, I'm not well-studied in sorting algorithms,
  so this may well be known \nalready under another name. After settling on this algorithm,
  I looked into \nseveral other sorting algorithms for comparison and found a few
  that I think \nare similar - significantly Blocksort, Bucketsort, and Patiencesort.
  If you are \nfamiliar with these algorithms, you may recognize that they each have
  a \nstructure that aids in understanding them.\n\nTensort uses an underlying structure
  as well. We will discuss this structure \nbefore going over the algorithm's actual
  steps. If this doesn't make sense yet,\nfear not!\n\n<!-- [image1] -->\n\n#### Structure\n\n
  \ - Bit <- Element of the list to be sorted\n    \n  - Byte <- List of Bits\n\n
  \ - Bytesize <- Maximum length of a Byte\n    \n  - Tensor <- Tuple of a Register
  list and a Memory list\n    \n  - Memory <- List of Bytes or Tensors contained in
  the current Tensor.\n    \n  - Register <- List of Records referencing each Byte
  or Tensor in Memory\n    \n  - Record <- Tuple of the Address and the TopBit of
  the referenced Byte or Tensor\n    \n  - Address <- Pointer to a Byte or Tensor
  in Memory\n    \n  - TopBit <- Value of the Bit at the top of the stack in a Byte
  or Tensor\n\n  - TensorStack <- A top-level Tensor along with all the Bits, Bytes,
  and Tensors it contains\n    \n  - SubAlgorithm <- The sorting sub-algorithm used
  at various stages\n\nIn Tensort, the smallest unit of information is a Bit. Each
  Bit stores one \nelement of the list to be sorted. A group of Bits is known as a
  Byte. \n\nA Byte is a list of Bits. The maximum length of a Byte is set according
  to an \nargument passed to Tensort. In practice, almost all Bytes will be of maximum
  \nlength until the final steps of Tensort. Several Bytes are grouped together \nin
  a Tensor.\n\nA Tensor is a tuple with two elements: Register and Memory.\n\nMemory
  is the second element in a Tensor tuple. It is a list of Bytes or \nother Tensors.
  The length of this Memory list is equal to the Bytesize.\n\nA Register is the first
  element in a Tensor tuple. It is a list of Records, \neach of which has an Address
  pointing to an element in its Tensor's Memory \nand a copy of the TopBit in the
  referenced element. These Records are arranged \nin the order that the elements
  of the Tensor's Memory are sorted (this will be \nclarified soon).\n\nA TensorStack
  is a top-level Tensor along with all the Bits, Bytes, and \nTensors it contains.
  Once the Tensors are fully built, the total number \nof TensorStacks will equal
  the Bytesize, but before that point there will \nbe many more TensorStacks.\n\nThe
  sorting SubAlgorithm will be used any time we sort something within \nTensort. The
  choice of this SubAlgorithm is very important. For reasons that \nwill become clear
  soon, the SubAlgorithm for Standard Tensort will be \nBubblesort, but the major
  part of Tensort's tunability is  the ability to \nsubstitute another sorting algorithm
  based on current priorities.\n\nNow, on to the algorithm!\n\n#### Algorithm\n\nThe
  first step in Tensort is to randomize the input list. I'll explain why we \ndo this
  in more detail later - for now just know that it's easier for Tensort \nto make
  mistakes when the list is already nearly sorted.\n\n  1. Randomize the input list
  of elements (Bits)\n\n  2. Assemble Bytes by sorting the Bits using the SubAlgorithm.
  After this, we \n    will do no more write operations on the Bits until the final
  steps. Instead, we \n    will make copies of the Bits and sort the copies alongside
  their pointers.\n\n  3. Assemble TensorStacks by creating Tensors from the Bytes.
  Tensors are \n    created by grouping Bytes together (setting them as the Tensor's
  \n    second element), making Records from their top bits, sorting the records,
  and \n    then recording the Pointers from the Records (after being sorted) as the
  \n    Tensor's first element.\n\n  4. Reduce the number of TensorStacks by creating
  a new layer of Tensors from \n    the Tensors created in Step 3. These new Tensors
  are created by grouping \n    the first layer of Tensors together (setting them
  as the new Tensor's \n    second element), making Records from their top Bits, sorting
  the Records, and \n    then recording the Pointers from the Records \n    (after
  being sorted) as the Tensor's first element.\n\n  5. Continue in the same manner
  as in Step 4 until the number of TensorStacks \n    equals the Bytesize\n\n  6.
  Assemble a top Register by Making Records from the Top Bits on each \n    TensorStack
  and sort the Records.\n\n  7. Remove the Top Bit from the top Byte in the top TensorStack
  and add it \n    to the final Sorted List. If the top Byte has more than one But
  in it stll, \n    Re-sort the Byte for good measure (technically this is \n    running
  the algorithm on different arguments - if anyone wants to me about \n    this I'll
  update this README)\n\n  8. If the top Byte in the top TensorStack is empty, remove
  the Record that \n    points to it from its Tensor's Register. If the Tensor is
  empty, remove\n    the Record that points to it from its Tensor's Register. Do this
  recursively \n    until the Tensor is not empty or the top of the TensorStack is
  reached. If the \n    entire TensorStack is empty of Bits, remove its Record from
  the top Register. If \n    all TensorStacks are empty of Bits, return the final
  Sorted List. Otherwise, \n    re-sort the top Register\n\n  9. Otherwise (the top
  Byte (or a Tensor that contains it) is not empty), \n    update the top Byte's (or
  Tensor's) Record with its \n    new Top Bit and re-sort its Tensor's Register. Then
  jump up a level to \n    the Tensor that contains that Tensor and update the top
  Tensor's Record\n    with its new Top Bit and re-sort its Register. Do this recursively
  until\n    the whole TensorStack is rebalanced. Then update the TensorStack's Record
  in the \n    top Register with its new Top Bit and re-sort the top Register.\n\nNow
  that we know all the steps, it's easier to see why we randomize the list\nas the
  beginning step. This way, if the list is already nearly \nsorted, values close to
  each other don't get stuck under each other in their \nByte. Ideally, we want the
  top Bits from all TensorStacks to be close to \neach other. Say for example, the
  first three elements in a 1,000,000-element \nlist are 121, 122, 123, and 124. If
  we don't randomize the list, these 3 \nelements get grouped together in the first
  byte. That's all well and good if \neverything performs as expected, but if something
  unexpected happens \nduring an operation where we intend to add 124 to the final
  list  \nand we add a different element instead, three of the best-case elements
  to have\nmistakenly added (121, 122, and 123) are impossible to have been selected.\n\n####
  What are the benefits?\n\nThe core idea of Tensort is breaking the input into smaller
  pieces along an \never-expanding rank, and sorting the smaller pieces. Once we understand
  the\noverall structure, we can design the SubAlgorithm (and Bytesize) to suit our
  \nneeds.\n\nStandard Tensort leverages the robustness of Bubblesort while reducing
  the time \nrequired by never Bubblesorting the entire input. \n\nWe are able to
  do this because A) Bubblesort is really good at making sure the \nlast element is
  in the final position of a list, and B) at each step of Tensort \nthe only element
  we *really* care about is the last element in a given list \n(or to look at it another
  way, the TopBit of a given Tensor).\n\n#### Logarithmic Tensort\n\nWhen using standard
  Tensort (i.e. using Bubblesort as the SubAlgoritm), as the \nBytesize approaches
  the square root of the number of elements in the \ninput list, its time efficiency
  approaches O(n^2).\n\nStandard Tensort is most time efficient when the Bytesize
  is close \nto the natural log of the number of elements in the input list. A logarithmic
  \nBytesize is likely to be ideal for most use cases of standard Tensort.\n\nAlright!
  Now we have a simple sorting algorithm absent of cheap hacks that is \nboth relatively
  fast and relatively robust. I'm pretty happy with that!\n\n<!-- [image2] -->\n\nNow
  for some cheap hacks!\n\n### Robustsort\n\n#### Preface\n\nIn Beyond Efficiency,
  Ackley augmented Mergesort and Quicksort with what he \ncalled \"cheap hacks\" in
  order to give them a boost in robustness to get them to \ncompare with Bubblesort.
  This amounted to adding a quorum system to the \nunpredictable comparison operator
  and choosing the most-agreed-upon answer. \n\nI agree that adding a quorum for the
  unpredictable comparison operator is a bit \nof a cheap hack, or at least a post-hoc
  solution to a known problem. Instead of \nretrying a specific component again because
  we know it to be unpredictable, \nlet's build redundancy into the system at the
  (sub-)algorithmic level. A simple \nway to do this is by asking different components
  the same question and see if \nthey agree.\n\nRobustsort is my attempt to make the
  most robust sorting algorithm possible \nutilizing some solution-checking on the
  (sub-)algorithmic level while still:\n\n  - Keeping runtime somewhat reasonable\n\n
  \ - Never re-running a sub-algorithm that is expected to act deterministicly \n
  \     on the same arguments looking for a non-deterministic result (i.e. expect
  \n      that if a components gives a wrong answer, running it again won't somehow
  \n      yield a right answer)\n\n  - Using a minimal number of different sub-algorithms
  (i.e. doesn't just \n      use every O(n log n) sorting algorithm I can think of
  and compare all \n      their results)\n\nWith those ground rules in place, let's
  get to Robustsort!\n\n#### Overview\n\nOnce we have Tensort in our toolbox, the
  road to Robustsort is pretty simple. \nRobustsort is a 3-bit Tensort with a custom
  SubAlgorithm that compares other \nsub-algorithms. For convenience, we will call
  this custom SubAlgorithm \nSupersort. We use a 3-bit Tensort here because there's
  something \nmagical that happens around these numbers.\n\nRobust sorting algorithms
  tend to be \nslow. Bubblesort, for example, has an average time efficiency of O(n^2),
  \ncompared with Quicksort and Mergesort, which both have an average of (n log n).\n\nHere's
  the trick though: with small numbers the difference between these values \nis minimal.
  For example, when n=4, Mergesort will make 6 comparisons, while \nBubblesort will
  make 12. A Byte holding 4 Bites is both small enough to run \nthe Bubblesort quickly
  and large enough to allow multiple opportunities for a \nmistake to be corrected.
  Since we don't as much built-in parallelism in \nTensort, it can make sense to weight
  more heavily on the side of making more \nchecks.\n\nIn Robustsort, however, we
  have parallelism built into the Supersort \nSubAlgorithm, so we can afford to make
  less checks during this step. \nWe choose a Bytesize of \n3 because a list of\n3
  Bits has some special properties. For one thing, sorting at \nthis length greatly
  reduces the time it takes to run our slow-but-robust \nalgorithms. For example,
  at this size, Bubblesort will make only 6 comparisons. \nMergesort still makes 6
  as well.\n\nIn addition, when making a mistake while sorting 3 elements, the mistake
  \nwill displace an element by only 1 or 2 positions at the, no matter which \nalgorithm
  is used.\n\nThis is all to say that using a 3-bit byte size allows us to have our
  pick of \nalgorithms to compare with!\n\nNote: One might ask why we don't use a
  Bytesize of 2, since it would be even faster\nand still have the same property of
  displacing an element by only 1 or 2\npositions. Well, how many different algorithms
  can you use to sort 2 elements?\nAt this length, most algorithms function equivalently
  (in terms of the \nsub-operations performed) and in my mind running two such algorithms
  is \nequivalent to re-running a single algorithm (which violates the requirements
  \nof this project).\n\n#### Examining Bubblesort\n\nBefore moving further, let's
  talk a little about Bubblesort, and why we're \nusing it in our SubAlgorithm.\n\nAs
  a reminder, Bubblesort will make an average of 6 comparisons when sorting\na 3-element
  list.\n\nWe've said before that Bubblesort is likely to put the last element in
  the \ncorrect position. Let's examine this in the context of Bubblesorting a \n3-element
  list.\n\nOur implementation of Bubblesort (which mirrors Ackley's) will perform
  three\niterations over a 3-element list. After the second iteration, if everything\ngoes
  as planned, the list will be sorted and the final iteration is an extra\nverification
  step. Therefore, to simplify the analysis, we will consider\nwhat happens with a
  faulty comparator during the final iteration, assuming the\nlist has been correctly
  sorted up to that point.\n\nGiven a Byte of [1,2,3], here are the chances of various
  outcomes from using a \nfaulty comparator that gives a random result 10% of the
  time:\n\n    81% <- [1,2,3] (correct - no swaps made)\n\n    9% <- [2,1,3] (faulty
  first swap)\n\n    9% <- [1,3,2] (faulty second swap)\n\n    1% <- [2,3,1] (faulty
  first and second swap)\n\nIn these cases, 90% of the time the Top Bit will be in
  the correct position, \nand in the other cases it will be off by one position, and
  in no case will the \nByte be reverse sorted.\n\n#### Exchangesort\n\nWhen choosing
  an algorithm to compare with Bubblesort, we want something with \nsubstantially
  different logic, for the sake of robustness. We do, \nhowever, want something similar
  to Bubblesort in that it compares our elements \nmultiple times. And, as mentioned
  above, the element that is most important to \nour sorting is the top (biggest)
  element, by a large degree.\n\nWith these priorities in mind, the comparison algorithm
  we choose shall be \nExchangesort. If you're not familiar with this algorithm, I'd
  recommend\nchecking out [this video](https://youtu.be/wqibJMG42Ik?feature=shared&t=143).
  \n\nThe Exchangesort we use is notable in two ways. Firstly, it is a Reverse \nExchangesort,
  as explained in that video.\n\nSecondly, the algorithm as described in the video
  only compares selected element \nwith elements that appear after (or before, as
  in Reverse Exchangesort) it in \nthe list, swapping them if the compared element
  is larger. This functions \nsimilarly to an optimized Bubblesort where after the
  each round the last \nelement compared that round is no longer compared in following
  rounds. Our \nimplementation will compare the selected element with all other elements
  in the \nlist, swapping them if the element that appears later is larger. Ackley
  \nuses an unoptimized Bubblesort in Beyond Efficiency, so I feel comfortable \nusing
  this variation for our Exchangesort.\n\nExchangesort will also make an average of
  6 comparisons when sorting a\n3-element list.\n\nAs with Bubblesort, Exchangesort
  will perform three iterations over a 3-element\nlist, with the final iteration being
  redundant.\n\nGiven a Byte of [1,2,3], here are the chances of various outcomes
  from using a \nfaulty comparator that gives a random result 10% of the time:\n\n
  \   81% <- [1,2,3] (correct - no swaps made)\n\n    9% <- [2,1,3] (faulty first
  swap)\n\n    9% <- [3,2,1] (faulty second swap)\n\n    1% <- [3,1,2] (faulty first
  and second swap)\n\nIn these cases, 90% of the time the Top Bit will have the correct
  value. \nNotably there is a 9% chance that the Byte will be reverse sorted, but
  we will \nexploit this trait later on in the Supersort SubAlgorithm. Note also that
  the \nonly possible outcomes shared between this example and the Bubblesort example\nare
  the correct outcome and [2,1,3], which retains the TopBit with the correct \nvalue.\n\n####
  Introducing Supersort\n\nSupersort is a SubAlgorithm that compares the results of
  two different\nsorting algorithms, in our case Bubblesort and Exchangesort. If both
  \nalgorithms agree on the result, that result is used. \n\nLooking at our analysis
  on Bubblesort and Exchangesort, we can \napproximate the chances of various outcomes
  when comparing the results of \nrunning these two algorithms in similar conditions:\n\n
  \   65.61% <- [1,2,3], [1,2,3] (Agree Correctly)\n\n    7.29% <- [1,2,3], [2,1,3]
  (Disagree - TopBit agrees correctly)\n\n    7.29% <- [1,2,3], [3,2,1] (Disagree
  Fully)\n\n    7.29% <- [2,1,3], [1,2,3] (Disagree - TopBit agrees correctly)\n\n
  \   7.29% <- [1,3,2], [1,2,3] (Disagree Fully)\n\n    0.81% <- [2,1,3], [2,1,3]
  (Agree Incorrectly - TopBit correct)\n\n    0.81% <- [2,1,3], [3,2,1] (Disagree
  Fully)\n\n    0.81% <- [1,3,2], [2,1,3] (Disagree Fully)\n\n    0.81% <- [1,3,2],
  [3,2,1] (Disagree Fully)\n\n    0.09% <- [2,1,3], [3,1,2] (Disagree Fully)\n\n    0.09%
  <- [1,3,2], [3,1,2] (Disagree - TopBit agrees incorrectly)\n\n    0.09% <- [2,3,1],
  [2,1,3] (Disagree Fully)\n  \n    0.09% <- [2,3,1], [3,2,1] (Disagree - TopBit agrees
  incorrectly)\n\n    0.01% <- [2,3,1], [3,1,2] (Disagree Fully)\n\nIn total, that
  makes:\n\n    65.61% <- Agree Correctly\n\n    17.2% <- Disagree Fully\n\n    14.58%
  <- Disagree - TopBit agrees correctly\n\n    0.81% <- Agree Incorrectly - TopBit
  correct\n\n    0.18% <- Disagree - TopBit agrees incorrectly\n\n    [no outcome]
  <- Agree with TopBit incorrect\n\nThe first thing that might stand out is that around
  34% of the time, these \nsub-algorithms will disagree with each other. What happens
  then?\n\nWell, in that case we run a third sub-algorithm to compare the results
  with: \nPermutationsort.\n\n#### Permutationsort\n\nPermutationsort is a simple,
  brute-force sorting algorithm. As a first step we \ngenerate all the different ways
  the elements could possibly be arranged in the \nlist. Then we loop over this list
  of permutations until we find one that is in \nthe right order. We check if a permutation
  is in the right order by comparing\nthe first two elements, if they are in the right
  order comparing the next two\nelements, and so on until we either find two elements
  that are out of order or\nwe confirm that the list is in order.\n\nPermutationsort
  will also make an average of 7 comparisons when sorting a \n3-element list. This
  is slightly more than the other algorithms examined but\nit's worth it because A)
  the spread of outcomes is favorable for our needs, and \nB) it uses logic that is
  completely different from Bubblesort and Exchangesort. \nUsing different manners
  of reasoning to reach an agreed-upon answer greatly \nincreases the robustness of
  the system.\n\nGiven a Byte of [1,2,3], here are the chances of various outcomes
  from using a\nfaulty comparator that gives a random result 10% of the time:\n\n
  \   ~68.67% <- [1,2,3] (correct)\n\n    ~7.63% <- [2,1,3] (faulty first comparator)\n
  \ \n    ~7.63% <- [3,1,2] (faulty first comparator)\n\n    ~7.63% <- [1,3,2] (faulty
  second comparator)\n\n    ~7.63% <- [2,3,1] (faulty second comparator)\n\n    ~0.85%
  <- [3,2,1] (faulty first and second comparator)\n\nIn these cases, 76.6% of the
  time the Top Bit will be in the correct position. \nNotably the least likely outcome
  is a reverse-sorted Byte and the other \npossible incorrect outcomes are in even
  distribution with each other.\n\n#### Supersort Adjudication\n\nSupposing that our
  results from Bubblesort and Exchangesort disagree \nand we now have our result from
  Permutationsort, how do we choose which to\nuse?\n\nFirst we check to see whether
  the result from Permutationsort agrees with\nthe results from either Bubblesort
  or Exchangesort. To keep things \nsimple, let's just look at the raw chances that
  \nPermutationsort will agree on results with Bubblesort or Exchangesort.\n\nPermutationsort
  and Bubblesort:\n\n    ~55.62% <- [1,2,3] (Correct)\n\n    ~0.69% <- [2,1,3] (Correct
  TopBit)\n\n    ~0.69% <- [1,3,2] (Incorrect)\n\n    ~0.08% <- [2,3,1] (Incorrect)\n\nPermutationsort
  and Exchangesort:\n\n    ~55.62% <- [1,2,3] (Correct)\n\n    ~0.69% <- [2,1,3] (Correct
  TopBit)\n\n    ~0.08% <- [3,1,2] (Incorrect)\n\n    ~0.08% <- [3,2,1] (Reverse)\n\nAs
  we can see, it is very unlikely that Permutationsort will agree with\neither Bubblesort
  or Exchangesort incorrectly. It is even less likely\nthat they will do so when the
  TopBit is incorrect. However, there are many \ncases in which they do not agree,
  so let's handle those.\n\nIf there is no agreed-upon result between these three
  algorithms, we will look \nat the top bit only.\n\nFirst we check if the results
  from Bubblesort and Exchangesort agree on the \nTopBit. This is because the chance
  is very unlikely \n(0.18%) that they will agree on an incorrect TopBit. If they
  do agree, we use \nthe result from Bubblesort (as it will not return a reverse-sorted
  list).\n\nIf they do not agree, we will check the TopBit results from Bubblesort
  and \nPermutationsort. This is because it is unlikely \n(~0.92%) that they will
  agree on an incorrect TopBit, and the chance of them \nincorrectly agreeing on the
  highest Bit as the TopBit is even lower (~0.16%). \nIf they do agree, we use the
  result from Bubblesort.\n\nIf they do not agree, we will check the TopBit results
  from Exchangesort \nand Permutationsort. The chance that they will agree on an \nincorrect
  TopBit is about 1.55%, with the chances of them incorrectly agreeing\non the highest
  Bit as the TopBit also around 0.16%. If they do agree, we use\nthe result from Exchangesort.\n\nIf
  after all this adjudication we still do not have an agreed-upon result, we\nwill
  use the result from Bubblesort.\n\nNow obviously we have made some approximations
  in our analysis (and I may have\nmade some mistakes in my calculations), but in
  general I think we can conclude \nthat it is very unlikely that this Supersort process
  will return an incorrect \nresult, and that if an incorrect result is returned,
  it is very likely to still \nhave a correct TopBit.\n\nWe now have the basic form
  of Robustsort: a 3-bit Tensort with a Supersort \nadjudicating Bubblesort, Exchangesort,
  and Permutationsort as its\nSubAlgorithm.\n\nWell that's pretty cool! But I wonder...
  can we make this more robust, if \nwe relax the rules just a little more?\n\n<!--
  (image3) -->\n\nOf course we can! And we will. To do so, we will simply replace
  Permutationsort\nwith another newly-named sorting algorithm: Magicsort!\n\n### Magicsort\n\nFor
  our most robust iteration of Robustsort we will relax the requirement on\nnever
  re-running the same deterministic sub-algorithm in one specific context.\nMagicsort
  is an algorithm that will re-run Permutationsort only if it disagrees \nwith an
  extremely reliable algorithm algorithm - one that's so good it's robust \nagainst
  logic itself...\n\n<!-- (image4) -->\n\nBogosort!\n\n<!-- (image5) -->\n\nMagicsort
  simply runs both Permutationsort and Bogosort on the same input and \nchecks if
  they agree. If they do, the result is used and if not, both \nalgorithms are run
  again. This process is repeated until the two algorithms\nagree on a result.\n\nStrong-brained
  readers may have already deduced that Permutationsort functions\nnearly identically
  to Bogosort. Indeed, their approximate analysis results are\nthe same. Magicsort
  is based on the idea that if you happen to pull the right \nanswer out of a hat
  once, it might be random chance, but if you do it twice,\nit might just be magic!\n\nGiven
  a Byte of [1,2,3], here are the approximate chances of various outcomes \nfrom Magicsort
  using a faulty comparator that gives a random result 10% of the \ntime:\n\n    ~95.27%
  <- [1,2,3] (Correct)\n\n    ~1.18% <- [2,1,3] (Correct TopBit)\n\n    ~1.18% <-
  [1,3,2] (Incorrect)\n\n    ~1.18% <- [3,1,2] (Incorrect)\n\n    ~1.18% <- [2,3,1]
  (Incorrect)\n\n    ~0.02% <- [3,2,1] (Reverse)\n\nThe downside here is that Magisort
  can take a long time to run. I don't know \nhow many comparisons are made on average,
  but it's well over 14.\n\nThankfully, Magicsort will only be run in our algorithm
  if Bubblesort and\nExchangesort disagree on an answer. Overall the Robustsort we're
  building that \nuses Magicsort will still have an average of O(n log n) time efficiency.\n\n####
  Supersort adjudication with Magic\n\nSince we have replaced Permutationsort with
  Magicsort (which is far more robust \nthan Bubblesort or Exchangesort), we will
  adjust our adjudication\nwithin the Supersort SubAlgorithm.\n\nIf Bubblesort and
  Exchangesort disagree, we will run Magicsort on the\ninput. If Magicsort agrees
  with either Bubblesort or Exchangesort, we\nwill use the result from Magicsort.
  Otherwise, if Magicsort agrees on the \nTopBit with either Bubblesort or Exchangesort,
  we will use the result\nfrom Magicsort. Otherwise, if Bubblesort and Exchangesort
  agree on the\nTopBit, we will use the result from Bubblesort.\n\nIf no agreement
  is reached at this point, we abandon all logic and just use\nMagicsort.\n\n### A
  note on Robustsort and Bogosort\n\nIt is perfectly valid to use Bogosort in place
  of Permutationsort in Robustsort's \nstandard Supersort SubAlgorithm. It may be
  argued that doing so is even more \nrobust, since it barely even relies on logic.
  Here are some considerations to\nkeep in mind:\n\n  - Permutationsort uses additional
  space and may take slightly longer on average \n      due to computing all possible
  permutations of the input and storing them in a \n      list.\n\n  - Bogosort could
  theoretically run forever without returning a result, even \n      when no errors
  occur.\n  \n## Comparing it all\n\nNow let's take a look at how everything compares.
  Here is a graph showing the \nbenchmarking results in both in both robustness and
  time efficiency for \nQuicksort, Mergesort, Standard Logarithmic Tensort, Robustsort
  (Permutations), \nRobustsort (Bogo), Robustsort (Magic), and Bubblesort:\n\n...Coming
  Soon!\n\n## Library\n\nThis package contains implementations of each algorithm discussed
  above. \nNotably, it provides the following:\n\n  - Customizable Tensort\n\n  -
  Standard Logarithmic Tensort\n\n  - Standard Tensort with customizable Bytesize\n\n
  \ - Mundane Robustsort with Permutationsort adjudicator\n\n  - Mundane Robustsort
  with Bogosort adjudicator\n\n  - Magic Robustsort\n\nCheck the code in `src/` or
  the documentation on Hackage/Hoogle\nfor more details.\n"
description-type: markdown
hash: cb80592f445f3e15038447b7289d80b80424c4958e96209d30a23d91fa1ad4f3
homepage: https://github.com/kaBeech/tensort
latest: 0.2.0.3
license-name: MIT
maintainer: contact@kaBeech.com
synopsis: Tunable sorting for responsive robustness and beyond!
test-bench-deps:
  QuickCheck: '>=2.14.3 && <2.16'
  base: '>=0'
  mtl: '>=0'
  tensort: '>=0'
