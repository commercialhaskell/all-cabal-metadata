all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.2
- 0.1.0.3
- 0.2.0.0
- 0.2.0.1
- 0.2.0.2
- 0.3.0.0
- 0.3.0.1
- 0.3.0.2
- 0.3.0.3
- 0.3.0.4
- 0.3.1.1
- 0.3.1.2
- 0.3.2.0
- 0.3.3.0
- 0.3.3.1
- 0.3.3.2
author: Michael Chavinda
basic-deps:
  array: ^>=0.5
  attoparsec: '>=0.12 && <0.15'
  base: '>=4 && <5'
  bytestring: '>=0.11 && <0.13'
  bytestring-lexing: '>=0.5 && <0.6'
  containers: '>=0.6.7 && <0.9'
  dataframe: ^>=0.3
  directory: '>=1.3.0.0 && <2'
  granite: ^>=0.3
  hashable: '>=1.2 && <2'
  process: ^>=1.6
  random: '>=1 && <2'
  snappy-hs: ^>=0.1
  template-haskell: '>=2.0 && <3'
  text: '>=2.0 && <3'
  time: '>=1.12 && <2'
  vector: '>=0.13 && <0.14'
  vector-algorithms: ^>=0.9
  zstd: '>=0.1.2.0 && <0.2'
changelog: "# Revision history for dataframe\n\n## 0.3.3.2\n* Update documentation
  on both readthedocs and hackage.\n\n## 0.3.3.1\n* Fix bug in `randomSplit` causing
  two splits to overlap.\n\n## 0.3.3.0\n* Better error messaging for expression failures.\n*
  Fix bug where exponentials were not being properly during CSV parsing.\n* `toMatrix`
  now returns either an exception or the a vector of vector doubles.\n* Add `sample`,
  `kFolds`, and `randomSplit` to sample dataframes.\n\n## 0.3.2.0\n* Fix dataframe
  semigroup instance. Appending two rows of the same name but different types now
  gives a row of `Either a b` (work by @jhrcek).\n* Fix left expansion of semigroup
  instance (work by @jhrcek). \n* Added `hasElemType` function that can be used with
  `selectBy` to filter columns by type. E.g. `selectBy [byProperty (hasElemType @Int)]
  df.`\n* Added basic support for program synthesis for feature generation (`synthesizeFeatureExpr`)
  and symbolic regression (`fitRegression`).\n* Web plotting doesn't embed entire
  script anymore.\n* Added `relu`, `min`, and `max` functions for expressions.\n*
  Add `fromRows` function to build a dataframe from rows. Also add `toAny` function
  that converts a value to a dynamic-like Columnable value.\n* `isNumeric` function
  now recognises `Integer` types.\n* Added `readCsvWithOpts` function that allows
  read specification.\n* Expose option to specify data formats when parsing CSV.\n*
  Added setup script for Hasktorch example.\n\n\n## 0.3.1.2\n* Update granite version,
  again, for stackage.\n\n## 0.3.1.1\n* Aggregation now works on expressions rather
  than just column references.\n* Export writeCsv\n* Loosen bounds for dependencies
  to keep library on stackage.\n* Add `filterNothing` function that returns all empty
  rows of a column.\n* Add `IfThenElse` function for conditional expressions.\n* Add
  `synthesizeFeatureExpr` function that does a search for a predictive variable in
  a `Double` dataframe.\n\n## 0.3.1.0\n* Add new `selectBy` function which subsumes
  all the other select functions. Specifically we can:\n    * `selectBy [byName \"x\"]
  df`: normal select.\n    * `selectBy [byProperty isNumeric] df`: all columns with
  a given property.\n    * `selectBy [byNameProperty (T.isPrefixOf \"weight\")] df`:
  select by column name predicate.\n    * `selectBy [byIndexRange (0, 5)] df`: picks
  the first size columns.\n    * `selectBy [byNameRange (\"a\", \"c\")] df`: select
  names within a range.\n* Cut down dependencies to reduce binary/installation size.\n*
  Add module for web plots that uses chartjs.\n* Web plots can open in the browser.\n\n##
  0.3.0.4\n* Fix bug with parquet reader.\n\n## 0.3.0.3\n* Improved parquet reader.
  The reader now supports most parquet files downloaded from internet sources\n  *
  Supports all primitive parquet types plain and uncompressed.\n  * Can decode both
  v1 and v2 data pages.\n  * Supports Snappy and ZSTD compression.\n  * Supports RLE/bitpacking
  encoding for primitive types\n  * Backward compatible with INT96 type.\n  * From
  the parquet-testing repo we can successfully read the following:\n    * alltypes_dictionary.parquet\n
  \   * alltypes_plain.parquet\n    * alltypes_plain.snappy.parquet\n    * alltypes_tiny_pages_plain.parquet\n
  \   * binary_truncated_min_max.parquet\n    * datapage_v1-corrupt-checksum.parquet\n
  \   * datapage_v1-snappy-compressed-checksum.parquet\n    * datapage_v1-uncompressed-checksum.parquet\n*
  Improve CSV parsing: Parse bytestring and convert to text only at the end. Remove
  some redundancies in parsing with suggestions from @Jhingon.\n* Faster correlation
  computation.\n* Update version of granite that ships with dataframe and add new
  scatterBy plot.\n\n## 0.3.0.2\n* Re-enable Parquet.\n* Change columnInfo to describeColumns\n*
  We can now convert columns to lists.\n* Fast reductions and groupings. GroupBys
  are now a dataframe construct not a column construct (thanks to @stites).\n* Filter
  is now faster because we do mutation on the index vector.\n* Frequencies table nnow
  correctly display percentages (thanks @kayvank)\n* Show table implementations have
  been unified (thanks @metapho-re)\n* We now compute statistics on null columns\n*
  Drastic improvement in plotting since we now use granite.\n\n## 0.3.0.1\n* Temporarily
  remove Parquet support. I think it'll be worth creating a spin off of snappy that
  doesn't rely on C bindings. Also I'll probably spin Parquet off into a separate
  library.\n\n## 0.3.0.0\n* Now supports inner joins\n```haskell\nghci> df |> D.innerJoin
  [\"key_1\", \"key_2\"] other\n```\n* Aggregations are now expressions allowing for
  more expressive aggregation logic. Previously: `D.aggregate [(\"quantity\", D.Mean),
  (\"price\", D.Sum)] df` now ``D.aggregate [(F.sum (F.col @Double \"label\") / (F.count
  (F.col @Double \"label\")) `F.as` \"positive_rate\")]``\n* In GHCI, you can now
  create type-safe bindings for each column and use those in expressions.\n\n```haskell\nghci>
  :exposeColumns df\nghci> D.aggregate  [(F.sum label / F.count label) `F.as` \"positive_rate\"]\n```\n*
  Added pandas and polars benchmarks.\n* Performance improvements to `groupBy`.\n*
  Various bug fixes.\n\n## 0.2.0.2\n* Experimental Apache Parquet support.\n* Rename
  conversion columns (changed from toColumn and toColumn' to fromVector and fromList).\n*
  Rename constructor for dataframe to fromNamedColumns\n* Create an error context
  for error messages so we can change the exceptions as they are thrown.\n* Provide
  safe versions of building block functions that allow us to build good traces.\n*
  Add readthedocs support.\n\n## 0.2.0.1\n* Fix bug with new comparison expressions.
  gt and geq were actually implemented as lt and leq.\n* Changes to make library work
  with ghc 9.10.1 and 9.12.2\n\n## 0.2.0.0\n### Replace `Function` adt with a column
  expression syntax.\n\nPreviously, we tried to stay as close to Haskell as possible.
  We used the explicit\nordering of the column names in the first part of the tuple
  to determine the function\narguments and the a regular Haskell function that we
  evaluated piece-wise on each row.\n\n```haskell\nlet multiply (a :: Int) (b :: Double)
  = fromIntegral a * b\nlet withTotalPrice = D.deriveFrom ([\"quantity\", \"item_price\"],
  D.func multiply) \"total_price\" df\n```\n\nNow, we have a column expression syntax
  that mirrors Pyspark and Polars.\n\n```haskell\nlet withTotalPrice = D.derive \"total_price\"
  (D.lift fromIntegral (D.col @Int \"quantity\") * (D.col @Double\"item_price\"))
  df\n```\n\n### Adds a coverage report to the repository (thanks to @oforero)\nWe
  don't have good test coverage right now. This will help us determine where to invest.\n@oforero
  provided a script to make an HPC HTML report for coverage.\n\n### Convenience functions
  for comparisons\nInstead of lifting all bool operations we provide `eq`, `leq` etc.\n\n##
  0.1.0.3\n* Use older version of correlation for ihaskell itegration\n\n## 0.1.0.2\n*
  Change namespace from `Data.DataFrame` to `DataFrame`\n* Add `toVector` function
  for converting columns to vectors.\n* Add `impute` function for replacing `Nothing`
  values in optional columns.\n* Add `filterAllJust` to filter out all rows with missing
  data.\n* Add `distinct` function that returns a dataframe with distict rows.\n\n##
  0.1.0.1\n* Fixed parse failure on nested, escaped quotation.\n* Fixed column info
  when field name isn't found.\n\n## 0.1.0.0\n* Initial release\n"
changelog-type: markdown
description: |
  <h1 align="center">
    <a href="https://dataframe.readthedocs.io/en/latest/">
      <img width="100" height="100" src="https://raw.githubusercontent.com/mchav/dataframe/master/docs/_static/haskell-logo.svg" alt="dataframe logo">
    </a>
  </h1>

  <div align="center">
    <a href="https://hackage.haskell.org/package/dataframe">
      <img src="https://img.shields.io/hackage/v/dataframe" alt="hackage Latest Release"/>
    </a>
    <a href="https://github.com/mchav/dataframe/actions/workflows/haskel-ci.yml">
      <img src="https://github.com/mchav/dataframe/actions/workflows/haskell-ci.yml/badge.svg" alt="C/I"/>
    </a>
  </div>

  <p align="center">
    <a href="https://dataframe.readthedocs.io/en/latest/">User guide</a>
    |
    <a href="https://discord.gg/XJE5wKT2kb">Discord</a>
  </p>

  # DataFrame

  A fast, safe, and intuitive DataFrame library.

  ## Why use this DataFrame library?

  * Encourages concise, declarative, and composable data pipelines.
  * Static typing makes code easier to reason about and catches many bugs at compile time—before your code ever runs.
  * Delivers high performance thanks to Haskell’s optimizing compiler and efficient memory model.
  * Designed for interactivity: expressive syntax, helpful error messages, and sensible defaults.
  * Works seamlessly in both command-line and notebook environments—great for exploration and scripting alike.

  For an installation guide and tutorials checkout the [project documentation](https://dataframe.readthedocs.io/) and for an API reference checkout the [hackage documentation](https://hackage-content.haskell.org/package/dataframe-0.3.3.2/docs/DataFrame.html).
description-type: markdown
hash: ce7a2c1d2d2111a8d7439b53863b1427c56ec0971d3fa898ab606864da674ed7
homepage: ''
latest: 0.3.3.2
license-name: GPL-3.0-or-later
maintainer: mschavinda@gmail.com
synopsis: A fast, safe, and intuitive DataFrame library.
test-bench-deps:
  HUnit: ^>=1.6
  base: '>=4 && <5'
  criterion: '>=1 && <2'
  dataframe: '>=0.3 && <0.4'
  process: '>=1.6 && <2'
  random: '>=1 && <2'
  random-shuffle: '>=0.0.4 && <1'
  text: '>=2.0 && <3'
  time: '>=1.12 && <2'
  vector: ^>=0.13
