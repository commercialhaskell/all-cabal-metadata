all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.2
- 0.1.0.3
- 0.2.0.0
- 0.2.0.1
- 0.2.0.2
- 0.3.0.0
- 0.3.0.1
author: Michael Chavinda
basic-deps:
  array: '>=0.5 && <0.6'
  attoparsec: '>=0.12 && <=0.14.4'
  base: '>=4.17.2.0 && <4.22'
  bytestring: '>=0.11 && <=0.12.2.0'
  containers: '>=0.6.7 && <0.8'
  directory: '>=1.3.0.0 && <=1.3.9.0'
  filepath: '>=1.0.0.0 && <=1.5.4.0'
  hashable: '>=1.2 && <=1.5.0.0'
  random: '>=1 && <=1.3.1'
  statistics: '>=0.16.2.1 && <0.16.3.0'
  template-haskell: '>=2.0 && <=2.30'
  text: '>=2.0 && <=2.1.2'
  time: '>=1.12 && <=1.14'
  vector: '>=0.13 && <0.14'
  vector-algorithms: '>=0.9 && <0.10'
  zstd: '>=0.1.2.0 && <=0.1.3.0'
changelog: "# Revision history for dataframe\n\n## 0.3.0.1\n* Temporarily remove Parquet
  support. I think it'll be worth creating a spin off of snappy that doesn't rely
  on C bindings. Also I'll probably spin Parquet off into a separate library.\n\n##
  0.3.0.0\n* Now supports inner joins\n```haskell\nghci> df |> D.innerJoin [\"key_1\",
  \"key_2\"] other\n```\n* Aggregations are now expressions allowing for more expressive
  aggregation logic. Previously: `D.aggregate [(\"quantity\", D.Mean), (\"price\",
  D.Sum)] df` now ``D.aggregate [(F.sum (F.col @Double \"label\") / (F.count (F.col
  @Double \"label\")) `F.as` \"positive_rate\")]``\n* In GHCI, you can now create
  type-safe bindings for each column and use those in expressions.\n\n```haskell\nghci>
  :exposeColumns df\nghci> D.aggregate  [(F.sum label / F.count label) `F.as` \"positive_rate\"]\n```\n*
  Added pandas and polars benchmarks.\n* Performance improvements to `groupBy`.\n*
  Various bug fixes.\n\n## 0.2.0.2\n* Experimental Apache Parquet support.\n* Rename
  conversion columns (changed from toColumn and toColumn' to fromVector and fromList).\n*
  Rename constructor for dataframe to fromNamedColumns\n* Create an error context
  for error messages so we can change the exceptions as they are thrown.\n* Provide
  safe versions of building block functions that allow us to build good traces.\n*
  Add readthedocs support.\n\n## 0.2.0.1\n* Fix bug with new comparison expressions.
  gt and geq were actually implemented as lt and leq.\n* Changes to make library work
  with ghc 9.10.1 and 9.12.2\n\n## 0.2.0.0\n### Replace `Function` adt with a column
  expression syntax.\n\nPreviously, we tried to stay as close to Haskell as possible.
  We used the explicit\nordering of the column names in the first part of the tuple
  to determine the function\narguments and the a regular Haskell function that we
  evaluated piece-wise on each row.\n\n```haskell\nlet multiply (a :: Int) (b :: Double)
  = fromIntegral a * b\nlet withTotalPrice = D.deriveFrom ([\"quantity\", \"item_price\"],
  D.func multiply) \"total_price\" df\n```\n\nNow, we have a column expression syntax
  that mirrors Pyspark and Polars.\n\n```haskell\nlet withTotalPrice = D.derive \"total_price\"
  (D.lift fromIntegral (D.col @Int \"quantity\") * (D.col @Double\"item_price\"))
  df\n```\n\n### Adds a coverage report to the repository (thanks to @oforero)\nWe
  don't have good test coverage right now. This will help us determine where to invest.\n@oforero
  provided a script to make an HPC HTML report for coverage.\n\n### Convenience functions
  for comparisons \nInstead of lifting all bool operations we provide `eq`, `leq`
  etc.\n\n## 0.1.0.3\n* Use older version of correlation for ihaskell itegration\n\n##
  0.1.0.2\n* Change namespace from `Data.DataFrame` to `DataFrame`\n* Add `toVector`
  function for converting columns to vectors.\n* Add `impute` function for replacing
  `Nothing` values in optional columns.\n* Add `filterAllJust` to filter out all rows
  with missing data.\n* Add `distinct` function that returns a dataframe with distict
  rows.\n\n## 0.1.0.1\n* Fixed parse failure on nested, escaped quotation.\n* Fixed
  column info when field name isn't found.\n\n## 0.1.0.0\n* Initial release\n"
changelog-type: markdown
description: "<h1 align=\"center\">\n  <a href=\"https://dataframe.readthedocs.io/en/latest/\">\n
  \   <img width=\"100\" height=\"100\" src=\"https://raw.githubusercontent.com/mchav/dataframe/master/docs/_static/haskell-logo.svg\"
  alt=\"dataframe logo\">\n  </a>\n</h1>\n\n<div align=\"center\">\n  <a href=\"https://hackage.haskell.org/package/dataframe-0.2.0.2\">\n
  \   <img src=\"https://img.shields.io/hackage/v/dataframe\" alt=\"hackage Latest
  Release\"/>\n  </a>\n  <a href=\"https://github.com/mchav/dataframe/actions/workflows/haskel-ci.yml\">\n
  \   <img src=\"https://github.com/mchav/dataframe/actions/workflows/haskell-ci.yml/badge.svg\"
  alt=\"C/I\"/>\n  </a>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://dataframe.readthedocs.io/en/latest/\">User
  guide</a>\n  |\n  <a href=\"https://discord.gg/XJE5wKT2kb\">Discord</a>\n</p>\n\n#
  DataFrame\n\nA fast, safe, and intuitive DataFrame library.\n\n## Why use this DataFrame
  library?\n\n* Encourages concise, declarative, and composable data pipelines.\n*
  Static typing makes code easier to reason about and catches many bugs at compile
  time—before your code ever runs.\n* Delivers high performance thanks to Haskell’s
  optimizing compiler and efficient memory model.\n* Designed for interactivity: expressive
  syntax, helpful error messages, and sensible defaults.\n* Works seamlessly in both
  command-line and notebook environments—great for exploration and scripting alike.\n\n##
  Example usage\n\n### Interactive environment\n![Screencast of usage in GHCI](./static/example.gif)\n\nKey
  features in example:\n* Intuitive, SQL-like API to get from data to insights.\n*
  Create typed, completion-ready references to columns in a dataframe using `:exposeColumns`\n*
  Type-safe column transformations for faster and safer exploration.\n* Fluid, chaining
  API that makes code easy to reason about.\n\n### Standalone script example\n```haskell\n--
  Useful Haskell extensions.\n{-# LANGUAGE OverloadedStrings #-} -- Allow string literal
  to be interpreted as any other string type.\n{-# LANGUAGE TypeApplications #-} --
  Convenience syntax for specifiying the type `sum a b :: Int` vs `sum @Int a b'.
  \n\nimport qualified DataFrame as D -- import for general functionality.\nimport
  qualified DataFrame.Functions as F -- import for column expressions.\n\nimport DataFrame
  ((|>)) -- import chaining operator with unqualified.\n\nmain :: IO ()\nmain = do\n
  \   df <- D.readTsv \"./data/chipotle.tsv\"\n    let quantity = F.col \"quantity\"
  :: D.Expr Int -- A typed reference to a column.\n    print (df\n      |> D.select
  [\"item_name\", \"quantity\"]\n      |> D.groupBy [\"item_name\"]\n      |> D.aggregate
  [ (F.sum quantity)     `F.as` \"sum_quantity\"\n                     , (F.mean quantity)
  \   `F.as` \"mean_quantity\"\n                     , (F.maximum quantity) `F.as`
  \"maximum_quantity\"\n                     ]\n      |> D.sortBy D.Descending [\"sum_quantity\"]\n
  \     |> D.take 10)\n\n```\n\nOutput:\n\n```\n------------------------------------------------------------------------------------------\nindex
  |          item_name           | sum_quantity |    mean_quanity    | maximum_quanity\n------|------------------------------|--------------|--------------------|----------------\n
  Int  |             Text             |     Int      |       Double       |       Int
  \     \n------|------------------------------|--------------|--------------------|----------------\n0
  \    | Chicken Bowl                 | 761          | 1.0482093663911847 | 3              \n1
  \    | Chicken Burrito              | 591          | 1.0687160940325497 | 4              \n2
  \    | Chips and Guacamole          | 506          | 1.0563674321503131 | 4              \n3
  \    | Steak Burrito                | 386          | 1.048913043478261  | 3              \n4
  \    | Canned Soft Drink            | 351          | 1.1661129568106312 | 4              \n5
  \    | Chips                        | 230          | 1.0900473933649288 | 3              \n6
  \    | Steak Bowl                   | 221          | 1.04739336492891   | 3              \n7
  \    | Bottled Water                | 211          | 1.3024691358024691 | 10             \n8
  \    | Chips and Fresh Tomato Salsa | 130          | 1.1818181818181819 | 15             \n9
  \    | Canned Soda                  | 126          | 1.2115384615384615 | 4 \n```\n\nFull
  example in `./examples` folder using many of the constructs in the API.\n\n## Installing\n\n###
  Jupyter notebook\n* We have a [hosted version of the Jupyter notebook](https://ihaskell-dataframe-crf7g5fvcpahdegz.westus2-01.azurewebsites.net/lab/)
  on azure sites. This is hosted on Azure's free tier so it slow and is only available
  at best effort.\n* To get started quickly, use the Dockerfile in the [ihaskell-dataframe](https://github.com/mchav/ihaskell-dataframe)
  to build and run an image with dataframe integration.\n* For a preview check out
  the [California Housing](https://ihaskell-dataframe-crf7g5fvcpahdegz.westus2-01.azurewebsites.net/lab/tree/California%20Housing.ipynb)
  notebook.\n\n### CLI\n* Run the installation script `curl '=https' --tlsv1.2 -sSf
  https://raw.githubusercontent.com/mchav/dataframe/refs/heads/main/scripts/install.sh
  | sh`\n* Download the run script with: `curl --output dataframe \"https://raw.githubusercontent.com/mchav/dataframe/refs/heads/main/scripts/dataframe.sh\"`\n*
  Make the script executable: `chmod +x dataframe`\n* Add the script your path: `export
  PATH=$PATH:./dataframe`\n* Run the script with: `dataframe`\n\n\n## What is exploratory
  data analysis?\nWe provide a primer [here](https://github.com/mchav/dataframe/blob/main/docs/exploratory_data_analysis_primer.md)
  and show how to do some common analyses.\n\n## Coming from other dataframe libraries\nFamiliar
  with another dataframe library? Get started:\n* [Coming from Pandas](https://github.com/mchav/dataframe/blob/main/docs/coming_from_pandas.md)\n*
  [Coming from Polars](https://github.com/mchav/dataframe/blob/main/docs/coming_from_polars.md)\n*
  [Coming from dplyr](https://github.com/mchav/dataframe/blob/main/docs/coming_from_dplyr.md)\n\n##
  Supported input formats\n* CSV\n* Apache Parquet (still buggy and experimental)\n\n##
  Future work\n* Apache arrow compatability\n* Integration with common data formats
  (currently only supports CSV)\n* Support windowed plotting (currently only supports
  ASCII plots)\n* Host the whole library + Jupyter lab on Azure with auth and isolation.\n"
description-type: markdown
hash: fa8bbaee7ce1e887fac2e96a36333fe8d21e739e4c13a9221a26eec3e5e10bce
homepage: ''
latest: 0.3.0.1
license-name: GPL-3.0-or-later
maintainer: mschavinda@gmail.com
synopsis: A fast, safe, and intuitive DataFrame library.
test-bench-deps:
  HUnit: ^>=1.6
  base: '>=4.17.2.0 && <4.22'
  criterion: '>=1 && <=1.6.4.0'
  dataframe: '>=0'
  process: '>=1.6'
  random: '>=1 && <=1.3.1'
  random-shuffle: '>=0.0.4'
  text: '>=2.0 && <=2.1.2'
  time: '>=1.12'
  vector: '>=0.13 && <0.14'
