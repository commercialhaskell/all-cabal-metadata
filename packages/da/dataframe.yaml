all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.2
- 0.1.0.3
- 0.2.0.0
- 0.2.0.1
- 0.2.0.2
- 0.3.0.0
- 0.3.0.1
- 0.3.0.2
- 0.3.0.3
- 0.3.0.4
- 0.3.1.1
- 0.3.1.2
- 0.3.2.0
- 0.3.3.0
- 0.3.3.1
- 0.3.3.2
- 0.3.3.3
- 0.3.3.4
- 0.3.3.5
- 0.3.3.6
- 0.3.3.7
- 0.3.3.8
- 0.3.3.9
- 0.3.4.0
- 0.3.4.1
- 0.3.5.0
- 0.4.0.0
author: Michael Chavinda
basic-deps:
  aeson: '>=0.11.0.0 && <3'
  array: '>=0.5.4.0 && <0.6'
  attoparsec: '>=0.12 && <0.15'
  base: '>=4 && <5'
  bytestring: '>=0.11 && <0.13'
  bytestring-lexing: '>=0.5 && <0.6'
  cassava: '>=0.1 && <1'
  containers: '>=0.6.7 && <0.9'
  dataframe: ^>=0.4
  directory: '>=1.3.0.0 && <2'
  filepath: '>=1.4 && <2'
  granite: ==0.3.0.5
  hashable: '>=1.2 && <2'
  mmap: '>=0.5.8 && <=0.5.9'
  parallel: '>=3.2.2.0 && <5'
  process: '>=1.6 && <1.7'
  random: '>=1.3 && <2'
  regex-tdfa: '>=1.3.0 && <2'
  scientific: '>=0.3.1 && <0.4'
  snappy-hs: ^>=0.1
  template-haskell: '>=2.0 && <3'
  text: '>=2.0 && <3'
  time: '>=1.12 && <2'
  unordered-containers: '>=0.1 && <1'
  vector: '>=0.13 && <0.14'
  vector-algorithms: ^>=0.9
  zlib: '>=0.5 && <1'
  zstd: '>=0.1.2.0 && <0.2'
changelog: "# Revision history for dataframe\n\n## 0.4.0.0\n* `readSeparated` no longer
  takes the separator as an argument. This is not placed into readOptions.\n* Some
  improvements to the synthesis demo\n* Add a `declareColumnsParquetFile` function.
  \n* Column conversion functions now take expressions instead of strings.\n* Add
  more monadic functions to make previously tricky transformations easier to write:\n
  \   ```haskell\n    {-# LANGUAGE OverloadedStrings #-}\n    {-# LANGUAGE TemplateHaskell
  #-}\n\n    module Main where\n\n    import qualified DataFrame as D\n    import
  qualified DataFrame.Functions as F\n\n    import DataFrame.Monad\n\n    import Data.Text
  (Text)\n    import DataFrame.Functions ((.&&), (.>=))\n\n    $(F.declareColumnsFromCsvFile
  \"./data/housing.csv\")\n\n    main :: IO ()\n    main = do\n        df <- D.readCsv
  \"./data/housing.csv\"\n        print $ execFrameM df $ do\n            is_expensive
  <- deriveM \"is_expensive\" (median_house_value .>= 500000)\n            meanBedrooms
  <- inspectM (D.meanMaybe total_bedrooms)\n            totalBedrooms <- imputeM total_bedrooms
  meanBedrooms\n            filterWhereM (totalBedrooms .>= 200 .&& is_expensive)\n
  \   ```\n\n## 0.3.5.0\n* Add a `deriveWithExpr` that returns an expression that
  you can use in a subsequent expressions.\n* Add `declareColumnsFromCsvFile` which
  can create the expressions up front for use in scripts.\n    ```haskell\n    import
  qualified DataFrame as D\n    import qualified DataFrame.Functions as F\n\n    import
  Data.Text (Text)\n    import DataFrame.Functions ((.==), (.>=))\n\n    $(F.declareColumnsFromCsvFile
  \"./data/housing.csv\")\n\n    main :: IO ()\n    main = do\n        df <- D.readCsv
  \"./data/housing.csv\"\n        let (df', test) = D.deriveWithExpr \"test\" (median_house_value
  .>= 500000) df\n        print (D.filterWhere test df')\n    ```\n* Fix bounds on
  random.\n* Parquet Column chunks weren't reading properly because we didn't correctly
  calculate the list size.\n* Sum function had a bug where the first number was summed
  twice.\n* Add monadic interface for building dataframe expressions that makes schema
  evolution nice.\n    ```haskell\n    {-# LANGUAGE OverloadedStrings #-}\n    {-#
  LANGUAGE TemplateHaskell #-}\n\n    module Main where\n\n    import qualified DataFrame
  as D\n    import qualified DataFrame.Functions as F\n\n    import DataFrame.Monad\n\n
  \   import Data.Text (Text)\n    import DataFrame.Functions ((.&&), (.>=))\n\n    $(F.declareColumnsFromCsvFile
  \"./data/housing.csv\")\n\n    main :: IO ()\n    main = do\n        df <- D.readCsv
  \"./data/housing.csv\"\n        print $ runFrameM df $ do\n            is_expensive
  <- deriveM \"is_expensive\" (median_house_value .>= 500000)\n            filterWhereM
  is_expensive\n            luxury <- deriveM \"luxury\" (is_expensive .&& median_income
  .>= 8)\n            filterWhereM luxury\n    ```\n* Change order of exponentiation
  to putting the exponent second. It was initially first cause of some internal efficiency
  detail but that's silly.\n* Fix bug where we didn't concat columns from row groups.\n\n##
  0.3.4.1\n* Faster sum operation (now does a reduction instead of collecting the
  vector and aggregating)\n* Update the fixity of comparison operations. Before `(x
  + y) .<= 10`. Now: `x + y ,<= 10`.\n* Revert sort for groupby back to mergesort.\n\n##
  0.3.4.0\n* Fix right join - previously erased some values in the key.\n* Change
  sort API so we can sort on different rows.\n* Add meanMaybe and stddevMaybe that
  work on `Maybe` values.\n* More efficient numeric groupby - use radix sort for indices
  and pre-sort when collecting.\n\n## 0.3.3.9\n* Fix compilation issue for ghc 9.12.*\n\n##
  0.3.3.8\n* More efficient inner joins using hashmaps.\n* Initial JSON lines implementation\n*
  More robust logic when specifying CSV types.\n* Strip spaces from titles and rows
  in CSV reading.\n* Auto parsing bools in CSV.\n* Add `imputeWith`, `bind`, `nRows`,
  `nColumns`, `recodeWitDefault` function that takes \n* Better support for proper
  markdown\n* Fix bug with full outer join.\n* Unify `insertVector` and `insertList`
  functions into insert.\n\n## 0.3.3.7\n* Many functions how rely on expressions (not
  strings).\n* full, left, and right join now implemented.\n* fastCsv now strips quotations
  from text.\n* Add \"NA\" as a nullish pattern.\n* Add bin parameter to terminal
  plotting.\n* Implement filterAllNothing for null handling.\n* Remove behaviour where
  we parse mixed types as `Either`\n* Add `whenPresent`, `whenBothPresent` and `recode`
  functions.\n* Web charts now show on first load.\n* Add deriveMay function for multiple
  column derivations.\n\n## 0.3.3.6\n* Fix bug where doubles were parsing as ints\n*
  Fix bugs where optionals were left in boxed column (instead of optionals)\n* Change
  syntax for conditional operations so it doesn't clash with regular operations.\n\n##
  0.3.3.5\n* Fix parsing logic for doubles. Entire parsing logic is still a work in
  progress.\n* Speed up index selection by using backPermute.\n* Add `mode` function
  to `Functions`.\n* Rewrite some expressions to evaluation more efficient.\n* Show
  correct number of rows in message after truncating for display.\n* Add experimental
  fast CSV parsers (thanks @jhingon)\n* Add support to read dataframes from SQL databases.\n\n##
  0.3.3.4\n* Add linting CI step + fix existing lint errors.\n* Show now only prints
  10 row. To print more you should use the new `display` function that takes the number
  of rows as a parameter in its configuration.\n* Add `toDouble`, `div`, and, `mod`
  functions.\n* Define an `IsString` instance for columns so you can use string literals
  without `F.lit`.\n* Include variance expression.\n* Improved filter performance.\n*
  Make beam search loss function configurable for synthesizing features.\n\n## 0.3.3.3\n*
  Split `toMatrix` into more specific `to<Type>Matrix` functions.\n\n## 0.3.3.2\n*
  Update documentation on both readthedocs and hackage.\n\n## 0.3.3.1\n* Fix bug in
  `randomSplit` causing two splits to overlap.\n\n## 0.3.3.0\n* Better error messaging
  for expression failures.\n* Fix bug where exponentials were not being properly during
  CSV parsing.\n* `toMatrix` now returns either an exception or the a vector of vector
  doubles.\n* Add `sample`, `kFolds`, and `randomSplit` to sample dataframes.\n\n##
  0.3.2.0\n* Fix dataframe semigroup instance. Appending two rows of the same name
  but different types now gives a row of `Either a b` (work by @jhrcek).\n* Fix left
  expansion of semigroup instance (work by @jhrcek). \n* Added `hasElemType` function
  that can be used with `selectBy` to filter columns by type. E.g. `selectBy [byProperty
  (hasElemType @Int)] df.`\n* Added basic support for program synthesis for feature
  generation (`synthesizeFeatureExpr`) and symbolic regression (`fitRegression`).\n*
  Web plotting doesn't embed entire script anymore.\n* Added `relu`, `min`, and `max`
  functions for expressions.\n* Add `fromRows` function to build a dataframe from
  rows. Also add `toAny` function that converts a value to a dynamic-like Columnable
  value.\n* `isNumeric` function now recognises `Integer` types.\n* Added `readCsvWithOpts`
  function that allows read specification.\n* Expose option to specify data formats
  when parsing CSV.\n* Added setup script for Hasktorch example.\n\n\n## 0.3.1.2\n*
  Update granite version, again, for stackage.\n\n## 0.3.1.1\n* Aggregation now works
  on expressions rather than just column references.\n* Export writeCsv\n* Loosen
  bounds for dependencies to keep library on stackage.\n* Add `filterNothing` function
  that returns all empty rows of a column.\n* Add `IfThenElse` function for conditional
  expressions.\n* Add `synthesizeFeatureExpr` function that does a search for a predictive
  variable in a `Double` dataframe.\n\n## 0.3.1.0\n* Add new `selectBy` function which
  subsumes all the other select functions. Specifically we can:\n    * `selectBy [byName
  \"x\"] df`: normal select.\n    * `selectBy [byProperty isNumeric] df`: all columns
  with a given property.\n    * `selectBy [byNameProperty (T.isPrefixOf \"weight\")]
  df`: select by column name predicate.\n    * `selectBy [byIndexRange (0, 5)] df`:
  picks the first size columns.\n    * `selectBy [byNameRange (\"a\", \"c\")] df`:
  select names within a range.\n* Cut down dependencies to reduce binary/installation
  size.\n* Add module for web plots that uses chartjs.\n* Web plots can open in the
  browser.\n\n## 0.3.0.4\n* Fix bug with parquet reader.\n\n## 0.3.0.3\n* Improved
  parquet reader. The reader now supports most parquet files downloaded from internet
  sources\n  * Supports all primitive parquet types plain and uncompressed.\n  * Can
  decode both v1 and v2 data pages.\n  * Supports Snappy and ZSTD compression.\n  *
  Supports RLE/bitpacking encoding for primitive types\n  * Backward compatible with
  INT96 type.\n  * From the parquet-testing repo we can successfully read the following:\n
  \   * alltypes_dictionary.parquet\n    * alltypes_plain.parquet\n    * alltypes_plain.snappy.parquet\n
  \   * alltypes_tiny_pages_plain.parquet\n    * binary_truncated_min_max.parquet\n
  \   * datapage_v1-corrupt-checksum.parquet\n    * datapage_v1-snappy-compressed-checksum.parquet\n
  \   * datapage_v1-uncompressed-checksum.parquet\n* Improve CSV parsing: Parse bytestring
  and convert to text only at the end. Remove some redundancies in parsing with suggestions
  from @Jhingon.\n* Faster correlation computation.\n* Update version of granite that
  ships with dataframe and add new scatterBy plot.\n\n## 0.3.0.2\n* Re-enable Parquet.\n*
  Change columnInfo to describeColumns\n* We can now convert columns to lists.\n*
  Fast reductions and groupings. GroupBys are now a dataframe construct not a column
  construct (thanks to @stites).\n* Filter is now faster because we do mutation on
  the index vector.\n* Frequencies table nnow correctly display percentages (thanks
  @kayvank)\n* Show table implementations have been unified (thanks @metapho-re)\n*
  We now compute statistics on null columns\n* Drastic improvement in plotting since
  we now use granite.\n\n## 0.3.0.1\n* Temporarily remove Parquet support. I think
  it'll be worth creating a spin off of snappy that doesn't rely on C bindings. Also
  I'll probably spin Parquet off into a separate library.\n\n## 0.3.0.0\n* Now supports
  inner joins\n```haskell\nghci> df |> D.innerJoin [\"key_1\", \"key_2\"] other\n```\n*
  Aggregations are now expressions allowing for more expressive aggregation logic.
  Previously: `D.aggregate [(\"quantity\", D.Mean), (\"price\", D.Sum)] df` now ``D.aggregate
  [(F.sum (F.col @Double \"label\") / (F.count (F.col @Double \"label\")) `F.as` \"positive_rate\")]``\n*
  In GHCI, you can now create type-safe bindings for each column and use those in
  expressions.\n\n```haskell\nghci> :exposeColumns df\nghci> D.aggregate  [(F.sum
  label / F.count label) `F.as` \"positive_rate\"]\n```\n* Added pandas and polars
  benchmarks.\n* Performance improvements to `groupBy`.\n* Various bug fixes.\n\n##
  0.2.0.2\n* Experimental Apache Parquet support.\n* Rename conversion columns (changed
  from toColumn and toColumn' to fromVector and fromList).\n* Rename constructor for
  dataframe to fromNamedColumns\n* Create an error context for error messages so we
  can change the exceptions as they are thrown.\n* Provide safe versions of building
  block functions that allow us to build good traces.\n* Add readthedocs support.\n\n##
  0.2.0.1\n* Fix bug with new comparison expressions. gt and geq were actually implemented
  as lt and leq.\n* Changes to make library work with ghc 9.10.1 and 9.12.2\n\n##
  0.2.0.0\n### Replace `Function` adt with a column expression syntax.\n\nPreviously,
  we tried to stay as close to Haskell as possible. We used the explicit\nordering
  of the column names in the first part of the tuple to determine the function\narguments
  and the a regular Haskell function that we evaluated piece-wise on each row.\n\n```haskell\nlet
  multiply (a :: Int) (b :: Double) = fromIntegral a * b\nlet withTotalPrice = D.deriveFrom
  ([\"quantity\", \"item_price\"], D.func multiply) \"total_price\" df\n```\n\nNow,
  we have a column expression syntax that mirrors Pyspark and Polars.\n\n```haskell\nlet
  withTotalPrice = D.derive \"total_price\" (D.lift fromIntegral (D.col @Int \"quantity\")
  * (D.col @Double\"item_price\")) df\n```\n\n### Adds a coverage report to the repository
  (thanks to @oforero)\nWe don't have good test coverage right now. This will help
  us determine where to invest.\n@oforero provided a script to make an HPC HTML report
  for coverage.\n\n### Convenience functions for comparisons\nInstead of lifting all
  bool operations we provide `eq`, `leq` etc.\n\n## 0.1.0.3\n* Use older version of
  correlation for ihaskell itegration\n\n## 0.1.0.2\n* Change namespace from `Data.DataFrame`
  to `DataFrame`\n* Add `toVector` function for converting columns to vectors.\n*
  Add `impute` function for replacing `Nothing` values in optional columns.\n* Add
  `filterAllJust` to filter out all rows with missing data.\n* Add `distinct` function
  that returns a dataframe with distict rows.\n\n## 0.1.0.1\n* Fixed parse failure
  on nested, escaped quotation.\n* Fixed column info when field name isn't found.\n\n##
  0.1.0.0\n* Initial release\n"
changelog-type: markdown
description: "<h1 align=\"center\">\n  <a href=\"https://dataframe.readthedocs.io/en/latest/\">\n
  \   <img width=\"100\" height=\"100\" src=\"https://raw.githubusercontent.com/mchav/dataframe/master/docs/_static/haskell-logo.svg\"
  alt=\"dataframe logo\">\n  </a>\n</h1>\n\n<div align=\"center\">\n  <a href=\"https://hackage.haskell.org/package/dataframe\">\n
  \   <img src=\"https://img.shields.io/hackage/v/dataframe\" alt=\"hackage Latest
  Release\"/>\n  </a>\n  <a href=\"https://github.com/mchav/dataframe/actions/workflows/haskell-ci.yml\">\n
  \   <img src=\"https://github.com/mchav/dataframe/actions/workflows/haskell-ci.yml/badge.svg\"
  alt=\"C/I\"/>\n  </a>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://dataframe.readthedocs.io/en/latest/\">User
  guide</a>\n  |\n  <a href=\"https://discord.gg/8u8SCWfrNC\">Discord</a>\n</p>\n\n#
  DataFrame\n\nA fast, safe, and intuitive DataFrame library.\n\n## Why use this DataFrame
  library?\n\n* Encourages concise, declarative, and composable data pipelines.\n*
  Static typing makes code easier to reason about and catches many bugs at compile
  time—before your code ever runs.\n* Delivers high performance thanks to Haskell’s
  optimizing compiler and efficient memory model.\n* Designed for interactivity: expressive
  syntax, helpful error messages, and sensible defaults.\n* Works seamlessly in both
  command-line and notebook environments—great for exploration and scripting alike.\n\n##
  Features\n- Type-safe column operations with compile-time guarantees\n- Familiar,
  approachable API designed to feel easy coming from other languages.\n- Interactive
  REPL for data exploration and plotting.\n\n## Quick start\nBrowse through some examples
  in [binder](https://mybinder.org/v2/gh/mchav/ihaskell-dataframe/HEAD) or in our
  [playground](https://ulwazi-exh9dbh2exbzgbc9.westus-01.azurewebsites.net/lab).\n\n##
  Install\n\n### Cabal\nTo use the CLI tool:\n```bash\n$ cabal update\n$ cabal install
  dataframe\n$ dataframe\n```\n\nAs a prodject dependency add `dataframe` to your
  <project>.cabal file.\n\n### Stack (in stack.yaml add to extra-deps if needed)\nAdd
  to your package.yaml dependencies:\n```yaml\ndependencies:\n  - dataframe\n```\n\nOr
  manually to stack.yaml extra-deps if needed.\n\n## Example\n\n```haskell\ndataframe>
  df = D.fromNamedColumns [(\"product_id\", D.fromList [1,1,2,2,3,3]), (\"sales\",
  D.fromList [100,120,50,20,40,30])]\ndataframe> df\n------------------\nproduct_id
  | sales\n-----------|------\n   Int     |  Int \n-----------|------\n1          |
  100  \n1          | 120  \n2          | 50   \n2          | 20   \n3          |
  40   \n3          | 30   \n\ndataframe> :exposeColumns df\n\"product_id :: Expr
  Int\"\n\"sales :: Expr Int\"\ndataframe> df |> D.groupBy [F.name product_id] |>
  D.aggregate [F.sum sales `as` \"total_sales\"]\n------------------------\nproduct_id
  | total_sales\n-----------|------------\n   Int     |     Int    \n-----------|------------\n1
  \         | 220        \n2          | 70         \n3          | 70         \n```\n\n##
  Documentation\n* \U0001F4DA User guide: https://dataframe.readthedocs.io/en/latest/\n*
  \U0001F4D6 API reference: https://hackage.haskell.org/package/dataframe/docs/DataFrame.html\n"
description-type: markdown
hash: 5d952e0805853bd7701bf59a17599f6451f9a66397013455bf628e2ab807bb5c
homepage: ''
latest: 0.4.0.0
license-name: GPL-3.0-or-later
maintainer: mschavinda@gmail.com
synopsis: A fast, safe, and intuitive DataFrame library.
test-bench-deps:
  HUnit: ^>=1.6
  base: '>=4 && <5'
  criterion: '>=1 && <2'
  dataframe: '>=0.4 && <0.5'
  process: '>=1.6 && <2'
  random: '>=1 && <2'
  random-shuffle: '>=0.0.4 && <1'
  text: '>=2.0 && <3'
  time: '>=1.12 && <2'
  vector: ^>=0.13
