homepage: https://github.com/DataHaskell/dh-core
changelog-type: markdown
hash: 8f6b4283e3cf057f2310b57c36cae4dfa4dceb545e0b86d36b3527ccd289ad84
test-bench-deps: {}
maintainer: Marco Zocca <ocramz fripost org>
synopsis: Classical data sets for statistics and machine learning
changelog: "0.3\n\t* 'datasets' hosted within the DataHaskell/dh-core project\n\n\t*
  use 'req' for HTTP and HTTPS requests, instead of 'wreq'\n\n\t* Mushroom and Titanic
  datasets\n\n\t* Restructured top-level documentation\n\n\t* Removed 'csvDatasetPreprocess'
  and added 'withPreprocess'. Now bytestring preprocessing is more compositional,
  i.e. 'withPreprocess' can be used with JSON datasets as well.\n\t\n\n0.2.5\n\n\t*
  Old Faithful matches R dataset\n\n0.2.4\n\n\t* Netflix dataset\n\n0.2.3\t\n\n\t*
  Coal dataset\n\n\t* New internal API\n\n\t* Ord instance for IrisClass\n\n0.2.2\n\n\t*
  Enum, Bounded instances for IrisClass\n\n\t* Gapminder dataset\n\n\t* Use wreq for
  HTTP and HTTPS requests\n\n0.2.1\n\n\t* Wine quality datasets\n\n\t* Vocabulary,
  UN, States datasets\n\n\t* CO2, Sunspots and Quakes datasets\n\n0.2.0.3\n\n\t* Further
  GHC portability\n\n0.2.0.2\n\n\t* Improve GHC portability\n\n0.2.0.1\n\n\t* Bugfix:
  include embedded data files in cabal extra-source-files\n\n0.2\n\n\t* iris dataset
  is a pure value (with file-embed)\n\n\t* Michelson, Nightingale and BostonHousing
  datasets\n"
basic-deps:
  bytestring: -any
  base: ! '>=4.6 && <5'
  data-default-class: -any
  time: -any
  text: -any
  stringsearch: -any
  filepath: -any
  req: ! '>=1.0.0 && <2'
  cassava: -any
  hashable: -any
  file-embed: -any
  attoparsec: ! '>=0.13'
  microlens: -any
  aeson: -any
  vector: -any
  directory: -any
all-versions:
- 0.1.0
- 0.1.0.1
- '0.2'
- 0.2.0.1
- 0.2.0.2
- 0.2.0.3
- 0.2.1
- 0.2.2
- 0.2.3
- 0.2.4
- 0.2.5
- 0.3.0
author: Tom Nielsen <tanielsen@gmail.com>
latest: 0.3.0
description-type: haddock
description: |-
  Classical machine learning and statistics datasets from
  the UCI Machine Learning Repository and other sources.

  The @datasets@ package defines two different kinds of datasets:

  * small data sets which are directly (or indirectly with `file-embed`)
  embedded in the package as pure values and do not require network or IO to download
  the data set. This includes Iris, Anscombe and OldFaithful.

  * other data sets which need to be fetched over the network with
  `Numeric.Datasets.getDataset` and are cached in a local temporary directory.

  The @datafiles/@ directory of this package includes copies of a few famous datasets, such as Titanic, Nightingale and Michelson.

  Example :

  > import Numeric.Datasets (getDataset)
  > import Numeric.Datasets.Iris (iris)
  > import Numeric.Datasets.Abalone (abalone)
  >
  > main = do
  >   -- The Iris data set is embedded
  >   print (length iris)
  >   print (head iris)
  >   -- The Abalone dataset is fetched
  >   abas <- getDataset abalone
  >   print (length abas)
  >   print (head abas)
license-name: MIT
