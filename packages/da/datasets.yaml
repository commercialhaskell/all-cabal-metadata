all-versions:
- 0.1.0
- 0.1.0.1
- '0.2'
- 0.2.0.1
- 0.2.0.2
- 0.2.0.3
- 0.2.1
- 0.2.2
- 0.2.3
- 0.2.4
- 0.2.5
- 0.3.0
- 0.4.0
author: Tom Nielsen <tanielsen@gmail.com>
basic-deps:
  JuicyPixels: '>=3.3.3'
  aeson: '>=1.4.2.0'
  attoparsec: '>=0.13'
  base: '>=4.6 && <5'
  bytestring: '>=0.10.8.2'
  cassava: '>=0.5.1.0'
  deepseq: '>=1.4.4.0'
  directory: '>=1.3.3.0'
  exceptions: '>=0.10.0'
  file-embed: '>=0.0.11'
  filepath: '>=1.4.2.1'
  hashable: '>=1.2.7.0'
  microlens: '>=0.4.10'
  mtl: '>=2.2.2'
  mwc-random: '>=0.14.0.0'
  parallel: '>=3.2.2.0'
  req: '>=2.0.0'
  safe-exceptions: '>=0.1.7.0'
  streaming: '>=0.2.2.0'
  streaming-attoparsec: '>=1.0.0'
  streaming-bytestring: '>=0.1.6'
  streaming-cassava: '>=0.1.0.1'
  streaming-commons: '>=0.2.1.0'
  stringsearch: '>=0.3.6.6'
  tar: '>=0.5.1.0'
  text: '>=1.2.3.1'
  time: '>=1.8.0.2'
  transformers: '>=0.5.5.0'
  vector: '>=0.12.0.2'
  zlib: '>=0.6.2'
changelog: "0.4\n\t* Get rid of dependency on 'data-default' (introduced by previous
  versions of 'req')\n\t\n\t* Bump 'req' dependency to 2.0.0 \n0.3\n\t* 'datasets'
  hosted within the DataHaskell/dh-core project\n\n\t* use 'req' for HTTP and HTTPS
  requests, instead of 'wreq'\n\n\t* Mushroom and Titanic datasets\n\n\t* Restructured
  top-level documentation\n\n\t* Removed 'csvDatasetPreprocess' and added 'withPreprocess'.
  Now bytestring preprocessing is more compositional, i.e. 'withPreprocess' can be
  used with JSON datasets as well.\n\t\n\n0.2.5\n\n\t* Old Faithful matches R dataset\n\n0.2.4\n\n\t*
  Netflix dataset\n\n0.2.3\t\n\n\t* Coal dataset\n\n\t* New internal API\n\n\t* Ord
  instance for IrisClass\n\n0.2.2\n\n\t* Enum, Bounded instances for IrisClass\n\n\t*
  Gapminder dataset\n\n\t* Use wreq for HTTP and HTTPS requests\n\n0.2.1\n\n\t* Wine
  quality datasets\n\n\t* Vocabulary, UN, States datasets\n\n\t* CO2, Sunspots and
  Quakes datasets\n\n0.2.0.3\n\n\t* Further GHC portability\n\n0.2.0.2\n\n\t* Improve
  GHC portability\n\n0.2.0.1\n\n\t* Bugfix: include embedded data files in cabal extra-source-files\n\n0.2\n\n\t*
  iris dataset is a pure value (with file-embed)\n\n\t* Michelson, Nightingale and
  BostonHousing datasets\n"
changelog-type: markdown
description: |-
  Classical machine learning and statistics datasets from
  the UCI Machine Learning Repository and other sources.

  The @datasets@ package defines two different kinds of datasets:

  * small data sets which are directly (or indirectly with `file-embed`)
  embedded in the package as pure values and do not require network or IO to download
  the data set. This includes Iris, Anscombe and OldFaithful.

  * other data sets which need to be fetched over the network with
  `Numeric.Datasets.getDataset` and are cached in a local temporary directory.

  The @datafiles/@ directory of this package includes copies of a few famous datasets, such as Titanic, Nightingale and Michelson.

  Example :

  > import Numeric.Datasets (getDataset)
  > import Numeric.Datasets.Iris (iris)
  > import Numeric.Datasets.Abalone (abalone)
  >
  > main = do
  >   -- The Iris data set is embedded
  >   print (length iris)
  >   print (head iris)
  >   -- The Abalone dataset is fetched
  >   abas <- getDataset abalone
  >   print (length abas)
  >   print (head abas)
description-type: haddock
hash: 9bfd5b54c6c5e1e72384a890cf29bf85a02007e0a31c98753f7d225be3c7fa6a
homepage: https://github.com/DataHaskell/dh-core
latest: 0.4.0
license-name: MIT
maintainer: Marco Zocca <ocramz fripost org>
synopsis: Classical data sets for statistics and machine learning
test-bench-deps:
  JuicyPixels: '>=3.3.3'
  QuickCheck: '>=2.12.6.1'
  base: '>=4.6 && <5'
  criterion: '>=1.5.3.0'
  datasets: '>=0'
  deepseq: '>=1.4.4.0'
  directory: '>=1.3.3.0'
  filepath: '>=1.4.2.1'
  hspec: '>=2.6.0'
  mwc-random: '>=0.14.0.0'
  req: '>=2.0.0'
  safe-exceptions: '>=0.1.7.0'
  streaming: '>=0.2.2.0'
