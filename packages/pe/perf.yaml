all-versions:
- 0.1.1
- 0.1.2
- 0.2.0
- 0.3.0
- 0.3.1.0
- 0.3.1.1
- 0.4.0.0
- 0.4.0.1
- 0.4.1.0
- 0.5.0.0
- 0.6.0
- 0.7.0
- 0.8.0
- 0.9.0
- 0.10.0
- 0.10.1
- 0.10.2
- 0.10.3
- 0.11.0.0
- 0.12.0.0
- 0.12.0.1
- 0.13.0.0
- 0.14.0.0
- 0.14.0.1
author: Tony Day, Marco Zocca
basic-deps:
  base: '>=4.14 && <5'
  boxes: '>=0.1.5 && <0.2'
  chart-svg: '>=0.7 && <0.9'
  clock: '>=0.8 && <0.9'
  containers: '>=0.6 && <0.8'
  deepseq: '>=1.4.4 && <1.6'
  formatn: '>=0.2.1 && <0.4'
  mtl: '>=2.2.2 && <2.4'
  numhask-space: '>=0.10 && <0.13'
  optics-core: '>=0.4.1 && <0.5'
  optparse-applicative: '>=0.17 && <0.20'
  perf: '>=0'
  prettychart: '>=0.3 && <0.4'
  prettyprinter: '>=1.7.1 && <1.8'
  recursion-schemes: '>=5.2.2 && <5.3'
  tasty: '>=1.5.2 && <1.6'
  tasty-bench: '>=0.4 && <0.5'
  text: '>=1.2 && <2.2'
  vector: '>=0.12.3 && <0.14'
changelog: |
  0.14
  ===
  * Added charting
  * Added Perf.Chart
  * refactored reportMain
  * expanded ReportOptions
  * added more algorithms to Example
  * refactored Perf.BigO
  * added PerfDumpOptions
  * reportOrg2D ==> report2D
  * added reportBigO
  * added reportTasty'
  * added reportToConsole & parseClock
  * refactored SpaceStats
  * added tickIOWith, timesN & timesNWith
  * removed measureM from Measure
  * added multiN


  0.13
  ===
  * replaced rdtsc with clocks library.

  0.12.0.0
  ===
  * added reportMain and support for executable development.
  * refactored app/perf-explore
  * created app/perf-bench and aded as a `cabal bench` thing.

  0.11.0.0
  ===
  * added Perf.Count
  * GHC 9.6.2 support

  0.10.0
  ===
  * GHC 9.2.1 support
  * inclusion of BigO

  0.9.0
  ===
  * Removed deepseq dependency

  0.8.0
  ===
  * GHC 9.0.1 support
  * internal fixes to remove numhask dependency
changelog-type: markdown
description: "[![img](https://img.shields.io/hackage/v/perf.svg)](https://hackage.haskell.org/package/perf)
  [![img](https://github.com/tonyday567/perf/workflows/haskell-ci.yml/badge.svg)](https://github.com/tonyday567/perf/actions)\n\n\n#
  Features\n\n`perf` is an experimental library with a focus on the low-level empirics
  of Haskell code performance. If you are looking for a quick and reliable performance
  benchmark, criterion and tasty-bench are both good choices. If your results are
  confounding, however, you may need to dig deeper, and this is the problem space
  of `perf`.\n\nThe library:\n\n-   provides a monad transformer, `PerfT`. The criterion
  API tends towards an atomistic approach - bust code up into snippets, copy-paste
  into a bench.hs and measure their isolated performance.  In contrast, with `PerfT`
  performance can be measured within a code snippet&rsquo;s original context. Differing
  code points can be labelled and measured as part of a single run, encouraging a
  much faster observation - experimentation - refactor cycle.\n\n-   is polymorphic
  to what, exactly, is being measured, so that concepts such as counters, debug checks,
  time and space performance can share treatment.\n\n-   attempts to measure big O
  for algorithms that can be defined in terms of input size growth.\n\n-   includes
  live charting of raw performance results via chart-svg and prettychart\n\n\n# Usage\n\nProbably
  the best introduction to `perf` is via the perf-explore executable:\n\n    perf-explore\n\n
  \   label1          label2          old result      new result      change\n    \n
  \   sum             time            9.93e3          7.57e3          improvement\n\nSumming
  [1..1000] took 9,930 nanoseconds, an improvement versus the on file performance
  previously measured.\n\nLive charts of raw performance measurement can be obtained
  via the prettychart library with:\n\n    prettychart-watch --watch --filepath other
  --port 3566\n\n&#x2026; and pointer your browser at localhost:3566\n\n    perf-explore
  -n 1000 --nocheck --chart\n\n![img](other/perf.svg)\n\nIn this particular measure,
  there was an improvement, dropping from about 10,000 nanos to 8,600 nanos. Increasing
  the number of measurements:\n\n    perf-explore -n 20000 --nocheck --chart --chartpath
  other/perf20000.svg\n\n![img](other/perf20000.svg)\n\nImprovements seem to continue
  as n increases before stabilising (after a GC perhaps) at 3,500 nanos\n\n    perf-explore
  -n 20000 --order --nocheck --tasty\n\n    label1          label2          results\n
  \   \n    sum             time            3.51e3\n    \n    sum:time 3.5 * O(N1)\n
  \   tasty:time: 3510\n\nThe order of the computation (`\\l -> fap sum [1 .. l]`)
  is O(N1) and the results are very close to the tasty-bench result.\n\nIn comparsion,
  (\\l -> fap (\\x -> sum [1 .. x]) l):\n\n    perf-explore --nocheck --sumFuse -n
  100000 --chart --chartpath other/perffuse.svg --order\n\n![img](other/perffuse.svg)\n\n
  \   perf-explore --nocheck --sumFuse -n 100000 --order\n\n    label1          label2
  \         results\n    \n    sumFuse         time            6.78e2\n    \n    sumFuse:time
  0.66 * O(N1)\n\n&#x2026; is much faster. Hooray for list fusion!\n\n\n# Issues\n\n\n##
  fragility\n\nResults, especially for simple computations, are fragile and can show
  large variance in performance characteristics in identical runs, and across differing
  compilations. Whether this is due to library flaws or is just the nature of ghc
  is an open question.\n\n\n## Statistics\n\n> Obligatory disclaimer: statistics is
  a tricky matter, there is no one-size-fits-all approach. In the absence of a good
  theory simplistic approaches are as (un)sound as obscure ones. Those who seek statistical
  soundness should rather collect raw data and process it themselves using a proper
  statistical toolbox. Data reported by tasty-bench is only of indicative and comparative
  significance. ~ [tasty-bench](https://hackage.haskell.org/package/tasty-bench-0.4/docs/Test-Tasty-Bench.html#t:Benchmarkable)\n\n>
  variance introduced by outliers: 88% (severely inflated) ~ [criterion](https://hackage.haskell.org/package/criterion)\n\nThe
  library default is to report the 10th percentile as a summary statistic, and this
  is a matter of taste, determined mostly by the purpose of the measurement.\n\n\n##
  ffap and fap\n\n    :t ffap\n\n    ffap\n      :: (Control.DeepSeq.NFData a, Control.DeepSeq.NFData
  b, MonadIO m,\n          Semigroup t) =>\n         Text.Text -> (a -> b) -> a ->
  PerfT m t b\n\nffap and fap are broadly similar to criterion&rsquo;s nf and whnf
  respectively, but passes throught the results of the computation into the monad
  transformer, enabling in-context measurement.\n\nA fine-grained and detailed examination
  of the effect of measurement on laziness and on core details would be beneficial
  to the library.\n\n\n## tasty\n\nThe library was originally developed before tasty-bench,
  which does a great job of integrating into the tasty api, and a future refactor
  may integrate with this, rather than supply idiosyncratic methods.\n\n\n## order\n\nBigOrder
  calculations tend to be fragile and sometimes differ from theory.\n\n\n# Development\n\nThis
  org file has been used to develop and document library innovation and testing, and
  may be of use to users in understanding the library. Note that running `perf` via
  ghci is very slow compared with an external process which accesses the compiled
  version of the library.\n\n    :r\n    :set -Wno-type-defaults\n    :set -Wno-unused-do-bind\n
  \   :set -Wno-name-shadowing\n    :set -XOverloadedStrings\n    :set -XOverloadedLabels\n
  \   import Perf\n    import Perf.Report\n    import Data.FormatN\n    import qualified
  Data.Text as Text\n    import qualified Data.Text.IO as Text\n    import qualified
  Data.Map.Strict as Map\n    import Control.Monad\n    import Data.Bifunctor\n    import
  System.Clock\n    import Data.List qualified as List\n    import Control.Category
  ((>>>))\n    import Optics.Core\n    import Data.Foldable\n    import NumHask.Space\n
  \   putStrLn \"ok\"\n    import Chart hiding (tick)\n    import Prettychart\n    import
  Chart.Examples\n    import Perf.Chart\n    (disp,q) <- startChartServer Nothing\n
  \   disp lineExample\n    import Prettyprinter\n    import Control.Monad.State.Lazy\n
  \   import Text.PrettyPrint.Boxes\n\n    Ok, 11 modules loaded.\n    ok\n    Setting
  phasegrhsc it>o  stun... (poTrrtu e9\n    160) (cgthrcli->c  to quitg)h\n\n    l
  = 1000\n    n = 1000\n    \n    :{\n    p = do\n      ffap \"sum\" sum [1 .. l]\n
  \     ffap \"sumfuse\" (\\x -> sum [1 .. x]) l\n    :}\n    :t p\n    run = runPerfT
  (times n) p\n    :t run\n    (res, m) <- run\n    :t m\n    median . fmap fromIntegral
  <$> m\n\n    ghci| ghci| ghci| ghci| ghci> p :: (MonadIO m, Semigroup t, Control.DeepSeq.NFData
  b, Num b,\n          Enum b) =>\n         PerfT m t b\n    run\n      :: (Control.DeepSeq.NFData
  a, Num a, Enum a) =>\n         IO (a, Map.Map Text.Text [Nanos])\n    m :: Map.Map
  Text.Text [Nanos]\n    fromList [(\"sum\",21978.1),(\"sumfuse\",26710.18)]\n\n\n#
  Details\n\n\n## System.Clock\n\nThe default clock is MonoticRaw for linux & macOS,
  and ThreadCPUTime for Windows.\n\n\n### resolution\n\n    getRes Monotonic\n    getRes
  Realtime\n    getRes ProcessCPUTime\n    getRes ThreadCPUTime\n    getRes MonotonicRaw\n\n
  \   TimeSpec {sec = 0, nsec = 1000}\n    TimeSpec {sec = 0, nsec = 1000}\n    TimeSpec
  {sec = 0, nsec = 1000}\n    TimeSpec {sec = 0, nsec = 42}\n    TimeSpec {sec = 0,
  nsec = 42}\n\n\n## ticks\n\nThe various versions of tick and a variety of algorithms
  are artifacts of ongoing exploration.\n\n    perf-explore -n 20000 --best --ticks\n\n
  \   algo          stepTime   tick tickForce tickForceArgs tickLazy tickWHNF  times
  timesn\n    sumAux          3.11e3 3.11e3    3.11e3        3.11e3   5.13e0   3.11e3
  3.11e3 3.10e3\n    sumCata         3.11e3 3.11e3    3.11e3        3.11e3   5.11e0
  \  3.11e3 3.11e3 3.14e3\n    sumCo           3.11e3 3.11e3    3.11e3        3.11e3
  \  5.06e0   3.11e3 3.11e3 3.08e3\n    sumCoCase       3.11e3 3.11e3    3.11e3        3.11e3
  \  5.11e0   3.11e3 3.11e3 3.08e3\n    sumCoGo         3.11e3 3.11e3    3.11e3        3.11e3
  \  5.06e0   3.11e3 3.11e3 3.12e3\n    sumF            3.48e3 3.49e3    3.46e3        3.46e3
  \  5.06e0   3.48e3 3.48e3 3.48e3\n    sumFlip         3.48e3 3.48e3    3.45e3        3.45e3
  \  5.03e0   3.48e3 3.48e3 3.48e3\n    sumFlipLazy     3.48e3 3.48e3    3.45e3        3.45e3
  \  4.96e0   3.48e3 3.48e3 3.45e3\n    sumFoldr        3.11e3 3.11e3    3.11e3        3.11e3
  \  5.13e0   3.11e3 3.11e3 3.11e3\n    sumFuse         6.54e2 6.54e2    6.54e2        6.54e2
  \  5.17e0   6.54e2 6.54e2 6.39e2\n    sumFuseFoldl'   6.54e2 6.54e2    6.54e2        6.54e2
  \  5.00e0   6.54e2 6.54e2 6.44e2\n    sumFuseFoldr    9.93e2 9.92e2    9.92e2        9.92e2
  \  5.13e0   9.92e2 9.93e2 9.63e2\n    sumFusePoly     6.56e2 6.56e2    6.56e2        6.56e2
  \  5.12e0   6.56e2 6.57e2 6.47e2\n    sumLambda       3.48e3 3.49e3    3.48e3        3.48e3
  \  5.12e0   3.48e3 3.48e3 3.55e3\n    sumMono         3.48e3 3.48e3    3.46e3        3.46e3
  \  5.00e0   3.48e3 3.48e3 3.50e3\n    sumPoly         3.62e3 3.49e3    3.54e3        3.56e3
  \  5.04e0   3.71e3 3.62e3 3.70e3\n    sumSum          3.48e3 3.49e3    3.48e3        3.48e3
  \  4.98e0   3.48e3 3.48e3 3.49e3\n    sumTail         3.48e3 3.49e3    3.45e3        3.45e3
  \  5.00e0   3.48e3 3.48e3 3.51e3\n    sumTailLazy     3.48e3 3.48e3    3.45e3        3.45e3
  \  5.16e0   3.48e3 3.48e3 3.49e3\n\n\n## Time\n\n\n### What is a tick?\n\nA fundamental
  operation of Perf.Time is tick, which sandwiches a (strict) function application
  between two readings of a clock, and returns time in nanoseconds, and the computation
  result. In this way, the \\`Perf\\` monad can be inserted into the midst of a computation
  in an attempt to measure performance in-situ as opposed to sitting off in a separate
  and decontextualized process.\n\n    :t tick\n\n    tick :: (a -> b) -> a -> IO
  (Nanos, b)\n\n`tick` returns in the IO monad, because reading a cycle counter is
  an IO effect. A trivial but fundamental point is that performance measurement effects
  the computation being measured.\n\n\n### tick\\_\n\ntick\\_ measures the nanoseconds
  between two immediate clock reads.\n\n    :t tick_\n\n    tick_ :: IO Nanos\n\n
  \   replicateM 10 tick_\n\n    [1833,500,416,416,416,375,375,416,416,416]\n\n\n###
  multiple ticks\n\n    fmap (fmap (fst)) . replicateM 10 $ tick (const ()) ()\n\n
  \   [7000,2333,2000,2208,1958,1959,1959,2000,2000,1959]\n\nHere, `const () ()` was
  evaluated and took 7 micro-seconds for the first effect, reducing down to 2 msecs
  after 10 effects.\n\n\n### tickIO\n\n`tickIO` measures the evaluation of an IO value.\n\n
  \   :t tickIO\n\n    tickIO :: IO a -> IO (Cycles, a)\n\n    fmap (fmap fst) . replicateM
  10 $ tickIO (pure ())\n\n    [5541,1625,1458,1833,1375,1416,1375,1375,1375,1375]\n\n\n###
  sum example\n\n    fmap (expt (Just 2) . fromIntegral) . fst <$> ticks 10 sum ([1..10000]
  :: [Double])\n\n    [\"5.0e5\",\"2.4e5\",\"2.4e5\",\"2.4e5\",\"2.4e5\",\"2.4e5\",\"2.4e5\",\"2.4e5\",\"2.5e5\",\"2.4e5\"]\n\n
  \   ts <- ticks 10000 sum ([1..1000] :: [Double])\n    print $ average (fmap fromIntegral
  $ fst ts)\n\n    10747.1975\n\n\n## PerfT\n\n`PerfT` allows for multiple measurement
  points and is polymorphic in what is being measured. It returns a Map of results
  held in State.\n\nCompare a lower-level usage of ticks, measuring the average of
  summing to one thousand over one thousand trials:\n\n    first (average . fmap fromIntegral)
  <$> ticks 1000 sum [1..1000]\n\n    (25947.635,500500)\n\n&#x2026; with PerfT usage\n\n
  \   second (fmap (average . fmap fromIntegral)) <$> runPerfT (times 1000) (sum |$|
  [1..1000])\n\n    (500500,fromList [(\"\",26217.098)])\n\nAn IO example\n\n    exampleIO'
  :: IO ()\n    exampleIO' = do\n      txt <- Text.readFile \"src/Perf.hs\"\n      let
  n = Text.length txt\n      Text.putStrLn $ \"length of file is: \" <> Text.pack
  (show n)\n\n    exampleIO = execPerfT time (do\n      txt <- fam \"file_read\" (Text.readFile
  \"src/Perf.hs\")\n      n <- fap \"length\" Text.length txt\n      fam \"print_result\"
  (Text.putStrLn $ \"length of file is: \" <> Text.pack (show n)))\n\n    perf-explore
  --exampleIO\n\n    length of file is: 1794\n    length of file is: 1794\n    \n
  \   label1          label2          label3          old result      new result      change\n
  \   \n    normal          file-read       time            2.31e5          1.28e5
  \         improvement\n    normal          length          time            2.71e3
  \         2.00e3          improvement\n    normal          print-result    time
  \           3.75e4          1.32e4          improvement\n    outer           file-read
  \      time            6.05e4          3.64e4          improvement\n    outer           length
  \         time            9.59e2          6.25e2          improvement\n    outer
  \          outer-total     time            7.39e4          4.02e4          improvement\n
  \   outer           print-result    time            9.79e3          1.71e3          improvement\n\n\n##
  Perf.BigO\n\nPerf.BigO represents functionality to determine the complexity order
  for a computation.\n\nWe could do a regression and minimise the error term, but
  we know that the largest run contains the most information; we would need to weight
  the simulations according to some heuristic.\n\nInstead, we:\n\n-   estimate the
  order factor for each possible Order, from N3 to N0, setting the highest n run constant
  factor to zero,\n-   pick the order based on lowest absolute error result summed
  across all the runs,\n\n    import qualified Prelude as P\n    import Data.List
  (nub)\n    estOrder (\\x -> sum $ nub [1..x]) 100 [10,100,1000,1000]\n\n    BigOrder
  {bigOrder = N2, bigFactor = 3.187417}\n\n    import qualified Prelude as P\n    import
  Data.List (nub)\n    estOrder (\\x -> sum $ [1..x]) 10 [1,10,100,1000]\n\n    BigOrder
  {bigOrder = N12, bigFactor = 695.0370069284081, bigConstant = 0.0}\n\n\n## References\n\n<https://wiki.haskell.org/Performance/GHC>\n\n[The
  Haskell performance checklist](https://github.com/haskell-perf/checklist)\n\n[ndmitchell/spaceleak:
  Notes on space leaks](https://github.com/ndmitchell/spaceleak)\n\n\n### Core\n\n[5.13.
  Debugging the compiler](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/debugging.html#options-debugging)\n\n
  \   ghc app/speed.hs -ddump-simpl -ddump-to-file -fforce-recomp -dlint -O\n\n[haskell
  wiki: Looking at the Core](https://wiki.haskell.org/Performance/GHC#Looking_at_the_Core)\n\n[godbolt](https://godbolt.org/)\n\n[ghc
  issue 15185: Enum instance for IntX / WordX are inefficient](https://gitlab.haskell.org/ghc/ghc/-/issues/15185)\n\n[fixpt
  - All About Strictness Analysis (part 1)](https://fixpt.de/blog/2017-12-04-strictness-analysis-part-1.html)\n\n\n###
  Profiling\n\n1.  setup\n\n    [8. Profiling](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/profiling.html#prof-heap)\n
  \   \n    A typical configuration step for profiling:\n    \n        cabal configure
  --enable-library-profiling --enable-executable-profiling -fprof-auto -fprof -write-ghc-environment-files=always\n
  \   \n    A cabal.project.local with profiling enabled:\n    \n    > write-ghc-environment-files:
  always\n    > ignore-project: False\n    > flags: +prof +prof-auto\n    > library-profiling:
  True\n    > executable-profiling: True\n    \n    Examples from markup-parse R&D:\n
  \   \n    Executable compilation:\n    \n        ghc -prof -fprof-auto -rtsopts
  app/speed0.hs -threaded -fforce-recomp\n    \n    Executable run:\n    \n        app/speed0
  +RTS -s -p -hc -l -RTS\n\n2.  Space usage output (-s)\n\n        885,263,472 bytes
  allocated in the heap\n               8,507,448 bytes copied during GC\n                 163,200
  bytes maximum residency (4 sample(s))\n                  27,752 bytes maximum slop\n
  \                      6 MiB total memory in use (0 MiB lost due to fragmentation)\n
  \       \n                                             Tot time (elapsed)  Avg pause
  \ Max pause\n          Gen  0       207 colls,     0 par    0.009s   0.010s     0.0001s
  \   0.0002s\n          Gen  1         4 colls,     0 par    0.001s   0.001s     0.0004s
  \   0.0005s\n        \n          TASKS: 4 (1 bound, 3 peak workers (3 total), using
  -N1)\n        \n          SPARKS: 0 (0 converted, 0 overflowed, 0 dud, 0 GC'd, 0
  fizzled)\n        \n          INIT    time    0.006s  (  0.006s elapsed)\n          MUT
  \    time    0.367s  (  0.360s elapsed)\n          GC      time    0.010s  (  0.011s
  elapsed)\n          RP      time    0.000s  (  0.000s elapsed)\n          PROF    time
  \   0.000s  (  0.000s elapsed)\n          EXIT    time    0.001s  (  0.001s elapsed)\n
  \         Total   time    0.384s  (  0.380s elapsed)\n\n3.  Cost center profile
  (-p)\n\n    Dumped to speed0.prof\n    \n        COST CENTRE MODULE                SRC
  \                                           %time %alloc\n        \n        token
  \      MarkupParse           src/MarkupParse.hs:(259,1)-(260,20)             50.2
  \  50.4\n        wrappedQ'   MarkupParse.FlatParse src/MarkupParse/FlatParse.hs:(215,1)-(217,78)
  \  20.8   23.1\n        ws_         MarkupParse.FlatParse src/MarkupParse/FlatParse.hs:(135,1)-(146,4)
  \   14.3    5.5\n        eq          MarkupParse.FlatParse src/MarkupParse/FlatParse.hs:243:1-30
  \          10.6   11.1\n        gather      MarkupParse           src/MarkupParse.hs:(420,1)-(428,100)
  \            2.4    3.7\n        runParser   FlatParse.Basic       src/FlatParse/Basic.hs:(217,1)-(225,24)
  \         1.0    6.0\n\n4.  heap analysis (-hc -l)\n\n        eventlog2html speed0.eventlog\n
  \   \n    Produces speed0.eventlog.html which contains heap charts.\n\n\n### Cache
  speed\n\nThe average cycles per + operation can get down to about 0.7 cycles, and
  there are about 4 cache registers per cycle, so a sum pipeline uses 2.8 register
  instructions per +.\n\n<table border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\"
  frame=\"hsides\">\n\n\n<colgroup>\n<col  class=\"org-left\" />\n\n<col  class=\"org-right\"
  />\n\n<col  class=\"org-left\" />\n</colgroup>\n<thead>\n<tr>\n<th scope=\"col\"
  class=\"org-left\">Cache</th>\n<th scope=\"col\" class=\"org-right\">nsecs</th>\n<th
  scope=\"col\" class=\"org-left\">Cycles</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td
  class=\"org-left\">register</td>\n<td class=\"org-right\">0.1</td>\n<td class=\"org-left\">4
  per cycle</td>\n</tr>\n\n<tr>\n<td class=\"org-left\">L1 Cache access</td>\n<td
  class=\"org-right\">1</td>\n<td class=\"org-left\">3-4 cycles</td>\n</tr>\n\n<tr>\n<td
  class=\"org-left\">L2 Cache access</td>\n<td class=\"org-right\">4</td>\n<td class=\"org-left\">11-12
  cycles</td>\n</tr>\n\n<tr>\n<td class=\"org-left\">L3 unified access</td>\n<td class=\"org-right\">14</td>\n<td
  class=\"org-left\">30 - 40</td>\n</tr>\n\n<tr>\n<td class=\"org-left\">DRAM hit</td>\n<td
  class=\"org-right\">80</td>\n<td class=\"org-left\">195 cycles</td>\n</tr>\n\n<tr>\n<td
  class=\"org-left\">L1 miss</td>\n<td class=\"org-right\">16</td>\n<td class=\"org-left\">40
  cycles</td>\n</tr>\n\n<tr>\n<td class=\"org-left\">L2 miss</td>\n<td class=\"org-right\">&gt;250</td>\n<td
  class=\"org-left\">&gt;600 cycles</td>\n</tr>\n</tbody>\n</table>\n\n"
description-type: markdown
hash: f31f90cb3f240e32906587c57542a1fea73e64beaa648b94f8afd09350b67273
homepage: https://github.com/tonyday567/perf#readme
latest: 0.14.0.1
license-name: BSD-3-Clause
maintainer: tonyday567@gmail.com
synopsis: Performance methods and monad.
test-bench-deps:
  base: '>=4.14 && <5'
  perf: '>=0'
