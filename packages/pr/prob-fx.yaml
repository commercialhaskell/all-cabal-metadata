homepage: https://github.com/min-nguyen/prob-fx/tree/hackage
changelog-type: markdown
hash: 5712f0318c16c884141a6217578ee6dbd89570c3a4729adcdef8c1b1c570a747
test-bench-deps: {}
maintainer: minhnguyen1995@googlemail.com
synopsis: A library for modular probabilistic modelling
changelog: |+
  # Change Log

  All notable changes to this project will be documented in this file.

basic-deps:
  prob-fx: -any
  mwc-random: '>=0.15.0 && <0.16'
  membership: '>=0.0.1 && <0.1'
  split: '>=0.2.3 && <0.3'
  base: '>=4.11 && <=4.17'
  criterion: '>=1.5.13 && <1.6'
  log-domain: '>=0.13.2 && <0.14'
  containers: '>=0.6.0 && <0.7'
  lens: '>=5.1.1 && <5.2'
  ghc-prim: '>=0.5.3 && <0.8'
  mtl: '>=2.2.2 && <2.3'
  statistics: '>=0.16.1 && <0.17'
  dirichlet: '>=0.1.0 && <0.2'
  transformers: '>=0.5.6 && <0.6'
  random: '>=1.2.1 && <1.3'
  deepseq: '>=1.4.4 && <1.5'
  extensible: ==0.9.*
  mwc-probability: '>=2.3.1 && <2.4'
  primitive: '>=0.7.4 && <0.8'
  vector: '>=0.12.3 && <0.13'
all-versions:
- 0.1.0.0
- 0.1.0.1
author: Minh Nguyen
latest: 0.1.0.1
description-type: markdown
description: "## ProbFX\n\n#### Prelude\nProbFX is a library for probabilistic programming
  using algebraic effects that implements the paper [**Modular Probabilistic Models
  via Algebraic Effects**](https://github.com/min-nguyen/prob-fx/blob/master/paper.pdf)
  -- this paper provides a comprehensive motivation and walkthrough of this library.
  To have a more interactive and visual play-around with ProbFX, please see https://github.com/min-nguyen/prob-fx:
  this corresponds parts of the paper to the implementation, and also provides an
  executable version of ProbFX as a script!\n\n#### Description\nProbFx is a PPL that
  places emphasis on being able to define modular and reusable probabilistic models,
  where the decision to `sample` or `observe` against a random variable or distribution
  of a model is delayed until the point of execution; this allows a model to be defined
  just *once* and then reused for a variety of applications. We also implement a compositional
  approach towards model execution (inference) by using effect handlers. \n\n####
  Building and executing models\n\nA large number of example ProbFX programs are documented
  [here](https://github.com/min-nguyen/prob-fx/tree/hackage/examples), showing how
  to define and then execute a probabilistic model. \n\nIn general, the process is:\n\n1.
  Define an appropriate model of type `Model env es a`, and (optionally) a corresponding
  model environment type `env`.\n\n    For example, a logistic regression model that
  takes a list of `Double`s as inputs and generates a list of `Bool`s:\n    ```haskell
  \n    type LogRegrEnv =\n      '[  \"y\" ':= Bool,   -- ^ output\n          \"m\"
  ':= Double, -- ^ mean\n          \"b\" ':= Double  -- ^ intercept\n      ]\n\n    logRegr
  \n      :: (Observable env \"y\" Bool\n       , Observables env '[\"m\", \"b\"]
  Double)\n      => [Double]           \n      -> Model env rs [Bool]  \n    logRegr
  xs = do\n      -- | Specify distribution of model parameters \n      m     <- normal
  0 5 #m   \n      b     <- normal 0 1 #b     \n      sigma <- gamma' 1 1      \n
  \     -- | Specify distribution of model output \n      let sigmoid x = 1.0 / (1.0
  + exp((-1.0) * x))\n      ys    <- foldM (\\ys x -> do\n                        p
  <- normal' (m * x + b) sigma\n                        y <- bernoulli (sigmoid p)
  #y\n                        return (y:ys)) [] xs\n      return (reverse ys)\n    ```\n
  \   The `Observables` constraint says that, for example, `\"m\"` and `\"b\"` are
  observable variables in the model environment `env` that may later be provided a
  trace of observed values of type `Double`. \n    \n    Calling a primitive distribution
  such as `normal 0 5 #m` lets us later provide observed values for \"m\" when executing
  the model. \n    \n    Calling a primed variant of primitive distribution such as
  `gamma' 1 1` will disable observed values from being provided to that distribution.\n\n2.
  Execute a model under a model environment, using one of the `Inference` library
  functions.\n\n   Below simulates from a logistic regression model using model parameters
  `m = 2` and `b = -0.15` but provides no values for `y`: this will result in `m`
  and `b` being *observed*  but `y` being *sampled*.\n    ```haskell\n    simulateLogRegr
  :: Sampler [(Double, Bool)]\n    simulateLogRegr = do\n      -- | Specify the model
  inputs\n      let xs  = map (/50) [(-50) .. 50]\n      -- | Specify the model environment
  \n          env = (#y := []) <:> (#m := [2]) <:> (#b := [-0.15]) <:> nil\n      --
  | Simulate from logistic regression\n      (ys, envs) <- SIM.simulate logRegr env
  xs\n      return (zip xs ys)\n    ```\n    \n    Below performs Metropolis-Hastings
  inference on the same model, by providing values for the model output `y` and hence
  *observing* (conditioning against) them, but providing none for the model parameters
  `m` and `b` and hence *sampling* them.\n    ```haskell\n    -- | Metropolis-Hastings
  inference \n    inferMHLogRegr :: Sampler [(Double, Double)]\n    inferMHLogRegr
  = do\n      -- | Simulate data from log regression\n      (xs, ys) <- unzip <$>
  simulateLogRegr\n      -- | Specify the model environment \n      let env = (#y
  := ys) <:> (#m := []) <:> (#b := []) <:> nil\n      -- | Run MH inference for 20000
  iterations\n      mhTrace :: [Env LogRegrEnv] <- MH.mh 20000 logRegr (xs, env) [\"m\",
  \"b\"]\n      -- | Retrieve values sampled for #m and #b during MH\n      let m_samples
  = concatMap (get #m) mhTrace\n          b_samples = concatMap (get #b) mhTrace\n
  \     return (zip m_samples b_samples)\n    ```\n    One may have noticed by now
  that *lists* of values are always provided to observable variables in a model environment;
  each run-time occurrence of that variable will then result in the head value being
  observed and consumed, and running out of values will default to sampling. \n\n
  \   Running the function `mh` returns a trace of output model environments, from
  which we can retrieve the trace of sampled model parameters via `get #m` and `get
  #b`. These represent the posterior distribution over `m` and `b`. (The argument
  `[\"m\", \"b\"]` to `mh` is optional for indicating interest in learning `#m` and
  `#b` in particular).\n\n3. `Sampler` computations can be evaluated with `sampleIO
  :: Sampler a -> IO a` to produce an `IO` computation.\n\n    ```haskell\n    sampleIO
  simulateLogRegr :: [(Double, Bool)] \n    ```\n\n    \n\n"
license-name: BSD-3-Clause
