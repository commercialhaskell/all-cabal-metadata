homepage: https://github.com/discus-lang/inchworm
changelog-type: markdown
hash: f9dcba190c230ae561c3f7ec36762649d647802783aae2448ce6299bdcdcddb1
test-bench-deps: {}
maintainer: Ben Lippmeier <benl@ouroborus.net>
synopsis: Simple parser combinators for lexical analysis.
changelog: |
  ## inchworm-1.1.1.1:

   * Matching combinators now produce the range of source locations that matched,
     instead of just the starting location.

   * Line and column offsets are now 0-based instead of 1-based,
     for easier inteface with client editors that expect this (eg VSCode).

   * Thanks to Amos Robinson: Haskell string parser now correctly handles strings
     gaps and the string escape character `'\&'`
basic-deps:
  base: ! '>=4.8 && <4.13'
all-versions:
- 1.0.0.1
- 1.0.1.1
- 1.0.2.1
- 1.0.2.2
- 1.0.2.3
- 1.0.2.4
- 1.1.1.1
author: The Inchworm Development Team
latest: 1.1.1.1
description-type: markdown
description: "# Inchworm\n\nInchworm is a simple parser combinator framework specialized
  to\nlexical analysis.\nTokens are specified via simple fold functions, and we include\nbaked
  in source location handling.\n\nIf you want to parse expressions instead of performing
  lexical\nanalysis then try the `parsec` or `attoparsec` packages, which\nhave more
  general purpose combinators.\n\nMatchers for standard tokens like comments and strings
  \nare in the `Text.Lexer.Inchworm.Char` module.\n\nNo dependencies other than the
  Haskell `base` library.\n\n## Minimal example\n\nThe following code demonstrates
  how to perform lexical analysis\nof a simple LISP-like language. We use two separate
  name classes,\none for variables that start with a lower-case letter, \nand one
  for constructors that start with an upper case letter. \n\nIntegers are scanned
  using the `scanInteger` function from the \n`Text.Lexer.Inchworm.Char` module.\n\nThe
  result of `scanStringIO` contains the list of leftover input\ncharacters that could
  not be parsed. In a real lexer you should\ncheck that this is empty to ensure there
  has not been a lexical\nerror.\n\n\n```\nimport Text.Lexer.Inchworm.Char\nimport
  qualified Data.Char as Char\n\n-- | A source token.\ndata Token \n        = KBra
  | KKet | KVar String | KCon String | KInt Integer\n        deriving Show\n\n-- |
  A thing with attached location information.\ndata Located a\n        = Located FilePath
  (Range Location) a\n        deriving Show\n\n-- | Scanner for a lispy language.\nscanner
  :: FilePath\n        -> Scanner IO Location [Char] (Located Token)\nscanner fileName\n
  = skip Char.isSpace\n $ alts [ fmap (stamp id)   $ accept '(' KBra\n        , fmap
  (stamp id)   $ accept ')' KKet\n        , fmap (stamp KInt) $ scanInteger \n        ,
  fmap (stamp KVar)\n          $ munchWord (\\ix c -> if ix == 0 then Char.isLower
  c\n                                           else Char.isAlpha c) \n        , fmap
  (stamp KCon) \n          $ munchWord (\\ix c -> if ix == 0 then Char.isUpper c\n
  \                                          else Char.isAlpha c)\n        ]\n where
  \ -- Stamp a token with source location information.\n        stamp k (range, t)
  \n          = Located fileName range (k t)\n\nmain :: IO ()\nmain \n = do   let
  fileName = \"Source.lispy\"\n        let source   = \"(some (Lispy like) 26 Program
  93 (for you))\"\n        toks    <- scanStringIO source (scanner fileName)\n        print
  toks\n```\n"
license-name: MIT
