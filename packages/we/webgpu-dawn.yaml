all-versions:
- 0.1.0.0
- 0.1.1.0
author: Junji Hashimoto
basic-deps:
  aeson: '>=2.0 && <2.3'
  base: '>=4.14 && <5'
  base64-bytestring: '>=1.0 && <1.3'
  binary: '>=0.8 && <0.9'
  bytestring: '>=0.10 && <0.13'
  clock: '>=0.8 && <0.9'
  containers: '>=0.6 && <0.8'
  filepath: '>=1.4 && <1.6'
  mtl: '>=2.2 && <2.4'
  stm: '>=2.5 && <2.6'
  text: '>=1.2 && <2.1'
  transformers: '>=0.5 && <0.7'
  unordered-containers: '>=0.2.14 && <0.3'
  vector: '>=0.12 && <0.14'
  webgpu-dawn: '>=0'
changelog: ''
changelog-type: ''
description: "# webgpu-dawn\n\nHigh-level, type-safe Haskell bindings to Google's
  [Dawn WebGPU](https://dawn.googlesource.com/dawn) implementation.\n\nThis library
  enables **portable GPU computing** with a **Production-Ready DSL** designed for
  high-throughput inference (e.g., LLMs), targeting **300 TPS (Tokens Per Second)**
  performance.\n\n---\n\n## ⚡ Core Design Principles\n\nTo achieve high performance
  and type safety, this library adheres to the following strict patterns:\n\n1. **Type-Safe
  Monadic DSL:** No raw strings. We use `ShaderM` for composability and type safety.\n2.
  **Natural Math & HOAS:** Standard operators (`+`, `*`) and Higher-Order Abstract
  Syntax (HOAS) for loops (`loop ... $ \\i -> ...`).\n3. **Profile-Driven:** Performance
  tuning is based on Roofline Analysis.\n4. **Async Execution:** Prefer `AsyncPipeline`
  to hide CPU latency and maximize GPU occupancy.\n5. **Hardware Acceleration:** Mandatory
  use of **Subgroup Operations** and **F16** precision for heavy compute (MatMul/Reduction).\n\n---\n\n##
  \U0001F3CE️ Performance & Profiling\n\nWe utilize a **Profile-Driven Development
  (PDD)** workflow to maximize throughput.\n\n### 1. Standard Benchmarks & Roofline
  Analysis\n\nRun the optimized benchmark to determine TFLOPS and check the Roofline
  classification (Compute vs Memory Bound).\n\n```bash\n# Run 2D Block-Tiling MatMul
  Benchmark (FP32)\ncabal run bench-optimized-matmul -- --size 4096 --iters 50\n\n```\n\n**Output
  Example:**\n\n```text\n[Compute]  137.4 GFLOPs\n[Memory]   201.3 MB\n[Status]   COMPUTE
  BOUND (limited by GPU FLOPs)\n[Hint]     Use F16 and Subgroup Operations to break
  the roofline.\n\n```\n\n### 2. Visual Profiling (Chrome Tracing)\n\nGenerate a trace
  file to visualize CPU/GPU overlap and kernel duration.\n\n```bash\ncabal run bench-optimized-matmul
  -- --size 4096 --trace\n\n```\n\n* **Load:** Open `chrome://tracing` or [ui.perfetto.dev](https://ui.perfetto.dev)\n*
  **Analyze:** Import `trace.json` to identify gaps between kernel executions (CPU
  overhead).\n\n### 3. Debugging\n\nUse the GPU printf-style debug buffer to inspect
  values inside kernels.\n\n```haskell\n-- In DSL:\ndebugPrintF \"intermediate_val\"
  val\n\n```\n\n---\n\n## \U0001F680 Quick Start\n\n### 1. High-Level API (Data Parallelism)\n\nZero
  boilerplate. Ideal for simple `map`/`reduce` tasks.\n\n```haskell\nimport WGSL.API\nimport
  qualified Data.Vector.Storable as V\n\nmain :: IO ()\nmain = withContext $ \\ctx
  -> do\n  input  <- toGPU ctx (V.fromList [1..100] :: V.Vector Float)\n  result <-
  gpuMap (\\x -> x * 2.0 + 1.0) input\n  out    <- fromGPU' result\n  print out\n\n```\n\n###
  2. Core DSL (Explicit Control)\n\nRequired for tuning **Shared Memory**, **Subgroups**,
  and **F16**.\n\n```haskell\nimport WGSL.DSL\n\nshader :: ShaderM ()\nshader = do\n
  \ input  <- declareInputBuffer \"in\" (TArray 1024 TF16)\n  output <- declareOutputBuffer
  \"out\" (TArray 1024 TF16)\n   \n  -- HOAS Loop: Use lambda argument 'i', NOT string
  \"i\"\n  loop 0 1024 1 $ \\i -> do\n    val <- readBuffer input i\n    -- f16 literals
  for 2x throughput\n    let res = val * litF16 2.0 + litF16 1.0\n    writeBuffer
  output i res\n\n```\n\n---\n\n## \U0001F4DA DSL Syntax Cheatsheet\n\n### Types &
  Literals\n\n| Haskell Type | WGSL Type | Literal Constructor | Note |\n| --- | ---
  | --- | --- |\n| `Exp F32` | `f32` | `litF32 1.0` or `1.0` | Standard float |\n|
  `Exp F16` | `f16` | `litF16 1.0` | Half precision (Fast!) |\n| `Exp I32` | `i32`
  | `litI32 1` or `1` | Signed int |\n| `Exp U32` | `u32` | `litU32 1` | Unsigned
  int |\n| `Exp Bool_` | `bool` | `litBool True` | Boolean |\n\n**Casting Helpers:**
  `i32(e)`, `u32(e)`, `f32(e)`, `f16(e)`\n\n### Control Flow (HOAS)\n\n```haskell\n--
  For Loop\nloop start end step $ \\i -> do ...\n\n-- If Statement\nif_ (val > 10.0)
  \n    (do ... {- then block -} ...) \n    (do ... {- else block -} ...)\n\n-- Barrier\nbarrier
  \ -- workgroupBarrier()\n\n```\n\n---\n\n## \U0001F9E9 Kernel Fusion\n\nFor maximum
  performance, fuse multiple operations (`Load` -> `Calc` -> `Store`) into a single
  kernel to reduce global memory traffic.\n\n```haskell\nimport WGSL.Kernel\n\n--
  Fuse: Load -> Process -> Store\nlet pipeline = loadK inBuf >>> mapK (* 2.0) >>>
  mapK relu >>> storeK outBuf\n\n-- Execute inside shader\nunKernel pipeline i\n\n```\n\n---\n\n##
  \U0001F4DA Architecture & Modules\n\n### Execution Model (Latency Hiding)\n\nTo
  maximize GPU occupancy, encoding is separated from submission.\n\n* **`WGSL.Async.Pipeline`**:
  Use for main loops. Allows CPU to encode Token `N+1` while GPU processes Token `N`.\n*
  **`WGSL.Execute`**: Low-level synchronous execution (primarily for debugging).\n\n###
  Module Guide\n\n| Feature | Module | Description |\n| --- | --- | --- |\n| **Subgroup
  Ops** | `WGSL.DSL` | `subgroupMatrixLoad`, `mma`, `subgroupMatrixStore` |\n| **F16
  Math** | `WGSL.DSL` | `litF16`, `vec4<f16>` for 2x throughput |\n| **Structs** |
  `WGSL.Struct` | `Generic` derivation for `std430` layout compliance |\n| **Analysis**
  | `WGSL.Analyze` | Roofline analysis logic |\n\n---\n\n## \U0001F4E6 Installation\n\nPre-built
  Dawn binaries are downloaded automatically during installation.\n\n```bash\ncabal
  install webgpu-dawn\n\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](https://www.google.com/search?q=LICENSE)
  file for details.\n\n## Acknowledgments\n\n* **Dawn (Google):** Core WebGPU runtime.\n*
  **gpu.cpp (Answer.AI):** High-level C++ API wrapper inspiration.\n* **GLFW:** Window
  management.\n\n## Contact\n\nMaintainer: Junji Hashimoto [junji.hashimoto@gmail.com](mailto:junji.hashimoto@gmail.com)\n"
description-type: markdown
hash: f59a799ffbd487bec2026f1c71a92a7d7ac128aac65cda32bc56fa91bab34358
homepage: https://github.com/junjihashimoto/webgpu-dawn
latest: 0.1.1.0
license-name: MIT
maintainer: junji.hashimoto@gmail.com
synopsis: Haskell bindings to WebGPU Dawn for GPU computing and graphics
test-bench-deps:
  base: '>=0'
  hspec: '>=2.7'
  webgpu-dawn: '>=0'
