homepage: https://github.com/haskell-works/hw-kafka-client
changelog-type: ''
hash: 2c626ca7aa603673c892a9c9ea0812480420984c1e0b4f9ed17ddd924a76fb68
test-bench-deps:
  either: -any
  bytestring: -any
  base: ! '>=4.6 && <5'
  hspec: -any
  monad-loops: -any
  containers: -any
  bifunctors: -any
  hw-kafka-client: -any
maintainer: Alexey Raga <alexey.raga@gmail.com>
synopsis: Kafka bindings for Haskell
changelog: ''
basic-deps:
  bytestring: -any
  unix: -any
  base: ! '>=4.6 && <5'
  containers: -any
  bifunctors: -any
  hw-kafka-client: -any
  transformers: -any
  temporary: -any
all-versions:
- '1.0.0'
- '1.1.0'
- '1.1.1'
- '1.1.2'
- '1.1.3'
- '1.1.4'
- '2.0.0'
- '2.0.1'
- '2.0.2'
- '2.0.3'
- '2.0.4'
- '2.1.0'
- '2.1.1'
- '2.1.2'
- '2.1.3'
- '2.2.0'
- '2.3.0'
- '2.3.1'
- '2.3.2'
- '2.3.3'
- '2.4.0'
- '2.4.1'
- '2.4.3'
author: Alexey Raga <alexey.raga@gmail.com>
latest: '2.4.3'
description-type: markdown
description: ! "# hw-kafka-client\n[![CircleCI](https://circleci.com/gh/haskell-works/hw-kafka-client.svg?style=svg&circle-token=5f3ada2650dd600bc0fd4787143024867b2afc4e)](https://circleci.com/gh/haskell-works/hw-kafka-client)\n\nKafka
  bindings for Haskell backed by the\n[librdkafka C module](https://github.com/edenhill/librdkafka).\n\n##
  Credits\nThis project is inspired by [Haskakafka](https://github.com/cosbynator/haskakafka)\nwhich
  unfortunately doesn't seem to be actively maintained.\n\n## Ecosystem\nHaskellWorks
  Kafka ecosystem is described here: https://github.com/haskell-works/hw-kafka\n\n#
  Consumer\nHigh level consumers are supported by `librdkafka` starting from version
  0.9.\nHigh-level consumers provide an abstraction for consuming messages from multiple\npartitions
  and topics. They are also address scalability (up to a number of partitions)\nby
  providing automatic rebalancing functionality. When a new consumer joins a consumer\ngroup
  the set of consumers attempt to \"rebalance\" the load to assign partitions to each
  consumer.\n\n### Example:\n```\n$ stack build --flag hw-kafka-client:examples\n```\n\nor\n\n```\n$
  stack build --exec kafka-client-example --flag hw-kafka-client:examples\n```\n\nA
  working consumer example can be found here: [ConsumerExample.hs](example/ConsumerExample.hs)</br>\nTo
  run an example please compile with the `examples` flag.\n\n```Haskell\nimport Data.Monoid
  ((<>))\nimport Kafka\nimport Kafka.Consumer\n\n-- Global consumer properties\nconsumerProps
  :: ConsumerProperties\nconsumerProps = brokersList [BrokerAddress \"localhost:9092\"]\n
  \            <> groupId (ConsumerGroupId \"consumer_example_group\")\n             <>
  noAutoCommit\n             <> logLevel KafkaLogInfo\n\n-- Subscription to topics\nconsumerSub
  :: Subscription\nconsumerSub = topics [TopicName \"kafka-client-example-topic\"]\n
  \          <> offsetReset Earliest\n\n-- Running an example\nrunConsumerExample
  :: IO ()\nrunConsumerExample = do\n    res <- runConsumer consumerProps consumerSub
  processMessages\n    print res\n\n-------------------------------------------------------------------\nprocessMessages
  :: KafkaConsumer -> IO (Either KafkaError ())\nprocessMessages kafka = do\n    mapM_
  (\\_ -> do\n                   msg1 <- pollMessage kafka (Timeout 1000)\n                   putStrLn
  $ \"Message: \" <> show msg1\n                   err <- commitAllOffsets OffsetCommit
  kafka\n                   putStrLn $ \"Offsets: \" <> maybe \"Committed.\" show
  err\n          ) [0 .. 10]\n    return $ Right ()\n```\n\n# Producer\n`kafka-client`
  producer supports sending messages to multiple topics.\nTarget topic name is a part
  of each message that is to be sent by `produceMessage`.\n\nA working producer example
  can be found here: [ProducerExample.hs](example/ProducerExample.hs)\n\n### Delivery
  reports\nKafka Producer maintains its own internal queue for outgoing messages.
  Calling `produceMessage`\ndoes not mean that the message is actually written to
  Kafka, it only means that the message is put\nto that outgoing queue and that the
  producer will (eventually) push it to Kafka.\n\nHowever, it is not always possible
  for the producer to send messages to Kafka. Network problems\nor Kafka cluster being
  offline can prevent the producer from doing it.\n\nWhen a message cannot be sent
  to Kafka for some time (see `message.timeout.ms` [configuration](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
  option),\nthe message is *dropped from the outgoing queue* and the *delivery report*
  indicating an error is raised.\n\nIt is possible to configure `hw-kafka-client`
  to set an infinite message timeout so the message is\nnever dropped from the queue:\n\n```\nproducerProps
  :: ProducerProperties\nproducerProps = brokersList [BrokerAddress \"localhost:9092\"]\n
  \            <> sendTimeout (Timeout 0)           -- for librdkafka \"0\" means
  \"infinite\".\n```\n\n*Delivery reports* provide the way to detect when producer
  experiences problems sending messages\nto Kafka.\n\nCurrently `hw-kafka-client`
  only supports delivery error callbacks:\n```\nproducerProps :: ProducerProperties\nproducerProps
  = brokersList [BrokerAddress \"localhost:9092\"]\n             <> setCallback (deliveryErrorsCallback
  print)\n```\nIn the example above when the producer cannot deliver the message to
  Kafka,\nthe error will be printed (and the message will be dropped).\n\nWhen `sendTimeout`
  is not configured to `Timeout 0` (infinite), no error callbacks will be delivered.\nThis
  is because no message will ever be timing out for sending.\n\n### Example\n\n```Haskell\nimport
  Control.Monad (forM_)\nimport Kafka\nimport Kafka.Producer\n\n-- Global producer
  properties\nproducerProps :: ProducerProperties\nproducerProps = brokersList [BrokerAddress
  \"localhost:9092\"]\n             <> logLevel KafkaLogDebug\n\n-- Topic to send
  messages to\ntargetTopic :: TopicName\ntargetTopic = TopicName \"kafka-client-example-topic\"\n\n--
  Run an example\nrunProducerExample :: IO ()\nrunProducerExample = do\n    res <-
  runProducer producerProps sendMessages\n    print res\n\nsendMessages :: KafkaProducer
  -> IO (Either KafkaError ())\nsendMessages prod = do\n  err1 <- produceMessage prod
  (mkMessage Nothing (Just \"test from producer\") )\n  forM_ err1 print\n\n  err2
  <- produceMessage prod (mkMessage (Just \"key\") (Just \"test from producer (with
  key)\"))\n  forM_ err2 print\n\n  return $ Right ()\n\nmkMessage :: Maybe ByteString
  -> Maybe ByteString -> ProducerRecord\nmkMessage k v = ProducerRecord\n                  {
  prTopic = targetTopic\n                  , prPartition = UnassignedPartition\n                  ,
  prKey = k\n                  , prValue = v\n                  }\n```\n\n# Installation\n\n##
  Installing librdkafka\n\nAlthough `librdkafka` is available on many platforms, most
  of\nthe distribution packages are too old to support `kafka-client`.\nAs such, we
  suggest you install from the source:\n\n    git clone https://github.com/edenhill/librdkafka\n
  \   cd librdkafka\n    ./configure\n    make && make install\n\nSometimes it is
  helpful to specify openssl includes explicitly:\n\n    LDFLAGS=-L/usr/local/opt/openssl/lib
  CPPFLAGS=-I/usr/local/opt/openssl/include ./configure\n\n## Installing Kafka\n\nThe
  full Kafka guide is at http://kafka.apache.org/documentation.html#quickstart\n\nAlternatively
  `docker-compose` can be used to run Kafka locally inside a Docker container.\nTo
  run Kafka inside Docker:\n\n```\n$ docker-compose up\n```\n"
license-name: MIT
