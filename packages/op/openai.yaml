all-versions:
- 1.0.0
- 1.0.1
- 1.1.0
- 1.1.1
author: Gabriella Gonzalez
basic-deps:
  aeson: '>=0'
  base: '>=4.15.0.0 && <5'
  bytestring: '>=0'
  containers: '>=0'
  filepath: '>=0'
  http-api-data: '>=0'
  http-client: '>=0'
  http-client-tls: '>=0'
  openai: '>=0'
  servant: '>=0'
  servant-client: '>=0'
  servant-multipart-api: '>=0'
  servant-multipart-client: '>=0'
  text: '>=0'
  time: '>=0'
  vector: '>=0'
changelog: |
  1.1.1:

  - [Remove timeout on default `ClientEnv`](https://github.com/MercuryTechnologies/openai/pull/55)
  - [`/v1/chat/completions`: Add support for Search](https://github.com/MercuryTechnologies/openai/pull/57)
  - [Fix CreateSpeech JSON instances, add new voices and optional instructions field](https://github.com/MercuryTechnologies/openai/pull/58)
  - [Correct `ToJSON` of `FileSearchResources`](https://github.com/MercuryTechnologies/openai/pull/49)
  - [New example app for tool-calling and chat-loop](https://github.com/MercuryTechnologies/openai/pull/60)

  1.1.0:

  - BREAKING CHANGE: Fix details representations for various types [[#44](https://github.com/MercuryTechnologies/openai/pull/44)] [[#45](https://github.com/MercuryTechnologies/openai/pull/45)] [[#50](https://github.com/MercuryTechnologies/openai/pull/50)] [[#51](https://github.com/MercuryTechnologies/openai/pull/51)]

    A few details-related fields were fixed to match the behavior of the OpenAI
    API.

  - Add `FromJSON`/`ToJSON` instances for all types [[#42](https://github.com/MercuryTechnologies/openai/pull/42)] [[#47](https://github.com/MercuryTechnologies/openai/pull/47)]

  - [Add support for `reasoning_effort` parameter in chat completions](https://github.com/MercuryTechnologies/openai/pull/48)

  1.0.1:

  - Include `README`
  - Include usage example

  1.0.0:

  - Initial release
changelog-type: markdown
description: |
  # `openai`

  This provides a binding to OpenAI's API using `servant`

  ## Example usage

  ```haskell
  {-# LANGUAGE DuplicateRecordFields #-}
  {-# LANGUAGE NamedFieldPuns        #-}
  {-# LANGUAGE OverloadedStrings     #-}
  {-# LANGUAGE OverloadedLists       #-}

  module Main where

  import Data.Foldable (traverse_)
  import OpenAI.V1
  import OpenAI.V1.Chat.Completions

  import qualified Data.Text as Text
  import qualified Data.Text.IO as Text.IO
  import qualified System.Environment as Environment

  main :: IO ()
  main = do
      key <- Environment.getEnv "OPENAI_KEY"

      clientEnv <- getClientEnv "https://api.openai.com"

      let Methods{ createChatCompletion } = makeMethods clientEnv (Text.pack key)

      text <- Text.IO.getLine

      ChatCompletionObject{ choices } <- createChatCompletion _CreateChatCompletion
          { messages = [ User{ content = [ Text{ text } ], name = Nothing } ]
          , model = "gpt-4o-mini"
          }

      let display Choice{ message } = Text.IO.putStrLn (messageToContent message)

      traverse_ display choices
  ```

  ## Setup

  ### Using Nix with Flakes (Recommended)

  This project uses Nix with flakes for development environment setup.

  1. Ensure you have Nix with flakes enabled
  2. Copy the sample environment file and configure your OpenAI API key:

  ```bash
  # Copy the sample environment file
  cp .envrc.sample .envrc
  ```

  3. Edit the `.envrc` file and replace the placeholder API key with your actual key

  4. Use direnv to automatically load the development environment:

  ```bash
  # Install direnv if you haven't already
  # macOS: brew install direnv
  # Linux: your-package-manager install direnv

  # Enable direnv hook in your shell
  eval "$(direnv hook bash)" # or zsh, fish, etc.

  # Clone the repository and enter the directory
  git clone https://github.com/MercuryTechnologies/openai.git
  cd openai

  # Allow direnv (this will automatically load the environment)
  direnv allow
  ```

  ### Manual Setup

  Without Nix:

  ```bash
  # Clone the repository
  git clone https://github.com/MercuryTechnologies/openai.git
  cd openai

  # Build with cabal
  cabal build
  ```

  ## Environment Variables

  Set your OpenAI API key as an environment variable:

  ```bash
  # Option 1: Set directly in your shell
  export OPENAI_KEY="your-openai-api-key"

  # Option 2: Using .envrc with direnv (recommended)
  (umask 077; cp .envrc.sample .envrc)
  # Edit .envrc to add your API key
  direnv allow
  ```

  The API key is needed for running the test suite and example program.

  ## Testing

  Run the test suite:

  ```bash
  cabal test
  ```

  The test suite is in the `tasty/` directory with test data located in `tasty/data/`.

  ## Running the Example

  ```bash
  # Make sure your API key is set (either via .envrc or export)
  # If using direnv with proper .envrc setup, this happens automatically

  # Build and run the example
  cabal run openai-example
  ```
description-type: markdown
hash: d8b4042430c67876d7d6c2b952ad9ba88ac76758585f23c923dcc48959fd28c1
homepage: ''
latest: 1.1.1
license-name: BSD-3-Clause
maintainer: GenuineGabriella@gmail.com
synopsis: Servant bindings to OpenAI
test-bench-deps:
  aeson: '>=0'
  base: '>=0'
  http-client: '>=0'
  http-client-tls: '>=0'
  openai: '>=0'
  servant-client: '>=0'
  tasty: '>=0'
  tasty-hunit: '>=0'
  text: '>=0'
