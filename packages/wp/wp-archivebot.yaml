all-versions:
- '0.1'
author: Gwern
basic-deps:
  HTTP: '>=0'
  base: '>=3 && <4'
  feed: '>=0'
  network: '>=0'
  parallel: '>=0'
  tagsoup: '>=0'
changelog: ''
changelog-type: ''
description: |
  A MediaWiki's RecentChanges or NewPages links to every new edit or article; this bot will
  poll the corresponding RSS feeds (easier and more reliable than parsing the HTML), follow
  the links to the new edit/article, and then use TagSoup to filter out every off-wiki link
  (eg. to http://cnn.com).

  With this list of external links, the bot will then fire off requests to http://webcitation.org/,
  which will make a backup (similar to the Internet Archive, but on-demand).

  Example: to archive links from every article in the English Wikipedia's RecentChanges:

  > wp-archivebot gwern0@gmail.com 'http://en.wikipedia.org/w/index.php?title=Special:RecentChanges&feed=rss'
description-type: haddock
hash: 7cdfb6e2de302e79949059b78afb323a2c05741bdcf2c0f6b94a723def62659e
homepage: ''
latest: '0.1'
license-name: BSD-3-Clause
maintainer: gwern0@gmail.com
synopsis: Subscribe to a wiki's RSS feed and archive external links
test-bench-deps: {}
