all-versions:
- '0.1'
- '0.2'
author: Felipe Almeida Lessa
basic-deps:
  base: '>=4'
  bytestring: '>=0'
  containers: '>=0'
  directory: '>=0'
  filepath: '>=0'
  unix: '>=0'
changelog: ''
changelog-type: ''
description: |-
  This program is capable of finding duplicated files and turning
  one of them into a hard link to the other, effectively reducing
  the space usage (as the data will not be duplicated in the disk).
  It works only on POSIXish systems, and was tested in GNU/Linux only.

  WARNING: As the duplicated files will point to each other, if one
  of them is modified then the other will as well! You should use
  make-hard-links only if the files won't be modified, only renamed,
  removed, or created.

  The author had a Maildir with lots of duplicated files, and in
  his case make-hard-links was capable of reducing the space usage
  in 29% (as measured by "du -hcs" and "du -hcs -l"). As a final note,
  this program currently has a high memory usage as it has to maintain
  information about all the files that are possibly duplicates in
  memory at once (the author measured 1.7 GiB of memory for about
  300.000 files).
description-type: haddock
hash: e6ea8ed5cb5d7b0f48e75f1ccbd323e9dc4d9c2e2f030afd19d2a3d05c024aa1
homepage: ''
latest: '0.2'
license-name: LicenseRef-GPL
maintainer: felipe.lessa@gmail.com
synopsis: Change duplicated files into hard-links.
test-bench-deps: {}
