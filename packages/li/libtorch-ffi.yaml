all-versions:
- 2.0.0.0
- 2.0.0.1
- 2.0.1.0
- 2.0.1.1
- 2.0.1.2
- 2.0.1.3
- 2.0.1.5
- 2.0.1.6
- 2.0.1.7
- 2.0.1.8
- 2.0.1.9
author: Austin Huang
basic-deps:
  async: '>=2.2.5 && <2.3'
  base: '>=4.7 && <5'
  bytestring: '>=0.11.5 && <0.13'
  containers: '>=0.6.7 && <0.8'
  inline-c: '>=0.9.1.10 && <0.10'
  inline-c-cpp: '>=0.5.0.2 && <0.6.0.0'
  libtorch-ffi-helper: '>=2.0.0 && <2.1'
  optparse-applicative: '>=0.14.3.0 && <0.19'
  safe-exceptions: '>=0.1.7 && <0.2'
  sysinfo: '>=0.1.1 && <0.2'
  template-haskell: '>=2.20.0 && <2.23'
  text: '>=2.0.2 && <2.2'
changelog: ''
changelog-type: ''
description: "# libtorch-ffi\n\nThis package provides FFI bindings to PyTorch's libtorch
  C++ library.\n\n## Setup\n\nThe package automatically downloads and configures libtorch
  during the build process. You can customize the setup using environment variables.\n\n###
  Environment Variables\n\n#### `LIBTORCH_VERSION`\n- **Default**: `2.5.0`\n- **Description**:
  Specifies the version of libtorch to download and use\n- **Example**: `export LIBTORCH_VERSION=2.5.0`\n\n####
  `LIBTORCH_HOME`\n- **Default**: XDG cache directory (`~/.cache/libtorch` on Linux/macOS)\n-
  **Description**: Base directory where libtorch will be downloaded and stored\n-
  **Example**: `export LIBTORCH_HOME=/opt/libtorch`\n\n#### `LIBTORCH_CUDA_VERSION`\n-
  **Default**: `cpu`\n- **Description**: CUDA version for GPU support\n- **Options**:
  \n  - `cpu` - CPU-only version (default)\n  - `cu117` - CUDA 11.7\n  - `cu118` -
  CUDA 11.8\n  - `cu121` - CUDA 12.1\n  - Any other CUDA version string supported
  by PyTorch\n- **Example**: `export LIBTORCH_CUDA_VERSION=cu118`\n\n#### `LIBTORCH_SKIP_DOWNLOAD`\n-
  **Default**: Not set\n- **Description**: When set (to any value), skips the automatic
  download of libtorch\n- **Use case**: When you have libtorch already installed system-wide\n-
  **Example**: `export LIBTORCH_SKIP_DOWNLOAD=1`\n\n### Directory Structure\n\nThe
  downloaded libtorch is stored in a platform-specific directory structure:\n```\n$LIBTORCH_HOME/\n└──
  <version>/\n    └── <platform>/\n        └── <cuda-flavor>/\n            ├── lib/\n
  \           ├── include/\n            └── .ok\n```\n\nWhere:\n- `<version>` is the
  libtorch version (e.g., `2.5.0`)\n- `<platform>` is one of:\n  - `macos-arm64` -
  macOS on Apple Silicon\n  - `macos-x86_64` - macOS on Intel\n  - `linux-x86_64`
  - Linux on x86_64\n- `<cuda-flavor>` is the CUDA version (e.g., `cpu`, `cu118`)\n\n###
  Build Process\n\n1. **Pre-configuration**: The package checks if it's running in
  a Nix sandbox. If not, it proceeds with the download process.\n\n2. **Download**:
  If libtorch is not found in the cache directory, it will be automatically downloaded
  from PyTorch's official servers.\n\n3. **Configuration**: The build system automatically:\n
  \  - Adds the libtorch library directory to the library search path\n   - Adds the
  include directories for C++ headers\n   - Sets up proper runtime library paths (rpath)
  for dynamic linking\n   - On macOS, adds the `-ld_classic` flag for compatibility\n\n###
  Platform-Specific Notes\n\n#### macOS\n- Uses rpath for dynamic library loading\n-
  Automatically adds `-ld_classic` flag for linker compatibility\n- Supports both
  Apple Silicon (arm64) and Intel (x86_64) architectures\n- **Since libtorch-ffi's
  rpath is propagated, it doesn't matter whether hasktorch is a static link or a shared
  link**\n\n#### Linux\n- Uses rpath for dynamic library loading\n- Supports x86_64
  architecture\n- Multiple CUDA versions available for GPU support\n- **Since libtorch-ffi's
  rpath is not propagated, hasktorch must be a shared link**\n\n### Linking Configuration\n\nDue
  to rpath propagation differences between platforms, Linux requires shared linking.
  Add the following configuration:\n\n#### For Cabal (cabal.project)\n```\nshared:
  True\nexecutable-dynamic: True\n```\n\n#### For Stack (stack.yaml)\n```yaml\nconfigure-options:\n
  \ $targets:\n    - --enable-executable-dynamic\n    - --enable-shared\n```\n\n###
  Nix Support\n\nThe package detects when it's being built in a Nix sandbox and skips
  the automatic download. In this case, libtorch should be provided through Nix derivation
  inputs.\n\n### Troubleshooting\n\n1. **Download failures**: Check your internet
  connection and ensure the PyTorch download servers are accessible.\n\n2. **Missing
  libraries**: The `.ok` marker file indicates a successful download. If this file
  is missing but the directory exists, delete the directory and let the setup download
  again.\n\n3. **CUDA version mismatch**: Ensure your system CUDA version matches
  the `LIBTORCH_CUDA_VERSION` you've specified.\n\n4. **Custom libtorch installation**:
  Set `LIBTORCH_SKIP_DOWNLOAD=1` and ensure your system's libtorch is properly configured
  in your build environment.\n\n### Example Usage\n\n```bash\n# Use CPU-only version\ncabal
  build libtorch-ffi\n\n# Use CUDA 11.8 version\nexport LIBTORCH_CUDA_VERSION=cu118\ncabal
  build libtorch-ffi\n\n# Use a specific version\nexport LIBTORCH_VERSION=2.4.0\ncabal
  build libtorch-ffi\n\n# Use existing system libtorch\nexport LIBTORCH_SKIP_DOWNLOAD=1\ncabal
  build libtorch-ffi\n```\n"
description-type: markdown
hash: 72fbecdef7003e1ee0be2d0e7a63b35aeee091cc7af33da69a0ce3e77f84e0a9
homepage: https://github.com/hasktorch/hasktorch#readme
latest: 2.0.1.9
license-name: BSD-3-Clause
maintainer: hasktorch@gmail.com
synopsis: Haskell bindings for PyTorch
test-bench-deps:
  base: '>=0'
  hspec: '>=0'
  libtorch-ffi: '>=0'
  safe-exceptions: '>=0'
