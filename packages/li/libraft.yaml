all-versions:
- 0.1.0.0
- 0.1.1.0
- 0.2.0.0
- 0.2.1.0
- 0.3.0.0
- 0.4.0.0
- 0.4.1.0
- 0.5.0.0
author: Adjoint Inc.
basic-deps:
  async: '>=0'
  atomic-write: '>=0'
  attoparsec: '>=0'
  base: '>=4.7 && <5'
  base16-bytestring: '>=0'
  bytestring: '>=0'
  cereal: '>=0'
  concurrency: '>=1.3.0.0'
  containers: '>=0'
  cryptohash-sha256: '>=0'
  dejafu: '>=1.12.0.0'
  directory: '>=0'
  ekg: '>=0'
  ekg-core: '>=0'
  exceptions: '>=0'
  file-embed: '>=0'
  filepath: '>=0'
  haskeline: '>=0'
  libraft: '>=0'
  lifted-base: '>=0'
  monad-control: '>=0'
  monad-metrics: '>=0'
  mtl: '>=0'
  network: '>=0'
  network-simple: '>=0'
  optparse-applicative: '>=0'
  parsec: '>=0'
  postgresql-simple: '>=0'
  postgresql-simple-url: '>=0'
  protolude: '>=0'
  random: '>=0'
  repline: '>=0'
  stm: '>=0'
  text: '>=0'
  time: '>=0'
  transformers: '>=0'
  transformers-base: '>=0'
  unordered-containers: '>=0'
  word8: '>=0'
changelog: "# Changelog for raft\n\n## 0.5.0.0\n\n- Feature: Client write requests
  are now validated by the leader before being\n  written to its log using the functions
  from the `RaftStateMachine` and\n  `RaftStateMachinePure` typeclasses; Followers
  do not re-validate the log\n  entry when they receive the entry from the leader.\n-
  Feature: Add `nix-build` and `nix-shell` support for use with the nix package\n
  \ manager.\n\n- API change: Added a client request to query a raft node's metrics.\n-
  API change: Added `preprocessCmd` function to the `RaftStateMachine`\n  typeclass
  for implementations where the leader should add data to state\n  machine commands
  before creating the log entry.\n- API change: The `clientSendX` family of functions
  now take a `ClientReq`\n  value as an argument instead of a fully formed `ClientRequest`
  value, such\n  that the known `ClientId` is used to construct the `ClientRequest`
  value\n  instead of users having to supply it themselves.\n- API change: The `RaftStateMachinePureError
  sm v` type family from the\n  `RaftStateMachinePure` typeclass must now have both
  a `Show` and a\n  `Serialize` instance.\n- API change: Client write requests now
  have the potential of returning a\n  `ClientWriteRespFail` signifying a failure
  during the validation of the\n  request state machine update.\n- API change: The
  `RaftStateMachine` typeclass now has a function\n  `preprocessCmd` for applications
  that need the leader to manipulate the\n  command before it is made into a log entry
  and applied to the state machine.\n\n- Tests: Factor out common test functionality
  and reorganize test files.\n- Tests: Added more comprehensive concurrency tests.\n\n-
  Bug Fix: When running networks of size 2, 'incrCommitIndex' will no longer run\n
  \ in an infinite loop when incrementing the leader's commit to the correct N. \n-
  Bug Fix: When an invalid client request is submitted, the leader appropriately\n
  \ responds with a failure response and handles the next event as expected.\n- Bug
  Fix: Correctly construct the Append Entries RPC data when handling a\n  client read
  request as the leader.\n- Bug Fix: Candidates now transition to followers if the
  term in an Append\n  Entries RPC is >= to their current term.\n\n## 0.4.1.0\n\n-
  Improvement: Users can now supply an existing logging function to log internal\n
  \ raft node logs, useful for integration into existing applications.\n- Improvement:
  The example instances for `RaftClientSend` and\n  `RaftClientRecv` using unix sockets
  no longer need to fork a server to handle\n  responses from the raft node; the response
  is sent on the same socket the\n  client opens while sending the request.\n\n##
  0.4.0.0\n\n- API change: `MonadRaftAsync` is now `MonadRaftFork`, with a simpler
  API\n\n## 0.3.0.0\n\n- API change: `runRaftNode` now requires the monad it runs
  in to provide an\n  instance of the `MonadRaftAsync` and `MonadRaftChan` in the
  `Raft.Monad`\n  module in lieu of the previously necessary `MonadConc` instance.\n-
  API change: Removed the `MonadConc` constraint on all example monad\n  transformers
  and implemented inherited `MonadRaftChan` and `MonadRaftAsync` \n  instances \n-
  API change: Removed the `MonadConc` const\n- API change: Renamed the old `Raft.Monad`
  module to `Raft.Transtion` and moved the \n  `RaftT` monad transformer from `Raft.hs`
  to the `Raft.Monad` module\n- Improvement: Rework example monad `RaftExampleT` for
  simplicity\n\n\n## 0.2.0.0\n\n- Feature: Client requests are now cached by the current
  leader such that duplicate\n  client requests are not serviced\n- Bug Fix: Fix issue
  in concurrent timer not resetting properly when the timeout\n  was set to values
  under 500ms\n- Feature: Client read requests can now query entries by index or range
  of\n  indices\n- Improvement: Raft nodes now only write to disk if the state changes
  during\n  handling of events\n- Feature: Users can now specify what severity of
  log messages should be logged\n- Bug Fix: Receiving all data from a socket in the
  RaftSocketT monad\n  transformer RaftRecvX typeclass instances inducing a deadlock
  has been\n  rewritten\n- Feature: A PostgreSQL backend has been added for storage
  of log entries\n\n## 0.1.2.0\n\n- Added a heartbeat broadcast by leader on read
  requests from client to ensure\n  that the node is leader before responding to client\n-
  Each log entry is now linked by sha256 hash to the log entry immediately\n  preceding
  it\n- Fixed bug where the last log entry was not being read from disk before\n  starting
  the main event loop\n- Added quickcheck-state-machine tests for black-box testing
  of the raft-example\n  client program\n\n## 0.1.1.0\n\n- Fixed MonadFail constraints
  for GHC 8.6\n\n## 0.1.0.0\n\n- Initial release.\n"
changelog-type: markdown
description: "<p align=\"center\">\n  <a href=\"http://www.adjoint.io\"><img src=\"https://www.adjoint.io/assets/img/adjoint-logo@2x.png\"
  width=\"250\"/></a>\n</p>\n\n[![CircleCI](https://circleci.com/gh/adjoint-io/raft.svg?style=svg&circle-token=71138966721e3459d81362f6f379a4782a3f6b7d)](https://circleci.com/gh/adjoint-io/raft)\n\n#
  Raft\n\nAdjoint's implementation of the Raft consensus algorithm. See [original\npaper](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf)\nfor
  further details about the protocol.\n\n# Overview\n\nRaft proposes a strong single-leader
  approach to consensus. It simplifies\noperations, as there are no conflicts, while
  being more efficient than other\nleader-less approaches due to the high throughput
  achievable by the leader. In\nthis leader-driven consensus algorithm, clients must
  contact the leader directly\nin order to communicate with the system. The system
  needs to have an\nelected leader in order to be available.\n\nIn addition to a pure
  core event loop, this library uses the systematic\nconcurrency testing library\n[dejafu](https://hackage.haskell.org/package/dejafu-1.11.0.3)
  to test\ncertain properties about streams of events throughout the system. Random
  thread\ninterleavings are generated in a raft network and realistic event\nstreams
  are delivered to each node's event queue. We test for the absence of\ndeadlocks
  and exceptions, along with checking that the convergent state of the\nsystem matches
  the expected results. These concurrency tests can be found\n[here](https://github.com/adjoint-io/raft/blob/master/test/TestDejaFu.hs).\n\n##
  Ensuring valid transitions between node states\n\nEach server in Raft can only be
  in one of these three states:\n\n- Leader: Active node that handles all client interactions
  and send\n  AppendEntries RPCs to all other nodes.\n- Candidate: Active node that
  attempts to become a leader.\n- Follower: Passive node that just responds to RPCs.\n\nTemporal
  (e.g. ElectionTimeout) and spatial (e.g. AppendEntries or RequestVote)\nevents cause
  nodes to transition from one state to another.\n\n```\n    [0]                     [1]
  \                      [2]\n------------> Follower --------------> Candidate -------------->
  Leader\n               ^  ^                       |                        |\n               |
  \ |         [3]           |                        |\n               |  |_______________________|
  \                       |\n               |                                                   |\n
  \              |                                 [4]               |\n               |___________________________________________________|\n\n-
  [0] Starts up | Recovers\n- [1] Times out | Starts election\n- [2] Receives votes
  from majority of servers and becomes leader\n- [3] Discovers leader of new term
  | Discovers candidate with a higher term\n- [4] Discovers server with higher term\n```\n\nAll
  nodes in the Raft protocol begin in the follower state. A follower will stay\na
  follower unless it fails to hear from a leader or a candidate requesting a\nvote
  within its ElectionTimeout timer. If this happens, a follower will\ntransition to
  a candidate state. These node states are illustrated in the type:\n\n```haskell\ndata
  Mode\n  = Follower\n  | Candidate\n  | Leader\n```\n\nThe volatile state a node
  keeps track of may vary depending on the mode that it\nis in. Using `DataKinds`
  and `GADTs`, we relate these specific node state\ndatatypes that contain the relevant
  data to the current node's mode with the\n`NodeState` type. This way, we can enforce
  that the volatile state carried by a\nnode in mode `Follower` is indeed `FollowerState`,
  etc:\n\n```haskell\n-- | The volatile state of a Raft node\ndata NodeState (a ::
  Mode) v where\n  NodeFollowerState :: FollowerState v -> NodeState 'Follower v\n
  \ NodeCandidateState :: CandidateState v -> NodeState 'Candidate v\n  NodeLeaderState
  :: LeaderState v -> NodeState 'Leader v\n```\n\nThe library's main event loop is
  comprised of a simple flow: Raft nodes receive\nevents on an STM channel, handle
  the event depending on the current node state,\nreturn a list of actions to perform,
  and then perform those actions in the order\nthey were generated. The `Event` type
  specifies the main value to which raft\nnodes react to, whereas the `Action` type
  specifies the action the raft node\nperforms as a result of the pairing of the current
  node state and received\nevent.\n\nThe Raft protocol has constraints on how nodes
  transition from one state to\nanother. For example, a follower cannot transition
  to a leader state\nwithout first transitioning to a candidate state. Similarly,
  a leader can\nnever transition directly to a candidate state due to the algorithm\nspecification.
  Candidates are allowed to transition to any other node state.\n\nTo adhere to the
  Raft specification, we make use of some type level programming\nto ensure that only
  valid transitions happen between node states.\n\n```haskell\n-- | All valid state
  transitions of a Raft node\ndata Transition (init :: Mode) (res :: Mode) where\n
  \ StartElection            :: Transition 'Follower 'Candidate\n  HigherTermFoundFollower
  \ :: Transition 'Follower 'Follower\n\n  RestartElection          :: Transition
  'Candidate 'Candidate\n  DiscoverLeader           :: Transition 'Candidate 'Follower\n
  \ HigherTermFoundCandidate :: Transition 'Candidate 'Follower\n  BecomeLeader             ::
  Transition 'Candidate 'Leader\n\n  HandleClientReq          :: Transition 'Leader
  'Leader\n  SendHeartbeat            :: Transition 'Leader 'Leader\n  DiscoverNewLeader
  \       :: Transition 'Leader 'Follower\n  HigherTermFoundLeader    :: Transition
  'Leader 'Follower\n\n  Noop :: Transition init init\n```\n\nTo compose the `Transition`
  with the resulting state from the event handler, we\nuse the `ResultState` datatype,
  existentially quantifying the result state mode:\n\n```haskell\n-- | Existential
  type hiding the result type of a transition, fixing the\n-- result state to the
  state dictated by the 'Transition init res' value.\ndata ResultState init v where\n
  \ ResultState :: Transition init res -> NodeState res -> ResultState init\n```\n\nThis
  datatype fixes the result state to be dependent on the transition that\noccurred;
  as long as the allowed transitions are correctly denoted in the\n`Transition` data
  constructors, only valid transitions can be specified by the\n`ResultState`. Furthermore,
  `ResultState` values existentially hide the result\nstate types, that can be accessed
  via pattern matching. Thus, all event\nhandlers, be they RPC handlers, timeout handlers,
  or client request handlers,\nhave a type signature of the form:\n\n```haskell\nhandler
  :: NodeState init -> ... relevant handler data ... -> ResultState init\n```\n\nStatically,
  the `ResultState` will enforce that invalid transitions are not made\nwhen writing
  handlers for all combinations of raft node modes and events. In the\nfuture, this
  approach may be extended to limit the actions a node can emit\ndependent on its
  current mode.\n\n## Library Architecture\n\nWithin the Raft protocol, there is a
  pure core that can be abstracted without\nthe use of global state. The protocol
  can be looked at simply as a series\nof function calls of a function from an initial
  node state to a result node\nstate. However, sometimes these transitions have *side
  effects*. In this library\nwe have elected to separate the *pure* and **effectful**
  layers.\n\nThe core event handling loop is a *pure* function that, given the current
  node\nstate and a few extra bits of global state, computes a list of `Action`s for
  the\neffectful layer to perform (updating global state, sending a message to another\nnode
  over the network, etc.).\n\n### Pure Layer\n\nIn order to update the replicated
  state machine, clients contact the leader via\n\"client requests\" containing commands
  to be committed to the replicated state\nmachine. Once a command is received, the
  current leader assesses whether it is\npossible to commit the command to the replicated
  state machine.\n\nThe replicated state machine must be deterministic such that every
  command\ncommitted by a leader to the state machine will eventually be replicated
  on\nevery node in the network at the same index.\n\nAs the only part of the internal
  event loop that needs to be specified manually,\nWe ask users of our library to
  provide an instance of the state machine `RaftStateMachinePure`\ntypeclass. This
  typeclass relates a state machine type to a command type\nand a single type class
  function `applyCmdRaftStateMachinePure`, a pure function that\nshould return the
  result of applying the command to the initial state machine.\n\n```haskell\nclass
  RaftStateMachinePure sm v | sm -> v where\n  data RaftStateMachinePureError sm v\n
  \ type RaftStateMachinePureCtx sm v = ctx | ctx -> sm v\n  applyCmdRaftStateMachinePure
  :: RaftStateMachinePureCtx sm v -> sm -> v -> Either (RaftStateMachinePureError
  sm v) sm\n```\n\nEverything else related to the core event handling loop is not
  exposed to\nlibrary users. All that needs to be specified is the type of the state
  machine,\nthe commands to update it, and how to perform those updates.\n\n### Effectful
  Layers\n\nIn this Raft implementation, there are four components that need access
  to global\nstate and system resources. Firstly, raft nodes must maintain some persistent\nstate
  for efficient and correct recovery from network outages or partitions.\nSecondly,
  raft nodes need to send messages to other raft nodes for the network\n(the replicated
  state machine) to be operational. Next, library users must\nspecify what event channel
  datastructure to use. Finally, the programmer must\nprovide a way to fork threads
  and run a list of effectful actions concurrently.\n\nThe reasons for the latter
  two design decisions-- requiring the programmer to\nprovide an event channel type
  and new/read/writeChannel primitives, a way to\nfork an effectful action to run
  concurrently, and a way to run a list of actions\nconcurrently-- is a result of
  property based concurrency testing that we do,\nfound in `test/TestDejaFu.hs`. In
  order to test the system as a whole, to run\nseveral nodes concurrently and test
  invariants about the system such as the\nabsence of deadlocks, we must be able to
  swap out the base monad for the\n`ConcIO` monad, which has implementations of concurrency
  primitives that act\ndeterministically. This allows us to test that the raft nodes
  run correctly in \na wide space of thread interleavings giving us more confidence
  that our code is\ncorrect, assuming \"correct\" implementations of the `MonadRaftFork`
  and\n`MonadRaftChan` typeclasses.\n\n#### Persistent State\n\nEach node persists
  data to disk, including the replicated log\nentries. Since persisting data is an
  action that programmers have many opinions\nand preferences regarding, we provide
  two type classes that abstract the\nspecifics of writing log entries to disk as
  well as a few other small bits of\nrelevant data. These are separated due to the
  nature in which the log entries\nare queried, often by specific index and without
  bounds. Thus, it may be\ndesirable to store the log entries in an efficient database.
  The remaining\npersistent data is always read and written atomically, and has a
  much smaller\nstorage footprint.\n\nThe actions of reading or modifying existing
  log entries on disk is broken down\neven further: we ask the user to specify how
  to write, delete, and read\nlog entries from disk. Often these types of operations
  can be optimized via\nsmarter persistent data solutions like modern SQL databases,
  thus we arrive at\nthe following level of granularity:\n\n```haskell\n-- | The type
  class specifying how nodes should write log entries to storage.\nclass Monad m =>
  RaftWriteLog m v where\n  type RaftWriteLogError m\n  -- | Write the given log entries
  to storage\n  writeLogEntries\n    :: Exception (RaftWriteLogError m)\n    => Entries
  v -> m (Either (RaftWriteLogError m) ())\n\n-- | The type class specifying how nodes
  should delete log entries from storage.\nclass Monad m => RaftDeleteLog m v where\n
  \ type RaftDeleteLogError m\n  -- | Delete log entries from a given index; e.g.
  'deleteLogEntriesFrom 7'\n  -- should delete every log entry\n  deleteLogEntriesFrom\n
  \   :: Exception (RaftDeleteLogError m)\n    => Index -> m (Either (RaftDeleteLogError
  m) (Maybe (Entry v)))\n\n-- | The type class specifying how nodes should read log
  entries from storage.\nclass Monad m => RaftReadLog m v where\n  type RaftReadLogError
  m\n  -- | Read the log at a given index\n  readLogEntry\n    :: Exception (RaftReadLogError
  m)\n    => Index -> m (Either (RaftReadLogError m) (Maybe (Entry v)))\n  -- | Read
  log entries from a specific index onwards\n  readLogEntriesFrom\n    :: Exception
  (RaftReadLogError m)\n    => Index -> m (Either (RaftReadLogError m) (Entries v))\n
  \ -- | Read the last log entry in the log\n  readLastLogEntry\n    :: Exception
  (RaftReadLogError m)\n    => m (Either (RaftReadLogError m) (Maybe (Entry v)))\n```\n\n---\n\nTo
  read and write the `PersistentData` type (the remaining persistent data that\nis
  not log entries), we ask the user to use the following `RaftPersist`\ntypeclass.\n\n```haskell\n--
  | The RaftPersist type class specifies how to read and write the persistent\n--
  state to disk.\nclass Monad m => RaftPersist m where\n  type RaftPersistError m\n
  \ readPersistentState\n    :: Exception (RaftPersistError m)\n    => m (Either (RaftPersistError
  m) PersistentState)\n  writePersistentState\n    :: Exception (RaftPersistError
  m)\n    => PersistentState -> m (Either (RaftPersistError m) ())\n```\n\n### Networking\n\nThe
  other non-deterministic, effectful part of the protocol is the communication\nbetween
  nodes over the network. It can be unreliable due to network delays,\npartitions
  and packet loss, duplication and reordering, but the Raft consensus\nalgorithm was
  designed to achieve consensus in such harsh conditions.\n\nThe actions that must
  be performed in the networking layer are *sending RPCs* to\nother raft nodes, *receiving
  RPCs* from other raft nodes, *sending client\nresponses* to clients who have issued
  requests, and *receiving client requests*\nfrom clients wishing to update the replicated
  state. Depending on use of this\nraft library, the two pairs are not necessary symmetric
  and so we do not\nforce the user into specifying a single way to send/receive messages
  to and from\nraft nodes or clients.\n\nWe provide several type classes for users
  to specify the networking layer\nthemselves. The user must make sure that the `sendRPC`/`receiveRPC`
  and\n`sendClient`/`receiveClient` pairs perform complementary actions; that an RPC\nsent
  from one raft node to another is indeed receivable via `receiveRPC` on the\nnode
  to which it was sent:\n\n```haskell\n-- | Interface for nodes to send messages to
  one\n-- another. E.g. Control.Concurrent.Chan, Network.Socket, etc.\nclass RaftSendRPC
  m v where\n  sendRPC :: NodeId -> RPCMessage v -> m ()\n\n-- | Interface for nodes
  to receive messages from one\n-- another\nclass RaftRecvRPC m v where\n  type RaftRecvRPCError
  m v\n  receiveRPC :: m (Either (RaftRecvRPCError m v) (RPCMessage v))\n\n-- | Interface
  for Raft nodes to send messages to clients\nclass RaftSendClient m sm v where\n
  \ sendClient :: ClientId -> ClientResponse sm v -> m ()\n\n-- | Interface for Raft
  nodes to receive messages from clients\nclass RaftRecvClient m v where\n  type RaftRecvClientError
  m v\n  receiveClient :: m (Either (RaftRecvClientError m v) (ClientRequest v))\n```\n\nWe
  have written a default implementation for network sockets over TCP in\n[src/Examples/Raft/Socket](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket)\n\n###
  Event Channel\n\nThe core of the effectful layers of this Raft implmentation is
  the _event\nchannel_. Since different data channels have different performance,
  we ask the\nprogrammer to supply an implementation of such a channel via yet another
  type\nclass and type family:\n\n```haskell\nclass Monad m => MonadRaftChan v m where\n
  \ type RaftEventChan v m\n  readRaftChan :: RaftEventChan v m -> m (Event v)\n  writeRaftChan
  :: RaftEventChan v m -> Event v -> m ()\n  newRaftChan :: m (RaftEventChan v m)\n```\n\nOn
  spawning a raft node, the program will create a new event channel using\n`newRaftChan`.
  Then, the event producers will be forked; These event producers\nwill use the aforementioned
  typeclasses like `RaftRecvRPC` and `RaftRecvClient`\nto wait for messages from other
  raft nodes or clients wishing to contact the\nnode. Once a message is received,
  a message event is constructed from the\nmessage contents and written to the main
  event channel via `writeRaftChan`. In\nthe main thread, the core event handler will
  be repeatedly reading events from\nthe event channel using `readRaftChan` and performing
  the correct action in\nresponse to each event.\n\n### Concurrency\n\nThe last of
  the type class instances the programmer must provide for the monad\nthey are running
  the raft node in is a `MonadRaftFork`, which provides the main\nraft loop with the
  ability to fork a concurrent action; The raft node needs to\nknow how to fork actions
  in the monad. This is necessary for the raft node to \nbe able to fork its event
  producers, and run other actions concurrently; e.g.\na leader responding to all
  followers at the same time during a heartbeat RPC\nbroadcast. The typeclass is defined
  as follows:\n\n```haskell\n-- | The typeclass encapsulating the concurrency operations
  necessary for the\n-- implementation of the main event handling loop.\nclass Monad
  m => MonadRaftFork m where\n  type RaftThreadId m\n  raftFork\n    :: RaftThreadRole
  \     -- ^ The role of the current thread being forked\n    -> m ()                --
  ^ The action to fork\n    -> m (RaftThreadId m)\n```\n\nThe implementation of this
  typeclass is a bit subtle, and it is advised that\nprogrammers do not implement
  it from scratch themselves. A default \nimplementation is provided for the `IO`
  type using standard concurrency \nprimitives making it easy for the programmer to
  simply rely on that\nimplementation. An example instance of this type class for
  a custom monad\ntransformer stack with `IO` the bottom:\n\n```haskell\ninstance
  MonadRaftFork MyMonad where\n  type RaftThreadId MyMonad = RaftThreadId IO\n  raftFork
  threadRole myMonad = \n    lift $ raftFork threadRole (runMyMonad myMonad) \n```\n\nThe
  last thing to mention about this typeclass is the `RaftThreadRole` value\nthat must
  be passed to invocations of the `raftFork` function. In some\napplications (and,
  noteably our concurrency testing suite) thread names can be\nused for debugging
  and even message passing purposes. For instance of\n`MonadRaftFork` that do not
  need to distinguish threads by name, simply ignore\nthe argument. \n\n# The Raft
  Example (`raft-example`)\n\nIn this library we provide a full fledged, non-production
  ready, example\nimplementation/s of monad transformers and type class instances
  for _all_ type\nclasses necessary to run a raft node. They can be found in\n`src/Examples/Raft/...`
  or in `app/Main.hs`:\n\n`RaftExampleT` (found in `app/Main.hs`):\n- `MonadRaftFork`\n-
  `MonadRaftChan`\n- `RaftStateMachine`\n\n`RaftSocketT` (found in `src/Examples/Raft/Socket/Node.hs`):\n-
  `RaftSendRPC`\n- `RaftRecvRPC`\n- `RaftSendClient`\n- `RaftRecvClient`\n\n`RaftLogFileStoreT`
  (found in `src/Examples/Raft/FileStore/Log.hs`):\n- `RaftReadLog`\n- `RaftWriteLog`\n-
  `RaftDeleteLog`\n- `RaftInitLog`\n\n`RaftPersistFileStoreT` (found in `src/Examples/Raft/FileStore/Persistent.hs`):\n-
  `RaftPersistent`\n\nProgrammers can use these files and implementations for references
  when implementing \nthe necessary type class instances for their bespoke monads,
  or even use some of\nthe monad transformers in their own stack!\n\nWe provide a
  complete example of the library where nodes communicate via network\nsockets, and
  they write their logs on text files. See\n[app/Main.hs](https://github.com/adjoint-io/raft/blob/master/app/Main.hs)
  to\nhave further insight.\n\n1) Build the example executable:\n```$ stack build
  ```\n\n2) In separate terminals, run some raft nodes:\n\n    The format of the cmd
  line invocation is:\n    ``` \n    $ raft-example node <fresh/existing> <file/postgres>
  <node-id> <peer-1-node-id> ... <peer-n-node-id> \n    \n    ```\n\n    We are going
  to run a network of three nodes:\n\n    - On terminal 1:\n\n    ```$ stack exec
  raft-example node fresh file localhost:3001 localhost:3002 localhost:3003```\n\n
  \   - On terminal 2:\n\n    ```$ stack exec raft-example node fresh file localhost:3002
  localhost:3001 localhost:3003```\n\n    - On terminal 3:\n\n    ```$ stack exec
  raft-example node fresh file localhost:3003 localhost:3001 localhost:3002```\n\n
  \   The first node spawned should become candidate once its election's timer\n    times
  out and request votes to other nodes. It will then become the leader,\n    once
  it receives a majority of votes and will broadcast messages to all\n    nodes at
  each heartbeat.\n\n    **Note:** If you want to run a raft example node with _existing_
  persistent data,\n    pass the `existing` command line option to the `raft-example`
  program instead\n    of `fresh`:\n    \n    ```$ stack exec raft-example node existing
  ...```\n\n\n    **Note:** The example also runs using a PostgreSQL database as long
  as a\n    user 'libraft_test' with password 'libraft_test' exists in your local\n
  \   postgresql installation. For ease of experimentation, if such a user does\n
  \   not exist, create it like so:\n\n    ```$ sudo -su postgres psql -U postgres
  -c \"CREATE USER libraft_test WITH CREATEDB PASSWORD 'libraft_test';\"```\n\n3)
  Run a client:\n```$ stack exec raft-example client```\n\n    In the example provided,
  there are five basic operations:\n\n      - `addNode <host:port>`: Add a nodeId
  to the set of nodeIds that the client\n        will communicate with. Adding a single
  node will be sufficient, as this node\n        will redirect the command to the
  leader in case he is not.\n\n      - `getNodes`: Return all node ids that the client
  is aware of.\n\n      - `read`: Return the state of the leader.\n\n      - `set
  <var> <val>`: Set a variable to a specific value.\n\n      - `incr <var>`: Increment
  the value of a variable.\n\n    Assuming that two nodes are run as mentioned above,
  a valid client workflow\n    would be:\n    ```\n    >>> addNode localhost:3001\n
  \   >>> set testVar 4\n    >>> incr testVar\n    >>> read\n    ```\n\n    It will
  return the state of the leader's state machine (and eventually the state\n    of
  all nodes in the Raft network). In our example, it will be a map of a single\n    key
  `testVar` of value `4`\n\n## How to use this library\n\n1. [Define the state\nmachine](https://github.com/adjoint-io/raft#define-the-state-machine)\n2.
  [Implement the networking\nlayer](https://github.com/adjoint-io/raft#implement-the-networking-layer)\n3.
  [Implement the persistent\nlayer](https://github.com/adjoint-io/raft#implement-the-persistent-layer)\n4.
  [Putting it all\ntogether](https://github.com/adjoint-io/raft#putting-it-all-together)\n\n###
  Define the state machine\n\nThe only requirement for our state machine is to instantiate
  the state machine `RaftStateMachinePure`\ntype class.\n\n```haskell\n-- | Interface
  to handle commands in the underlying state machine. Functional\n--dependency permitting
  only a single state machine command to be defined to\n--update the state machine.\nclass
  RaftStateMachinePure sm v | sm -> v where\n  data RaftStateMachinePureError sm v\n
  \ type RaftStateMachinePureCtx sm v = ctx | ctx -> sm v\n  rsmTransition :: RaftStateMachinePureCtx
  sm v -> sm -> v -> Either (RaftStateMachinePureError sm v) sm\n  \n```\n\nIn our
  [example](https://github.com/adjoint-io/raft/blob/master/app/Main.hs) we\nuse a
  simple map as a store whose values can only increase.\n\n### Implement the networking
  layer\n\nWe leave the choice of the networking layer open to the user, as it can
  vary\ndepending on the use case (E.g. TCP/UDP/cloud-haskell/etc).\n\nWe need to
  specify how nodes will communicate with clients and with each other.\nAs described
  above in the [Networking\nsection](https://github.com/adjoint-io/raft#networking),
  it suffices to\nimplement those four type classes (`RaftSendRPC`, `RaftRecvRPC`,\n`RaftSendClient`,
  `RaftRecvClient`).\n\nIn our example, we provide instances of nodes communicating
  over TCP to other\nnodes\n([Socket/Node.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket/Node.hs))\nand
  clients\n([Socket/Client.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket/Client.hs)).\n\nNote
  that our datatypes will need to derive instances of `MonadThrow`,\n`MonadCatch`,
  `MonadMask` and `MonadConc`. This allows us to test concurrent\nproperties of the
  system, using randomized thread scheduling to assert the\nabsence of deadlocks and
  exceptions.\n\nIn case of the `RaftSocketT` data type used in our example:\n\n```haskell\nderiving
  instance MonadConc m => MonadThrow (RaftSocketT v m)\nderiving instance MonadConc
  m => MonadCatch (RaftSocketT v m)\nderiving instance MonadConc m => MonadMask (RaftSocketT
  v m)\nderiving instance MonadConc m => MonadConc (RaftSocketT v m)\n```\n\n### Implement
  the persistent layer\n\nThere are many different possibilities when it comes to
  persist data to disk, so\nwe also leave the specification open to the user.\n\nAs
  explained in the [Persistent\nState](https://github.com/adjoint-io/raft#persistent-state)
  section above, we\nwill create instances for `RaftReadLog`, `RaftWriteLog` and\n`RaftDeleteLog`
  to specify how we will read, write and\ndelete log entries, as well as `RaftPersist`.
  There are actually several data\nthat must be stored on disk; 1) the data the raft
  paper calls \"persistent data\"\nand 2) the log entries of the node.\n\nWe provide
  an implementation that stores the persistent data in a file in\n[src/Examples/Raft/FileStore/Persistent.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/FileStore/Persistent.hs)\n\nAn
  example of storing log entries in a single file (for ease of implementation\nin
  lieu of good performance for reads/writes) can be found in\n[src/Examples/Raft/FileStore/Log.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/FileStore/Log.hs)\n\nLastly,
  a more \"production ready\" example of log entry storage using a\nPostgreSQL database
  can be found in [src/Raft/Log/PostgreSQL.hs](https://github.com/adjoint-io/raft/blob/master/src/Raft/Log/PostgreSQL.hs).\nThis
  implementation is used in our `quickcheck-state-machine` model testing\nmodule and
  is thus thoroughly tested. \n\n### Putting it all together\n\nThe last step is wrapping
  our previous data types that deal with\nnetworking and persistent data into a single
  monad that also derives instances\nof all the Raft type classes described (`RaftSendRPC`,
  `RaftRecvRPC`,\n`RaftSendClient`, `RaftRecvClient`, `RaftReadLog`, `RaftWriteLog`,\n`RaftDeleteLog`
  and `RaftPersist`).\n\nIn our example, this monad is `RaftExampleM sm v`. See\n[app/Main.hs](https://github.com/adjoint-io/raft/blob/master/app/Main.hs).\n\nFinally,
  we are ready to run our Raft nodes. We call the `runRaftNode` function\nfrom the\n[src/Raft.hs](https://github.com/adjoint-io/raft/blob/master/src/Raft.hs)\nfile,
  together with the function we define to run the stack of monads that\nderive our
  Raft type classes.\n\n# Test suite dependencies\n\nThe test suite depends on libfiu
  (commonly installed with package `fiu-utils`), \nwhich it uses to simulate network
  failures. In addition, the test suite also\ndepends on libpq-dev and postgresql.
  Furthermore, in order to successfully run\nthe model tests (which will run autmatically
  when executing `stack test`, but\nfail immediately with \"Failed to spawn node),
  you will have to run the following\ncommand:\n\n```\n$ sudo -su postgres psql -U
  postgres -c \"CREATE USER libraft_test WITH CREATEDB PASSWORD 'libraft_test';\"
  \n```\n\n# References\n\n1. Ongaro, D., Ousterhout, J. [In Search of an Understandable
  Consensus\n   Algorithm](https://raft.github.io/raft.pdf), 2014\n\n2. Howard, H.
  [ARC: Analysis of Raft\n   Consensus](https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-857.pdf)
  2014\n"
description-type: markdown
hash: 678adfd09dd2974108f8415c6f76006317e00f7fbc18c036f7f98859cf9f1708
homepage: https://github.com/adjoint-io/raft#readme
latest: 0.5.0.0
license-name: BSD-3-Clause
maintainer: info@adjoint.io
synopsis: Raft consensus algorithm
test-bench-deps:
  QuickCheck: '>=0'
  async: '>=0'
  atomic-write: '>=0'
  attoparsec: '>=0'
  base: '>=4.7 && <5'
  base16-bytestring: '>=0'
  bytestring: '>=0'
  cereal: '>=0'
  concurrency: '>=1.3.0.0'
  containers: '>=0'
  cryptohash-sha256: '>=0'
  dejafu: '>=0'
  directory: '>=0'
  ekg: '>=0'
  ekg-core: '>=0'
  exceptions: '>=0'
  file-embed: '>=0'
  filepath: '>=0'
  haskeline: '>=0'
  libraft: '>=0'
  lifted-base: '>=0'
  monad-control: '>=0'
  monad-metrics: '>=0'
  mtl: '>=0'
  network: '>=0'
  network-simple: '>=0'
  parsec: '>=0'
  postgresql-simple: '>=0'
  process: '>=1.6.3.0'
  protolude: '>=0'
  quickcheck-state-machine: '>=0'
  random: '>=0'
  repline: '>=0'
  stm: '>=0'
  tasty: '>=0'
  tasty-dejafu: '>=0'
  tasty-discover: '>=0'
  tasty-expected-failure: '>=0'
  tasty-hunit: '>=0'
  tasty-quickcheck: '>=0'
  text: '>=0'
  time: '>=0'
  transformers: '>=0'
  transformers-base: '>=0'
  tree-diff: '>=0'
  unordered-containers: '>=0'
  word8: '>=0'
