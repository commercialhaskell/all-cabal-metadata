homepage: https://github.com/adjoint-io/raft#readme
changelog-type: markdown
hash: f0819966a8f16b70396135ef6e4dd0a6859a4faed944501da6f07214bc9aee2f
test-bench-deps:
  exceptions: -any
  cereal: -any
  bytestring: -any
  haskeline: -any
  hunit-dejafu: -any
  base: ! '>=4.7 && <5'
  time: -any
  tasty-discover: -any
  tasty-expected-failure: -any
  network-simple: -any
  text: -any
  network: -any
  word8: -any
  parsec: -any
  libraft: -any
  protolude: -any
  repline: -any
  containers: -any
  tasty-dejafu: -any
  tasty-quickcheck: -any
  concurrency: -any
  mtl: -any
  tasty-hunit: -any
  attoparsec: -any
  transformers: -any
  random: -any
  tasty: -any
  QuickCheck: -any
  dejafu: -any
  directory: -any
maintainer: info@adjoint.io
synopsis: Raft consensus algorithm
changelog: ! '# Changelog for raft


  ## Unreleased changes

'
basic-deps:
  exceptions: -any
  cereal: -any
  bytestring: -any
  haskeline: -any
  stm: -any
  base: ! '>=4.7 && <5'
  time: -any
  network-simple: -any
  text: -any
  network: -any
  word8: -any
  parsec: -any
  libraft: -any
  protolude: -any
  repline: -any
  containers: -any
  concurrency: -any
  mtl: -any
  attoparsec: -any
  transformers: -any
  random: -any
  directory: -any
all-versions:
- '0.1.0.0'
- '0.1.1.0'
author: Adjoint Inc.
latest: '0.1.1.0'
description-type: markdown
description: ! "<p align=\"center\">\n  <a href=\"http://www.adjoint.io\"><img src=\"https://www.adjoint.io/assets/img/adjoint-logo@2x.png\"
  width=\"250\"/></a>\n</p>\n\n[![CircleCI](https://circleci.com/gh/adjoint-io/raft.svg?style=svg&circle-token=71138966721e3459d81362f6f379a4782a3f6b7d)](https://circleci.com/gh/adjoint-io/raft)\n\n#
  Raft\n\nAdjoint's implementation of the Raft consensus algorithm. See [original\npaper](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf)\nfor
  further details about the protocol.\n\n# Overview\n\nRaft proposes a strong single-leader
  approach to consensus. It simplifies\noperations, as there are no conflicts, while
  being more efficient than other\nleader-less approaches due to the high throughput
  achievable by the leader. In\nthis leader-driven consensus algorithm, clients must
  contact the leader directly\nin order to communicate with the system. The system
  needs to have an\nelected leader in order to be available.\n\nIn addition to a pure
  core event loop, this library uses the systematic\nconcurrency testing library\n[dejafu](https://hackage.haskell.org/package/dejafu-1.11.0.3)
  to test\ncertain properties about streams of events throughout the system. Random
  thread\ninterleavings are generated in a raft network and realistic event\nstreams
  are delivered to each node's event queue. We test for the absence of\ndeadlocks
  and exceptions, along with checking that the convergent state of the\nsystem matches
  the expected results. These concurrency tests can be found\n[here](https://github.com/adjoint-io/raft/blob/master/test/TestDejaFu.hs).\n\n##
  Ensuring valid transitions between node states\n\nEach server in Raft can only be
  in one of these three states:\n\n- Leader: Active node that handles all client interactions
  and send\n  AppendEntries RPCs to all other nodes.\n- Candidate: Active node that
  attempts to become a leader.\n- Follower: Passive node that just responds to RPCs.\n\nTemporal
  (e.g. ElectionTimeout) and spatial (e.g. AppendEntries or RequestVote)\nevents cause
  nodes to transition from one state to another.\n\n```\n    [0]                     [1]
  \                      [2]\n------------> Follower --------------> Candidate -------------->
  Leader\n               ^  ^                       |                        |\n               |
  \ |         [3]           |                        |\n               |  |_______________________|
  \                       |\n               |                                                   |\n
  \              |                                 [4]               |\n               |___________________________________________________|\n\n-
  [0] Starts up | Recovers\n- [1] Times out | Starts election\n- [2] Receives votes
  from majority of servers and becomes leader\n- [3] Discovers leader of new term
  | Discovers candidate with a higher term\n- [4] Discovers server with higher term\n```\n\nAll
  nodes in the Raft protocol begin in the follower state. A follower will stay\na
  follower unless it fails to hear from a leader or a candidate requesting a\nvote
  within its ElectionTimeout timer. If this happens, a follower will\ntransition to
  a candidate state. These node states are illustrated in the type:\n\n```haskell\ndata
  Mode\n  = Follower\n  | Candidate\n  | Leader\n```\n\nThe volatile state a node
  keeps track of may vary depending on the mode that it\nis in. Using `DataKinds`
  and `GADTs`, we relate these specific node state\ndatatypes that contain the relevant
  data to the current node's mode with the\n`NodeState` type. This way, we can enforce
  that the volatile state carried by a\nnode in mode `Follower` is indeed `FollowerState`,
  etc:\n\n```haskell\n-- | The volatile state of a Raft Node\ndata NodeState (a ::
  Mode) where\n  NodeFollowerState :: FollowerState -> NodeState 'Follower\n  NodeCandidateState
  :: CandidateState -> NodeState 'Candidate\n  NodeLeaderState :: LeaderState -> NodeState
  'Leader\n```\n\nThe library's main event loop is comprised of a simple flow: Raft
  nodes receive\nevents on an STM channel, handle the event depending on the current
  node state,\nreturn a list of actions to perform, and then perform those actions
  in the order\nthey were generated. The `Event` type specifies the main value to
  which raft\nnodes react to, whereas the `Action` type specifies the action the raft
  node\nperforms as a result of the pairing of the current node state and received\nevent.\n\nThe
  Raft protocol has constraints on how nodes transition from one state to\nanother.
  For example, a follower cannot transition to a leader state\nwithout first transitioning
  to a candidate state. Similarly, a leader can\nnever transition directly to a candidate
  state due to the algorithm\nspecification. Candidates are allowed to transition
  to any other node state.\n\nTo adhere to the Raft specification, we make use of
  some type level programming\nto ensure that only valid transitions happen between
  node states.\n\n```haskell\n-- | All valid state transitions of a Raft node\ndata
  Transition (init :: Mode) (res :: Mode) where\n  StartElection            :: Transition
  'Follower 'Candidate\n  HigherTermFoundFollower  :: Transition 'Follower 'Follower\n\n
  \ RestartElection          :: Transition 'Candidate 'Candidate\n  DiscoverLeader
  \          :: Transition 'Candidate 'Follower\n  HigherTermFoundCandidate :: Transition
  'Candidate 'Follower\n  BecomeLeader             :: Transition 'Candidate 'Leader\n\n
  \ SendHeartbeat            :: Transition 'Leader 'Leader\n  DiscoverNewLeader        ::
  Transition 'Leader 'Follower\n  HigherTermFoundLeader    :: Transition 'Leader 'Follower\n\n
  \ Noop :: Transition init init\n```\n\nTo compose the `Transition` with the resulting
  state from the event handler, we\nuse the `ResultState` datatype, existentially
  quantifying the result state mode:\n\n```haskell\n-- | Existential type hiding the
  result type of a transition, fixing the\n-- result state to the state dictated by
  the 'Transition init res' value.\ndata ResultState init v where\n  ResultState ::
  Transition init res -> NodeState res -> ResultState init\n```\n\nThis datatype fixes
  the result state to be dependent on the transition that\noccurred; as long as the
  allowed transitions are correctly denoted in the\n`Transition` data constructors,
  only valid transitions can be specified by the\n`ResultState`. Furthermore, `ResultState`
  values existentially hide the result\nstate types, that can be accessed via pattern
  matching. Thus, all event\nhandlers, be they RPC handlers, timeout handlers, or
  client request handlers,\nhave a type signature of the form:\n\n```haskell\nhandler
  :: NodeState init -> ... relevant handler data ... -> ResultState init\n```\n\nStatically,
  the `ResultState` will enforce that invalid transitions are not made\nwhen writing
  handlers for all combinations of raft node modes and events. In the\nfuture, this
  approach may be extended to limit the actions a node can emit\ndependent on its
  current mode.\n\n## Library Architecture\n\nWithin the Raft protocol, there is a
  pure core that can be abstracted without\nthe use of global state. The protocol
  can be looked at simply as a series\nof function calls of a function from an initial
  node state to a result node\nstate. However, sometimes these transitions have *side
  effects*. In this library\nwe have elected to separate the *pure* and **effectful**
  layers.\n\nThe core event handling loop is a *pure* function that, given the current
  node\nstate and a few extra bits of global state, computes a list of `Action`s for
  the\neffectful layer to perform (updating global state, sending a message to another\nnode
  over the network, etc.).\n\n### Pure Layer\n\nIn order to update the replicated
  state machine, clients contact the leader via\n\"client requests\" containing commands
  to be committed to the replicated state\nmachine. Once a command is received, the
  current leader assesses whether it is\npossible to commit the command to the replicated
  state machine.\n\nThe replicated state machine must be deterministic such that every
  command\ncommitted by a leader to the state machine will eventually be replicated
  on\nevery node in the network at the same index.\n\nAs the only part of the internal
  event loop that needs to be specified manually,\nWe ask users of our library to
  provide an instance of the `StateMachine`\ntypeclass. This typeclass relates a state
  machine type to a command type\nand a single type class function 'applyCommittedLogEntry',
  a pure function that\nshould return the result of applying the command to the initial
  state machine.\n\n```haskell\nclass StateMachine sm v | sm -> v where\n  applyCommittedLogEntry
  :: sm -> v -> sm\n```\n\nEverything else related to the core event handling loop
  is not exposed to\nlibrary users. All that needs to be specified is the type of
  the state machine,\nthe commands to update it, and how to perform those updates.\n\n###
  Effectful Layers\n\nIn the protocol, there are two main components that need access
  to global\nstate and system resources. Firstly, raft nodes must maintain some persistent\nstate
  for efficient and correct recovery from network outages or partitions.\nSecondly,
  raft nodes need to send messages to other raft nodes for the network\n(the replicated
  state machine) to be operational.\n\n#### Persistent State\n\nEach node persists
  data to disk, including the replicated log\nentries. Since persisting data is an
  action that programmers have many opinions\nand preferences regarding, we provide
  two type classes that abstract the\nspecifics of writing log entries to disk as
  well as a few other small bits of\nrelevant data. These are separated due to the
  nature in which the log entries\nare queried, often by specific index and without
  bounds. Thus, it may be\ndesirable to store the log entries in an efficient database.
  The remaining\npersistent data is always read and written atomically, and has a
  much smaller\nstorage footprint.\n\nThe actions of reading or modifying existing
  log entries on disk is broken down\neven further: we ask the user to specify how
  to write, delete, and read\nlog entries from disk. Often these types of operations
  can be optimized via\nsmarter persistent data solutions like modern SQL databases,
  thus we arrive at\nthe following level of granularity:\n\n```haskell\n-- | The type
  class specifying how nodes should write log entries to storage.\nclass Monad m =>
  RaftWriteLog m v where\n  type RaftWriteLogError m\n  -- | Write the given log entries
  to storage\n  writeLogEntries\n    :: Exception (RaftWriteLogError m)\n    => Entries
  v -> m (Either (RaftWriteLogError m) ())\n\n-- | The type class specifying how nodes
  should delete log entries from storage.\nclass Monad m => RaftDeleteLog m v where\n
  \ type RaftDeleteLogError m\n  -- | Delete log entries from a given index; e.g.
  'deleteLogEntriesFrom 7'\n  -- should delete every log entry\n  deleteLogEntriesFrom\n
  \   :: Exception (RaftDeleteLogError m)\n    => Index -> m (Either (RaftDeleteLogError
  m) (Maybe (Entry v)))\n\n-- | The type class specifying how nodes should read log
  entries from storage.\nclass Monad m => RaftReadLog m v where\n  type RaftReadLogError
  m\n  -- | Read the log at a given index\n  readLogEntry\n    :: Exception (RaftReadLogError
  m)\n    => Index -> m (Either (RaftReadLogError m) (Maybe (Entry v)))\n  -- | Read
  log entries from a specific index onwards\n  readLogEntriesFrom\n    :: Exception
  (RaftReadLogError m)\n    => Index -> m (Either (RaftReadLogError m) (Entries v))\n
  \ -- | Read the last log entry in the log\n  readLastLogEntry\n    :: Exception
  (RaftReadLogError m)\n    => m (Either (RaftReadLogError m) (Maybe (Entry v)))\n```\n\nTo
  read and write the `PersistentData` type (the remaining persistent data that\nis
  not log entries), we ask the user to use the following `RaftPersist`\ntypeclass.\n\n```haskell\n--
  | The RaftPersist type class specifies how to read and write the persistent\n--
  state to disk.\n--\nclass Monad m => RaftPersist m where\n  type RaftPersistError
  m\n  readPersistentState\n    :: Exception (RaftPersistError m)\n    => m (Either
  (RaftPersistError m) PersistentState)\n  writePersistentState\n    :: Exception
  (RaftPersistError m)\n    => PersistentState -> m (Either (RaftPersistError m) ())\n```\n\n###
  Networking\n\nThe other non-deterministic, effectful part of the protocol is the
  communication\nbetween nodes over the network. It can be unreliable due to network
  delays,\npartitions and packet loss, duplication and reordering, but the Raft consensus\nalgorithm
  was designed to achieve consensus in such harsh conditions.\n\nThe actions that
  must be performed in the networking layer are *sending RPCs* to\nother raft nodes,
  *receiving RPCs* from other raft nodes, *sending client\nresponses* to clients who
  have issued requests, and *receiving client requests*\nfrom clients wishing to update
  the replicated state. Depending on use of this\nraft library, the two pairs are
  not necessary symmetric and so we do not\nforce the user into specifying a single
  way to send/receive messages to and from\nraft nodes or clients.\n\nWe provide several
  type classes for users to specify the networking layer\nthemselves. The user must
  make sure that the `sendRPC`/`receiveRPC` and\n`sendClient`/`receiveClient` pairs
  perform complementary actions; that an RPC\nsent from one raft node to another is
  indeed receivable via `receiveRPC` on the\nnode to which it was sent:\n\n```haskell\n--
  | Provide an interface for nodes to send messages to one\n-- another. E.g. Control.Concurrent.Chan,
  Network.Socket, etc.\nclass RaftSendRPC m v where\n  sendRPC :: NodeId -> RPCMessage
  v -> m ()\n\n-- | Provide an interface for nodes to receive messages from one\n--
  another\nclass RaftRecvRPC m v where\n  receiveRPC :: m (RPCMessage v)\n\n-- | Provide
  an interface for Raft nodes to send messages to clients\nclass RaftSendClient m
  sm where\n  sendClient :: ClientId -> ClientResponse sm -> m ()\n\n-- | Provide
  an interface for Raft nodes to receive messages from clients\nclass RaftRecvClient
  m v where\n  receiveClient :: m (ClientRequest v)\n```\n\nWe have written a default
  implementation for network sockets over TCP in\n[src/Examples/Raft/Socket](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket)\n\n#
  Run example\n\nWe provide a complete example of the library where nodes communicate
  via network\nsockets, and they write their logs on text files. See\n[app/Main.hs](https://github.com/adjoint-io/raft/blob/master/app/Main.hs)
  to\nhave further insight.\n\n1) Build the example executable:\n```$ stack build
  ```\n\n2) In separate terminals, run some raft nodes:\n\n    The format of the cmd
  line invocation is:\n    ``` raft-example <node-id> <peer-1-node-id> ... <peer-n-node-id>
  ```\n\n    We are going to run a network of three nodes:\n\n    - On terminal 1:\n
  \   ```$ stack exec raft-example localhost:3001 localhost:3002 localhost:3003```\n\n
  \   - On terminal 2:\n    ```$ stack exec raft-example localhost:3002 localhost:3001
  localhost:3003```\n\n    - On terminal 3:\n    ```$ stack exec raft-example localhost:3003
  localhost:3001 localhost:3002```\n\n    The first node spawned should become candidate
  once its election's timer\n    times out and request votes to other nodes. It will
  then become the leader,\n    once it receives a majority of votes and will broadcast
  messages to all\n    nodes at each heartbeat.\n\n3) Run a client:\n```$ stack exec
  raft-example client```\n\n    In the example provided, there are five basic operations:\n\n
  \     - `addNode <host:port>`: Add a nodeId to the set of nodeIds that the client\n
  \       will communicate with. Adding a single node will be sufficient, as this
  node\n        will redirect the command to the leader in case he is not.\n\n      -
  `getNodes`: Return all node ids that the client is aware of.\n\n      - `read`:
  Return the state of the leader.\n\n      - `set <var> <val>`: Set a variable to
  a specific value.\n\n      - `incr <var>`: Increment the value of a variable.\n\n
  \   Assuming that two nodes are run as mentioned above, a valid client workflow\n
  \   would be:\n    ```\n    >>> addNode localhost:3001\n    >>> set testVar 4\n
  \   >>> incr testVar\n    >>> read\n    ```\n\n    It will return the state of the
  leader's state machine (and eventually the state\n    of all nodes in the Raft network).
  In our example, it will be a map of a single\n    key `testVar` of value `4`\n\n##
  How to use this library\n\n1. [Define the state\nmachine](https://github.com/adjoint-io/raft#define-the-state-machine)\n2.
  [Implement the networking\nlayer](https://github.com/adjoint-io/raft#implement-the-networking-layer)\n3.
  [Implement the persistent\nlayer](https://github.com/adjoint-io/raft#implement-the-persistent-layer)\n4.
  [Putting it all\ntogether](https://github.com/adjoint-io/raft#putting-it-all-together)\n\n###
  Define the state machine\n\nThe only requirement for our state machine is to instantiate
  the `StateMachine`\ntype class.\n\n```haskell\nclass StateMachine sm v | sm -> v
  where\n  applyCommittedLogEntry :: sm -> v -> sm\n```\n\nIn our [example](https://github.com/adjoint-io/raft/blob/master/app/Main.hs)
  we\nuse a simple map as a store whose values can only increase.\n\n### Implement
  the networking layer\n\nWe leave the choice of the networking layer open to the
  user, as it can vary\ndepending on the use case (E.g. TCP/UDP/cloud-haskell/etc).\n\nWe
  need to specify how nodes will communicate with clients and with each other.\nAs
  described above in the [Networking\nsection](https://github.com/adjoint-io/raft#networking),
  it suffices to\nimplement those four type classes (`RaftSendRPC`, `RaftRecvRPC`,\n`RaftSendClient`,
  `RaftRecvClient`).\n\nIn our example, we provide instances of nodes communicating
  over TCP to other\nnodes\n([Socket/Node.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket/Node.hs))\nand
  clients\n([Socket/Client.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/Socket/Client.hs)).\n\nNote
  that our datatypes will need to derive instances of `MonadThrow`,\n`MonadCatch`,
  `MonadMask` and `MonadConc`. This allows us to test concurrent\nproperties of the
  system, using randomized thread scheduling to assert the\nabsence of deadlocks and
  exceptions.\n\nIn case of the `RaftSocketT` data type used in our example:\n\n```haskell\nderiving
  instance MonadConc m => MonadThrow (RaftSocketT v m)\nderiving instance MonadConc
  m => MonadCatch (RaftSocketT v m)\nderiving instance MonadConc m => MonadMask (RaftSocketT
  v m)\nderiving instance MonadConc m => MonadConc (RaftSocketT v m)\n```\n\n### Implement
  the persistent layer\n\nThere are many different possibilities when it comes to
  persist data to disk, so\nwe also leave the specification open to the user.\n\nAs
  explained in the [Persistent\nState](https://github.com/adjoint-io/raft#persistent-state)
  section above, we\nwill create instances for `RaftReadLog`, `RaftWriteLog` and\n`RaftDeleteLog`
  to specify how we will read, write and\ndelete log entries, as well as `RaftPersist`.\n\nWe
  provide an implementation that stores persistent data on files in\n[FileStore.hs](https://github.com/adjoint-io/raft/blob/master/src/Examples/Raft/FileStore.hs)\n\n###
  Putting it all together\n\nThe last step is wrapping our previous data types that
  deal with\nnetworking and persistent data into a single monad that also derives
  instances\nof all the Raft type classes described (`RaftSendRPC`, `RaftRecvRPC`,\n`RaftSendClient`,
  `RaftRecvClient`, `RaftReadLog`, `RaftWriteLog`,\n`RaftDeleteLog` and `RaftPersist`).\n\nIn
  our example, this monad is `RaftExampleM sm v`. See\n[app/Main.hs](https://github.com/adjoint-io/raft/blob/master/app/Main.hs).\n\nFinally,
  we are ready to run our Raft nodes. We call the `runRaftNode` function\nfrom the\n[src/Raft.hs](https://github.com/adjoint-io/raft/blob/master/src/Raft.hs)\nfile,
  together with the function we define to run the stack of monads that\nderive our
  Raft type classes.\n\n# References\n\n1. Ongaro, D., Ousterhout, J. [In Search of
  an Understandable Consensus\n   Algorithm](https://raft.github.io/raft.pdf), 2014\n\n2.
  Howard, H. [ARC: Analysis of Raft\n   Consensus](https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-857.pdf)
  2014\n"
license-name: BSD3
