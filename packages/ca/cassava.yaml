homepage: https://github.com/hvr/cassava
changelog-type: markdown
hash: aa7e296da9573e0567a9160a997a39d48c3c76ce93733b5e10c4300327a408f8
test-bench-deps:
  test-framework-hunit: ==0.3.*
  bytestring: -any
  test-framework: ==0.8.*
  base: -any
  unordered-containers: -any
  text: -any
  test-framework-quickcheck2: ==0.3.*
  HUnit: <1.7
  quickcheck-instances: '>=0.3.12 && <0.4'
  cassava: -any
  hashable: -any
  attoparsec: -any
  scientific: -any
  QuickCheck: '>=2.13 && <2.15'
  vector: -any
maintainer: hvr@gnu.org
synopsis: A CSV parsing and encoding library
changelog: |
  ## Version 0.5.2.0

   * Add `FromField`/`ToField` instances for `Identity` and `Const` (#158)
   * New `typeclass`-less decoding functions `decodeWithP` and `decodeByNameWithP` (#67,#167)
   * Support for final phase of MFP / base-4.13

  ## Version 0.5.1.0

   * Add `FromField`/`ToField` instance for `Natural` (#141,#142)
   * Add `FromField`/`ToField` instances for `Scientific` (#143,#144)
   * Add support for modifying Generics-based instances (adding
     `Options`, `defaultOptions`, `fieldLabelModifier`,
     `genericParseRecord`, `genericToRecord`, `genericToNamedRecord`,
     `genericHeaderOrder`) (#139,#140)
   * Documentation improvements

  ## Version 0.5.0.0

  ### Semantic changes

   * Don't unecessarily quote spaces with `QuoteMinimal` (#118,#122,#86)
   * Fix semantics of `foldl'` (#102)
   * Fix field error diagnostics being mapped to `endOfInput` in `Parser` monad. (#99)
   * Honor `encIncludeHeader` in incremental API (#136)

  ### Other changes

   * Support GHC 8.2.1
   * Use factored-out `Only` package
   * Add `FromField`/`ToField` instance for `ShortText`
   * Add `MonadFail` and `Semigroup` instance for `Parser`
   * Add `Semigroup` instance for incremental CSV API `Builder` & `NamedBuilder`
   * Port to `ByteString` builder & drop dependency on `blaze-builder`

  ## Version 0.4.5.1

   * Restore GHC 7.4 support (#124)

  ## Version 0.4.5.0

   * Support for GHC 8.0 added; support for GHC 7.4 dropped

   * Fix defect in `Foldable(foldr)` implementation failing to skip
     unconvertable records (#102)

   * Documentation fixes

   * Maintainer changed

  ## Version 0.4.4.0

   * Added record instances for larger tuples.

   * Support attoparsec 0.13.

   * Add field instances for short bytestrings.

  ## Version 0.4.3.0

   * Documentation overhaul with more examples.

   * Add Data.Csv.Builder, a low-level bytestring builder API.

   * Add a high-level builder API to Data.Csv.Incremental.

   * Generalize the default FromNamedRecord/ToNamedRecord instances.

   * Improved support for deriving instances using GHC.Generics.

   * Added some control over quoting.

  ## Version 0.4.2.4

   * Support attoparsec 0.13.

  ## Version 0.4.2.3

   * Support GHC 7.10.

  ## Version 0.4.2.2

   * Support blaze-builder 0.4.

   * Make sure inlining doesn't prevent rules from firing.

   * Fix incorrect INLINE pragmas.

  ## Version 0.4.2.1

   * Support deepseq-1.4.

  ## Version 0.4.2.0

   * Minor performance improvements.

   * Add 8 and 9 tuple instances for From/ToRecord.

   * Support text-1.2.

  ## Version 0.4.1.0

   * Ignore whitespace when converting numeric fields.

   * Accept \r as a line terminator.

   * Support attoparsec-0.12.
basic-deps:
  Only: '>=0.1 && <0.1.1'
  bytestring: '>=0.9.2 && <0.10.4'
  base: '>=4.5 && <4.15'
  unordered-containers: <0.3
  text: <1.3
  array: '>=0.4 && <0.6'
  containers: '>=0.4.2 && <0.7'
  hashable: <1.4
  attoparsec: '>=0.11.3.0 && <0.14'
  transformers: '>=0.2 && <0.6'
  deepseq: '>=1.1 && <1.5'
  scientific: '>=0.3.4.7 && <0.4'
  bytestring-builder: '>=0.10.8 && <0.11'
  vector: '>=0.8 && <0.13'
all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.2.0.0
- 0.2.1.0
- 0.2.1.1
- 0.2.1.2
- 0.2.2.0
- 0.3.0.0
- 0.3.0.1
- 0.4.0.0
- 0.4.1.0
- 0.4.2.0
- 0.4.2.1
- 0.4.2.2
- 0.4.2.3
- 0.4.2.4
- 0.4.3.0
- 0.4.3.1
- 0.4.4.0
- 0.4.5.0
- 0.4.5.1
- 0.5.0.0
- 0.5.1.0
- 0.5.2.0
author: Johan Tibell
latest: 0.5.2.0
description-type: markdown
description: "# `cassava`: A CSV parsing and encoding library [![Hackage](https://img.shields.io/hackage/v/cassava.svg)](https://hackage.haskell.org/package/cassava)
  [![Build Status](https://travis-ci.org/hvr/cassava.svg)](https://travis-ci.org/hvr/cassava)\n\n**Please
  refer to the [package description](https://hackage.haskell.org/package/cassava#description)
  for an overview of `cassava`.**\n\n## Usage example\n\nHere's the two second crash
  course in using the library. Given a CSV file with this content:\n\n```csv\nJohn
  Doe,50000\nJane Doe,60000\n```\n\nhere's how you'd process it record-by-record:\n\n```haskell\n{-#
  LANGUAGE ScopedTypeVariables #-}\n\nimport qualified Data.ByteString.Lazy as BL\nimport
  Data.Csv\nimport qualified Data.Vector as V\n\nmain :: IO ()\nmain = do\n    csvData
  <- BL.readFile \"salaries.csv\"\n    case decode NoHeader csvData of\n        Left
  err -> putStrLn err\n        Right v -> V.forM_ v $ \\ (name, salary :: Int) ->\n
  \           putStrLn $ name ++ \" earns \" ++ show salary ++ \" dollars\"\n```\n\nIf
  you want to parse a file that includes a header, like this one\n\n```csv\nname,salary\nJohn
  Doe,50000\nJane Doe,60000\n```\n\nuse [`decodeByName`](https://hackage.haskell.org/package/cassava/docs/Data-Csv.html#v:decodeByName):\n\n```haskell\n{-#
  LANGUAGE OverloadedStrings #-}\n\nimport Control.Applicative\nimport qualified Data.ByteString.Lazy
  as BL\nimport Data.Csv\nimport qualified Data.Vector as V\n\ndata Person = Person\n
  \   { name   :: !String\n    , salary :: !Int\n    }\n\ninstance FromNamedRecord
  Person where\n    parseNamedRecord r = Person <$> r .: \"name\" <*> r .: \"salary\"\n\nmain
  :: IO ()\nmain = do\n    csvData <- BL.readFile \"salaries.csv\"\n    case decodeByName
  csvData of\n        Left err -> putStrLn err\n        Right (_, v) -> V.forM_ v
  $ \\ p ->\n            putStrLn $ name p ++ \" earns \" ++ show (salary p) ++ \"
  dollars\"\n```\n\nYou can find more code examples in the [`examples/` folder](https://github.com/hvr/cassava/tree/master/examples)
  as well as smaller usage examples in the [`Data.Csv` module documentation](https://hackage.haskell.org/package/cassava/docs/Data-Csv.html).\n\n##
  Project Goals for `cassava`\n\nThere's no end to what people consider CSV data.
  Most programs don't\nfollow [RFC4180](https://tools.ietf.org/html/rfc4180) so one
  has to\nmake a judgment call which contributions to accept.  Consequently, not\neverything
  gets accepted, because then we'd end up with a (slow)\ngeneral purpose parsing library.
  There are plenty of those. The goal\nis to roughly accept what the Python\n[`csv`](https://docs.python.org/3/library/csv.html)
  module accepts.\n\nThe Python `csv` module (which is implemented in C) is also considered\nthe
  base-line for performance.  Adding options (e.g. the above\nmentioned parsing \"flexibility\")
  will have to be a trade off against\nperformance. There's been complaints about
  performance in the past,\ntherefore, if in doubt performance wins over features.\n\nLast
  but not least, it's important to keep the dependency footprint\nlight, as each additional
  dependency incurs costs and risks in terms\nof additional maintenance overhead and
  loss of flexibility. So adding\na new package dependency should only be done if
  that dependency is\nknown to be a reliable package and there's a clear benefit which\noutweights
  the cost.\n\n## Further reading\n\nThe primary API documentation for `cassava` is
  its Haddock documentation which can be found at http://hackage.haskell.org/package/cassava/docs/Data-Csv.html
  \n\nBelow are listed additional recommended third-party blogposts and tutorials\n\n
  - [CSV encoding and decoding in Haskell with Cassava](https://www.stackbuilders.com/tutorials/haskell/csv-encoding-decoding/)\n"
license-name: BSD-3-Clause
