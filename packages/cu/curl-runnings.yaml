homepage: https://github.com/aviaviavi/curl-runnings#readme
changelog-type: ''
hash: 06f705008d2e9a04293d50b7360af5484a6d95df39109acd6e78b0209476bcf1
test-bench-deps:
  base: ! '>=4.0 && <5'
  hspec: ! '>=2.4.4'
  curl-runnings: -any
  hspec-expectations: ! '>=0.8.2'
  directory: ! '>=1.3.0.2'
maintainer: mail@avi.press
synopsis: A framework for declaratively writing curl based API tests
changelog: ''
basic-deps:
  bytestring: ! '>=0.10.8.2'
  case-insensitive: ! '>=0.2.1'
  base: ! '>=4.7 && <5'
  unordered-containers: ! '>=0.2.8.0'
  hspec: ! '>=2.4.4'
  text: ! '>=1.2.2.2'
  megaparsec: ! '>=7.0.4'
  connection: ! '>=0.2.8'
  tar: ! '>=0.5.0.3'
  http-client-tls: ! '>=0.3.5.3'
  regex-posix: ! '>=0.95.2'
  zlib: ! '>=0.6.1.2'
  cmdargs: ! '>=0.10.20'
  pretty-simple: ! '>=2.0.2.1'
  http-conduit: ! '>=2.3.6'
  aeson: ! '>=1.2.4.0'
  curl-runnings: -any
  yaml: ! '>=0.8.28'
  vector: ! '>=0.12.0'
  hspec-expectations: ! '>=0.8.2'
  directory: ! '>=1.3.0.2'
all-versions:
- 0.1.0
- 0.2.0
- 0.3.0
- 0.6.0
- 0.9.2
- 0.10.0
- 0.11.0
- 0.11.1
author: Avi Press
latest: 0.11.1
description-type: markdown
description: "# curl-runnings\n\n[![Build Status](https://travis-ci.org/aviaviavi/curl-runnings.svg?branch=master)](https://travis-ci.org/aviaviavi/curl-runnings)
  \n[![Hackage](https://img.shields.io/hackage/v/curl-runnings.svg)](https://hackage.haskell.org/package/curl-runnings)\n[![Scarf](https://scarf.sh/package/badge/curl-runnings)](https://scarf.sh/package/avi/curl-runnings)\n\n_Feel
  the rhythm! Feel the rhyme! Get on up, it's testing time! curl-runnings!_\n\ncurl-runnings
  is a framework for writing declarative, curl based tests for your\nAPIs. Write your
  tests quickly and correctly with a straight-forward\nspecification in yaml or json
  that can encode simple but powerful matchers\nagainst responses.\n\nAlternatively,
  you can use the curl-runnings library to write your tests in\nHaskell (though a
  Haskell setup is absolutely not required to use this tool).\n\n### Why?\n\nThis
  library came out of a pain-point my coworkers at\n[DotDashPay](https://dotdashpay.com)
  and I were running into during development:\nWriting integration tests for our APIs
  was generally annoying. They were time\nconsuming to write especially considering
  how basic they were, and we are a\nsmall startup where developer time is in short
  supply. Over time, we found\nourselves sometimes just writing bash scripts that
  would `curl` our various\nendpoints and check the output with very basic matchers.
  These tests were fast\nto write, but quickly became difficult to maintain as complexity
  was added. Not\nonly did maintenance become challenging, but the whole system was
  very error prone\nand confidence in the tests overall was decreasing. At the end
  of the day, we\nneeded to just curl some endpoints and verify the output looks sane,
  and do this\nquickly and correctly. This is precisely the goal of curl-runnings.\n\nNow
  you can write your tests just as data in a yaml or json file,\nand curl-runnings
  will take care of the rest!\n\nWhile yaml/json is the current way to write curl-runnings
  tests, this project is\nbeing built in a way that should lend itself well to an
  embedded domain specific\nlanguage, which is a future goal for the project. curl-runnings
  specs in Dhall\nis also being developed and may fulfill the same needs.\n\n### Installing\n\nThe
  best way to install curl-runnings is with the [scarf](https://scarf.sh)\npackage
  manager.\n\n```bash\n# If you don't have scarf, you can easily install it with:\n$
  curl -L https://scarf.sh/install | bash\n \n$ scarf install curl-runnings\n```\n\nAlternatively,
  you can compile from source with stack.\n\n### Writing a test specification\n\nCurl
  runnings tests are just data! A test spec is an object containing an array\nof `cases`,
  where each item represents a single curl and set of assertions about\nthe response.
  Write your tests specs in a yaml or json file. Note: the legacy\nformat of a top
  level array of test cases is still supported, but may not be in\nfuture releases.\n\n\n```yaml\n---\n#
  example-test.yaml\n#\n# specify all your test cases as an array keys on `cases`\ncases:\n
  \ - name: A curl runnings test case\n    url: http://your-endpoint.com/status\n
  \   requestMethod: GET\n    # Specify the json payload we expect here\n    expectData:\n
  \     # The 1 key in this object specifies the matcher we want\n      # to use to
  test the returned payload. In this case, we\n      # require the payload is exactly
  what we specify.\n      exactly:\n        okay: true\n        msg: 'a message'\n
  \   # Assertions about the returned status code. Pass in\n    # an acceptable code
  or list of codes\n    expectStatus: 200\n\n```\n\nSee /examples for more example
  curl runnings specifications, which walk\nthrough some of the other features that
  can be encoded in your tests such as:\n- reference data from previous responses
  of previous test cases\n- reference environment variables\n- various easy-to-use
  json matchers\n- support for importing data from other yaml files in your spec\n\n###
  Running\n\nOnce you've written a spec, simply run it with:\n\n```curl-runnings -f
  path/to/your/spec.yaml ```\n\n(hint: try using the --verbose flag for more output)\n\nIf
  all your tests pass, curl-runnings will cleanly exit with a 0 code. A code of\n1
  will be returned if any tests failed.\n\nYou can also select specific test cases
  by filtering via regex by using the\n`--grep` flag. Just make sure your case isn't
  referencing data from previous\nexamples that won't get run!\n\nFor more info:\n\n```curl-runnings
  --help ```\n\n\n### Running With Docker\nA dockerfile is included in the root of
  the project. The Dockerfile will expect the linux based curl-runnings executable
  in the same directory as the Dockerfile and a `tests.yml` file. You can download
  the latest executable from the release page : https://github.com/aviaviavi/curl-runnings/releases
  .\n\n``` docker build . -t curl-runnings-tests```\n\n```  docker run curl-runnings-tests```\n\nIf
  you use docker-compose, you can add this to docker-compose.yml:\n\n```\ntests:\n
  \   build:\n      context: .\n      dockerfile: ./Dockerfile\n```\n\n\n### Contributing\n\nContributions
  in any form are welcome and encouraged. Don't be shy! :D\n\n"
license-name: MIT
