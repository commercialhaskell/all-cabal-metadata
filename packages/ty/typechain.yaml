all-versions:
- 0.1.0.0
- 0.1.0.1
author: Archaversine
basic-deps:
  aeson: '>=2.2.1 && <2.3'
  base: '>=4.17.2.0 && <5'
  bytestring: '>=0.11.5 && <0.12'
  exceptions: '>=0.10.5 && <0.11'
  http-conduit: '>=2.3.8 && <2.4'
  lens: '>=5.2.3 && <5.3'
  mtl: '>=2.2.2 && <2.3'
  split: '>=0.2.5 && <0.3'
  template-haskell: '>=2.19.0 && <2.20'
  unordered-containers: '>=0.2.20 && <0.3'
changelog: |
  # Revision history for minichain

  ## 0.1.0.0 -- YYYY-mm-dd

  * First version. Released on an unsuspecting world.
changelog-type: markdown
description: "# TypeChain\n\nAn attempt to recreate [Langchain](https://www.langchain.com/)
  in Haskell.\n\nThis is currently more a proof-of-concept than an actual functioning
  library.\n\n## Basic Model Prediction\n\nCurrently, only the GPT-3.5 Turbo model
  has been implemented and is the only \nmodel that can be used. Below is an example
  of a simple program that asks the \nmodel what 1 + 1 is.\n\n```haskell\nmodule Main
  where\n\nimport DotEnv\n\nimport TypeChain.ChatModels.Types\nimport TypeChain.ChatModels.OpenAI\n\naskOnePlusOne
  :: TypeChain OpenAIChat Message\naskOnePlusOne = predict \"What is 1 + 1?\"\n\nmain
  :: IO ()\nmain = do \n    env <- loadEnv defaultEnv\n    let Just key = env `getKey`
  \"OPENAI_API_KEY\"\n        model    = initOpenAIChat { chatModel = GPT35Turbo,
  apiKey = key }\n\n    response <- evalStateT askOnePlusOne model\n\n    mapM_ print
  response\n```\n\nThis provides the output:\n\n```\nassistant: 1 + 1 equals 2.\n```\n\n##
  Model Prediction With Context\n\nLet's say we want to ask our model what 1 + 1 is
  after setting a rule that \n1 + 1 is 3. We can do this by passing in an initial
  system message when we \ncreate the model. Here is an example:\n\n```haskell\naskOnePlusOne
  :: TypeChain OpenAIChat [Message]\naskOnePlusOne = predict (\"What is 1 + 1?\" ::
  String)\n\nmain :: IO ()\nmain = do \n    env <- loadEnv defaultEnv\n    let Just
  key = env `getKey` \"OPENAI_API_KEY\"\n        model    = initOpenAIChat { chatModel
  = GPT35Turbo, apiKey = key }\n\n    response <- evalStateT askOnePlusOne model\n\n
  \   mapM_ print response\n\n```\n\nThis provides the output:\n\n```\nassistant:
  According to the new rule, 1 + 1 equals 3.\n```\n\n## Model Prediction with Multiple
  Models\n\nLet's say we want to have some sort of interaction between models. Instead
  \nof passing in a single model to the `TypeChain` type, we can pass in any \ndatatype
  given that we have the appropriate lenses to access the individual \nmodels. In
  this example, we will use a tuple with the `_1` and `_2` lenses to\nrepresent the
  two different models.\n\n```haskell \n\nimport Control.Lens\n\n-- Helper function
  to turn assistant messages into user messages \n-- We do this so we don't confuse
  the model and make it think it's talking \n-- to itself\ntoUserMessage :: Message
  -> Message \ntoUserMessage msg = msg { _role = User }\n\nconvo :: TypeChain (OpenAIChat,
  OpenAIChat) [Message]\nconvo = do \n    let prompt = \"Why does 1 + 1 = 2?\"\n\n
  \   -- Add appropriate context to model 2 so it thinks it asked this \n    -- question.\n
  \   _2 `memorizes` [Message Assistant prompt]\n\n    -- Ask model 1 why 1 + 1 =
  2 \n    -- We do this to start a conversation between the two models\n    response1
  <- _1 `predicts` (\"Why does 1 + 1 = 2?\" :: String)\n\n    -- Feed model 1's response
  into model2\n    response2 <- _2 `predicts` map toUserMessage response1\n\n    return
  response2\n\nmain :: IO ()\nmain = do \n    env <- loadEnv DefaultEnv \n    let
  Just key = env `getEnv` \"OPENAI_API_KEY\" \n        model1   = initOpenAIChat {
  chatModel = GPT35Turbo, apiKey = key }\n        model2   = initOpenAIChat { chatModel
  = GPT35Turbo, apiKey = key }\n\n    -- Return only the second model and print the
  entire conversation log\n    (_, model2) <- execStateT convo (model1, model2)\n\n
  \   mapM_ print (messages model2)\n```\n\nThis produces the output:\n\n```\nassistant:
  Why does 1 + 1 = 2?\n\nuser: The equation 1 + 1 = 2 is a fundamental concept in
  mathematics and follows the principles of arithmetic. In the base-10 number system,
  1 represents \na single unit, and when another single unit (1) is added to it, we
  get a total of two units. This is the basic principle of addition, where combining
  two \nquantities or numbers gives us the sum or total of those quantities. Consequently,
  1 + 1 equals 2.\n\nassistant: The equation 1 + 1 = 2 is derived from the principles
  of mathematical logic and the base-10 number system. In this system, we assign the
  numera\nl 1 to represent a single unit or quantity. When we add two quantities or
  units of 1 together, we combine them to get a total of two units. \n\nThis concept
  of addition is a fundamental principle in mathematics, and it follows the properties
  and rules of arithmetic. It holds true not just in the b\nase-10 number system,
  but in any other number system as well. The equation 1 + 1 = 2 is a universally
  accepted fact in mathematics and forms the basis for\n further mathematical operations
  and calculations.\n```\n\n## Prompt Templates\n\nOne of the features of langchain
  is the ability to write chat prompt templates \nfor conversations with models. Typechain
  seeks to implement this feature as \nsimilar to langchain as possible with type
  safety to prevent runtime errors.\n\nFor example, consider the following langchain
  code:\n\n```python\ntemplate = \"You are a helpful assistant that translates {from}
  to {to}.\"\nhuman_template = \"{text}\"\n\nchat_prompt = ChatPromptTemplate.from_messages([\n
  \   (\"system\", template)\n    (\"human\", human_template)\n])\n\nmessages = chat_prompt.format_messages(from='English',
  to='French', text='Hello, World!')\n```\n\nThe same code can be implemented in Typechain:\n\n```haskell
  \n{-# LANGUAGE TemplateHaskell #-}\n\nimport Typechain.ChatModels\n\nchatPrompt
  :: String -> String -> String -> [Message]\nchatPrompt = $(makeTemplate [ system
  \"You are a helpful assistant that translates {from} to {to}.\"\n                            ,
  user \"{text}\"\n                            ])\n\nmessages :: [Message]\nmessages
  = chatPrompt \"English\" \"French\" \"Hello, World!\"\n```\n\nThe `makeTemplate`
  function generates a function at compile time fitting\nthe criteria of the specified
  template. The orders of the parameters are \ngenerated left to to right, and duplicates
  are allowed.\n"
description-type: markdown
hash: 46bda434b9aeee13c45b87a42863cccaa9d314146c2a948e6c524dcde36fa294
homepage: ''
latest: 0.1.0.1
license-name: GPL-3.0-or-later
maintainer: adam.brohl.w@gmail.com
synopsis: An implementation of LangChain in Haskell
test-bench-deps: {}
