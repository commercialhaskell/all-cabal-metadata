homepage: ''
changelog-type: markdown
hash: 3053f96d0f64418b30f6f98375dc45ebc1ace4ff574b711de1dd88bc45736aa7
test-bench-deps:
  newtype: -any
  sop-core: -any
  base: -any
  generic-deriving: -any
  json-sop: -any
  tasty-quickcheck: -any
  mtl: -any
  tasty-hunit: -any
  record-hasfield: -any
  transformers: -any
  tasty: -any
  ghc-dump-core: -any
  generics-sop: -any
  record-dot-preprocessor: -any
  QuickCheck: -any
  large-records: -any
  microlens: -any
  aeson: -any
  template-haskell: -any
  vector: -any
maintainer: edsko@well-typed.com
synopsis: Efficient compilation for large records, linear in the size of the record
changelog: |
  # Revision history for large-records

  ## 0.1.0.0 -- 2021-08-19

  * First public release
basic-deps:
  sop-core: -any
  base: '>=4.13 && <4.15'
  text: -any
  syb: -any
  containers: -any
  haskell-src-exts: -any
  mtl: -any
  record-hasfield: -any
  generics-sop: -any
  haskell-src-meta: -any
  microlens: -any
  aeson: -any
  template-haskell: -any
  vector: -any
all-versions:
- 0.1.0.0
author: Edsko de Vries
latest: 0.1.0.0
description-type: haddock
description: |-
  For many reasons, the internal code generated for modules
  that contain records is quadratic in the number of record
  fields. For large records (more than 30 fields, say), this
  can become problematic, leading to large compilation times
  and high memory requirements for ghc. The large-records
  library provides a way to define records that is guaranteed
  to result in ghc core that is /linear/ in the number of
  record fields.
license-name: BSD-3-Clause
