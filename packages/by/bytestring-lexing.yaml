homepage: https://wrengr.org/
changelog-type: text
hash: c7d146063f2efc44a70c103c01fb7421efd3ee353d522a620fec939055d95920
test-bench-deps:
  bytestring: '>=0.9.2.1 && <0.12'
  tasty-smallcheck: '>=0.8.0.1 && <0.9'
  base: '>=4.5 && <5'
  tasty-quickcheck: '>=0.8.3.2 && <0.11'
  tasty: '>=0.10.1.2 && <1.5'
  bytestring-lexing: -any
maintainer: wren@cpan.org
synopsis: Efficiently parse and produce common integral and fractional numbers.
changelog: "0.5.0.7 (2021-10-16):\n    - Switching from TravisCI to GithubActions\n\t-
  Linting Haddock warnings\n\t- Remove some trailing whitespaces\n0.5.0.6 (2019-04-13):\n
  \   - Nudging everything to the correct urls, emails, etc\n0.5.0.2 (2015-05-06):\n
  \   - Fixed the benchmarking url\n0.5.0.1 (2015-05-06):\n    - Cleaned up the README
  file\n0.5.0 (2015-05-06):\n    - Corrected the License field in the .cabal file
  to say BSD2 (instead of BSD3)\n    - Data.ByteString.Lex.{Double,.Lazy.Double}:
  removed\n    - Data.ByteString.Lex.Fractional: added based on the inefficiency of
  the old Alex-based parsers, as demonstrated by Hirotomo Moriwaki's bytestring-read
  (v0.3.0).\n\n0.4.3.3 (2015-05-30):\n    - Moved VERSION to CHANGELOG\n0.4.3.1 (2014-03-07):\n
  \   - Updated the .cabal file to require newer alex for newer ghc.\n0.4.3 (2013-03-21):\n
  \   - Data.ByteString.Lex.Integral: Corrected a segmentation fault in packDecimal.\n0.4.2
  (2013-03-20):\n    - Data.ByteString.Lex.Integral: Improved packDecimal.\n0.4.1
  (2012-00-00):\n    - Data.ByteString.Lex.Integral: Added buffer overflow check for
  asHexadecimal\n0.4.0 (2012-02-03):\n    - Data.ByteString.Lex.Integral: added readDecimal_\n\n0.3.0
  (2012-01-28):\n    - Added Data.ByteString.Lex.Integral\n    - Converted repo to
  Darcs-2 hashed format.\n    - wren ng thornton took over maintainership.\n\n0.2.1
  (2010-02-14):\n0.2 (2008-10-15):\n    - Add support for lexing lazy bytestrings.\n\n0.1.2
  (2008-07-23):\n0.1.0.2 (2008-07-23):\n0.1.0.1 (2008-07-19):\n0.1.0 (2008-07-19):\n"
basic-deps:
  bytestring: '>=0.9.2.1 && <0.12'
  base: '>=4.5 && <4.16'
all-versions:
- '0.1'
- 0.1.0.1
- 0.1.0.2
- 0.1.2
- '0.2'
- 0.2.1
- 0.3.0
- 0.4.0
- 0.4.2
- 0.4.3
- 0.4.3.1
- 0.4.3.2
- 0.4.3.3
- 0.5.0
- 0.5.0.1
- 0.5.0.2
- 0.5.0.7
author: wren gayle romano, Don Stewart
latest: 0.5.0.7
description-type: markdown
description: "bytestring-lexing\n=================\n[![Hackage version](https://img.shields.io/hackage/v/bytestring-lexing.svg?style=flat)](https://hackage.haskell.org/package/bytestring-lexing)
  \n[![Build Status](https://github.com/wrengr/bytestring-lexing/workflows/ci/badge.svg)](https://github.com/wrengr/bytestring-lexing/actions?query=workflow%3Aci)\n[![Dependencies](https://img.shields.io/hackage-deps/v/bytestring-lexing.svg?style=flat)](http://packdeps.haskellers.com/specific?package=bytestring-lexing)\n\nThe
  bytestring-lexing package offers extremely efficient `ByteString`\nparsers for some
  common lexemes: namely integral and fractional\nnumbers. In addition, it provides
  efficient serializers for (some\nof) the formats it parses.\n\nAs of version 0.3.0,
  bytestring-lexing offers the best-in-show\nparsers for integral values. And as of
  version 0.5.0 it offers (to\nmy knowledge) the best-in-show parser for fractional/floating\nnumbers.
  A record of these benchmarks can be found\n[here](http://code.haskell.org/~wren/bytestring-lexing/bench/html)\n\n\n##
  Install\n\nThis is a simple package and should be easy to install. You should\nbe
  able to use any of the standard methods to install it.\n\n    -- With cabal-install
  and without the source:\n    $> cabal install bytestring-lexing\n    \n    -- With
  cabal-install and with the source already:\n    $> cd bytestring-lexing\n    $>
  cabal install\n    \n    -- Without cabal-install, but with the source already:\n
  \   $> cd bytestring-lexing\n    $> runhaskell Setup.hs configure --user\n    $>
  runhaskell Setup.hs build\n    $> runhaskell Setup.hs haddock --hyperlink-source\n
  \   $> runhaskell Setup.hs copy\n    $> runhaskell Setup.hs register\n\nThe Haddock
  step is optional.\n\n\n### Testing\n\nIf you want to run the test suite, use the
  following standard method\n(with `runhaskell Setup.hs` in lieu of `cabal`, if necessary):\n\n
  \   $> cd bytestring-lexing\n    $> cabal configure --enable-tests --enable-coverage\n
  \   $> cabal build\n    $> cabal test --keep-tix-files\n\nThe results of the code
  coverage are in\n`./dist/hpc/vanilla/html/bytestring-lexing-$VERSION/hpc_index.html`.\nIf
  you're not interested in the coverage of the test suite, then\nyou needn't pass
  the `--enable-coverage` nor `--keep-tix-files`\nflags. Note that older versions
  of cabal used the flag name\n`--enable-library-coverage` instead of `--enable-coverage`.
  And\nIIRC hpc integration in cabal was broken for ghc-7.6.\n\n\n### Benchmarks\n\nIf
  you want to run the benchmarking code, then do:\n\n    $> cd bytestring-lexing/bench\n
  \   $> cabal configure\n    $> cabal build\n    $> for b in isSpace numDigits packDecimal
  readDecimal readExponential ceilEightThirds; do\n           ./dist/build/bench-${b}/bench-${b}
  -o ${b}.html;\n       done && open *.html\n\nOf course, you needn't run all the
  benchmarking programs if you\ndon't want. Notably, these benchmarks are artefacts
  of the development\nof the library. They are not necessarily the most up-to-date\nreflection
  of the library itself, nor of other Haskell libraries\nwe've compared against in
  the past.\n\n\n## Portability\n\nAn attempt has been made to keep this library portable.
  However,\nwe do make use of two simple language extensions. Both of these\nwould
  be easy enough to remove, but they should not pose a significant\nportability burden.
  If they do in fact pose a burden for your\ncompiler, contact the maintainer.\n\n*
  ScopedTypeVariables - the `decimalPrecision` function in\n    `Data.ByteString.Lex.Fractional`
  uses ScopedTypeVariables for\n    efficiency; namely to ensure that the constant
  function\n    `decimalPrecision` need only compute its result once (per type),\n
  \   and that its result has no data dependency on the proxy argument.\n* BangPatterns
  - are used to make the code prettier and to \"improve\"\n    code coverage over
  the equivalent semantics via the following\n    idiom:\n    \n        foo x ...
  z\n            | x `seq` ... `seq` z `seq` False = error \"impossible\"\n            |
  otherwise = ...\n    \n    BangPatterns are supported in GHC as far back as [version\n
  \   6.6.1][ghc-bangpatterns], and are also supported by\n    [JHC][jhc-bangpatterns]
  and [UHC][uhc-bangpatterns]. As of 2010,\n    they were [not supported by Hugs][hugs-bangpatterns];
  but alas\n    Hugs is pretty much dead now.\n\n[ghc-bangpatterns]: \n    https://downloads.haskell.org/~ghc/6.6.1/docs/html/users_guide/sec-bang-patterns.html\n[jhc-bangpatterns]:\n
  \   http://repetae.net/computer/jhc/manual.html#code-options\n[uhc-bangpatterns]:\n
  \   https://github.com/UU-ComputerScience/uhc-js/issues/1\n[hugs-bangpatterns]:
  \n    https://mail.haskell.org/pipermail/haskell-cafe/2010-July/079946.html\n\n\n##
  Changes: Version 0.5.0 (2015-05-06) vs 0.4.3 (2013-03-21)\n\nI've completely overhauled
  the parsers for fractional numbers.\n\nThe old `Data.ByteString.Lex.Double` and
  `Data.ByteString.Lex.Lazy.Double`\nmodules have been removed, as has their reliance
  on Alex as a build\ntool. I know some users were reluctant to use bytestring-lexing\nbecause
  of that dependency, and forked their own version of\nbytestring-lexing-0.3.0's integral
  parsers. This is no longer an\nissue, and those users are requested to switch over
  to using\nbytestring-lexing.\n\nThe old modules are replaced by the new `Data.ByteString.Lex.Fractional`\nmodule.
  This module provides two variants of the primary parsers.\nThe `readDecimal` and
  `readExponential` functions are very simple\nand should suffice for most users'
  needs. The `readDecimalLimited`\nand `readExponentialLimited` are variants which
  take an argument\nspecifying the desired precision limit (in decimal digits). With\ncare,
  the limited-precision parsers can perform far more efficiently\nthan the unlimited-precision
  parsers. Performance aside, they can\nalso be used to intentionally restrict the
  precision of your program's\ninputs.\n\n\n## Benchmarks: Version 0.5.0 (2015-05-06)\n\nThe
  Criterion output of the benchmark discussed below, [is available\nhere](http://code.haskell.org/~wren/bytestring-lexing/bench/html/readExponential-0.5.0_ereshkigal.html).\nThe
  main competitors we compare against are the previous version\nof bytestring-lexing
  (which already surpassed text and\nattoparsec/scientific) and bytestring-read which
  was the previous\nbest-in-show.\n\nThe unlimited-precision parsers provide 3.3x
  to 3.9x speedup over\nthe `readDouble` function from bytestring-lexing-0.4.3.3,
  as well\nas being polymorphic over all `Fractional` values. For `Float`/`Double`:\nthese
  functions have essentially the same performance as bytestring-read\non reasonable
  inputs (1.07x to 0.89x), but for inputs which have\nfar more precision than `Float`/`Double`
  can handle these functions\nare much slower than bytestring-read (0.30x 'speedup').
  However,\nfor `Rational`: these functions provide 1.26x to 1.96x speedup\ncompared
  to bytestring-read.\n\nThe limited-precision parsers do even better, but require
  some care\nto use properly. For types with infinite precision (e.g., `Rational`)\nwe
  can pass in an 'infinite' limit by passing the length of the\ninput string plus
  one. For `Rational`: doing so provides 1.5x speedup\nover the unlimited-precision
  parsers (and 1.9x to 3x speedup over\nbytestring-read), because we can avoid intermediate
  renormalizations.\nWhether other unlimited precision types would see the same benefit\nremains
  an open question.\n\nFor types with inherently limited precision (e.g., `Float`/`Double`),\nwe
  could either pass in an 'infinite' limit or we could pass in the\nactual inherent
  limit. For types with inherently limited precision,\npassing in an 'infinite' limit
  degrades performance compared to the\nunlimited-precision parsers (0.51x to 0.8x
  'speedup'). Whereas,\npassing in the actual inherent limit gives 1.3x to 4.5x speedup\nover
  the unlimited-precision parsers. They also provide 1.2x to\n1.4x speedup over bytestring-read;
  for a total of 5.1x to 14.4x\nspeedup over bytestring-lexing-0.4.3.3!\n\n\n## Links\n\n*
  [Website](https://wrengr.org/)\n* [Blog](http://winterkoninkje.dreamwidth.org/)\n*
  [Twitter](https://twitter.com/wrengr)\n* [Hackage](http://hackage.haskell.org/package/bytestring-lexing)\n*
  [GitHub](https://github.com/wrengr/bytestring-lexing)\n"
license-name: BSD-3-Clause
