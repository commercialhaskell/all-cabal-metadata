homepage: https://github.com/HeinrichApfelmus/disk-bytes
changelog-type: markdown
hash: f6a208b2a5e1b98ec6a5e3793364f05634749842df5a474479dbb3f52a8bde86
test-bench-deps:
  bytestring: -any
  base: -any
  text: -any
  disk-bytes: -any
maintainer: apfelmus@quantentunnel.de
synopsis: On-disk storage, but referentially transparent
changelog: |
  # Revision history for disk-bytes

  All notable changes to this project will (hopefully) be documented in this file.

  The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
  and this project adheres to the [Haskell Package Versioning Policy](https://pvp.haskell.org).

  ## Unreleased

  (This section tracks upcoming changes.)

  ## 0.1.0.0 — 2022-09-25

  Initial release.

  ### Added

  * Module `System.Mem.Disk` which introduces the `DiskBytes` and `Disk` data types.
  * Benchmark `memory` that tests whether RAM usage and garbage collection work as claimed.
basic-deps:
  bytestring: '>=0.10.12.0 && <0.12'
  stm: ^>=2.5.0.1
  base: '>=4.14.3.0 && <4.18'
  text: '>=1.2.4.1 && <2.1'
  direct-sqlite: ^>=2.3.27
  containers: ^>=0.6.5.1
  directory: ^>=1.3.6.0
all-versions:
- 0.1.0.0
author: Heinrich Apfelmus
latest: 0.1.0.0
description-type: markdown
description: "# disk-bytes\n\nThis package provides a data type `DiskBytes` which
  represents a sequence of bytes that is stored on disk — but in a referentially transparent
  manner.\n\nThe key invariant is that a value of type `DiskBytes` that has been evaluated
  *to weak-head normal form* (WHNF) occupies just a few words of RAM, but many bytes
  of on-disk storage. (We can't guarantee anything about expressions that are not
  in WHNF.)\n\nThe main use case for `DiskBytes` is when you have a pure Haskell program
  which is storing too much data, and you want to offload some of this data in a controlled,
  yet transparent way to disk — without `IO` doing violence to your beautiful, pure
  Haskell code.\n\nThe interface for `DiskBytes` consists of two *pure* functions
  which convert to/from an in-memory (RAM) `ByteString`:\n\n```hs\ntoDiskBytes ::
  Disk -> ByteString -> DiskBytes\nfromDiskBytes :: DiskBytes -> ByteString\n```\n\nHere,
  `Disk` represents the on-disk storage, typically obtained by opening a file on the
  file system. One can interpret `Disk` as virtual memory.\n\n## Implementation Details\n\n###
  Disk storage\n\nCurrently, the `Disk` data type is implemented as an open sqlite
  database file. In other words, sqlite is used to manage on-disk memory in a file.
  I decided to use an existing library for on-disk storage, because managing the on-disk
  storage (B+ trees, trade-offs between read and write speed, …) is an interesting
  problem, but it's not a problem that I want to solve *here*.\n\nHowever, sqlite
  is a bit overkill, because all that we need is a key-value store. In the future,
  one might consider on-disk storage libraries such as [lmdb][] or [RocksDB][] — I
  picked sqlite simply because it has Haskell bindings that I have used before. Pull
  requests (with benchmarks) are welcome.\n\n### Sqlite\n\nTODO: Implement batching?
  We may want to batch *insertions* and *deletions* until the total number of bytes
  to process reaches a certain threshold, e.g. 10kB? Rumor has it that sequences of
  database operations such as `INSERT INTO` become faster if they are batched into
  a single transaction, rather than run as separate queries with just a few bytes
  each.\n\n### Referential transparency\n\nInternally, the `DiskBytes` type uses `unsafePerformIO`.
  However, this use is referentially transparent as long as the library has exclusive
  access to the on-disk storage. In other words, we assume that the on-disk memory
  is as exclusive to the Haskell run-time as we assume that RAM is exclusive to the
  Haskell run-time. \n\nTODO: Make an honest attempt to ensure that no other process
  can read or write to the file, e.g. by setting file permissions.\n\n### Testing\n\nCurrently,
  the benchmark `memory` serves as a basic test that everything is working as intended.
  You can run the benchmark and look at its heap profile by executing the commands\n\n```shell\n$
  cabal bench\n$ hp2pretty memory.hp\n```\n\nThis tests the following properties:\n\n*
  `DiskBytes` that are alive do not use much RAM. (Currently, ~`100` bytes per WHNF
  of `DiskBytes`.)\n* `DiskBytes` that are not alive are garbage collected and disk
  memory is freed. (This works as the value returned by `getDiskSize` stops growing.)\n*
  The bytes of 'DiskBytes' that are alive can be loaded back into RAM. (`fromDiskBytes`
  does not throw an error.)\n\n  [lmdb]: https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database\n
  \ [rocksdb]: https://en.wikipedia.org/wiki/RocksDB\n"
license-name: BSD-3-Clause
