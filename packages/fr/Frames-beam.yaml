all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.2
- 0.2.0.0
author: Gagandeep Bhatia
basic-deps:
  Frames: '>=0.5 && <0.6'
  base: '>=4.7 && <5.0'
  beam-core: '>=0.7.2.1'
  beam-migrate: '>=0.3.2.1'
  beam-postgres: '>=0.3.2.0'
  bytestring: '>=0.10.8.2'
  conduit: '>=1.3.0.2'
  generics-sop: '>=0.3.2.0'
  monad-control: '>=1.0.2.3'
  postgresql-simple: '>=0.5.3.0'
  process: '>=1.6.1.0'
  scientific: '>=0.3.5.3'
  template-haskell: '>=2.12.0.0'
  text: '>=1.2.3.0'
  time: '>=1.8.0.2'
  uuid-types: '>=1.0.3'
  vinyl: '>=0.10 && <0.11'
changelog: "# 0.2.0.0\nSupport for `Frames-0.5.0` and `vinyl-0.10.0`. \nAlso see [issue
  #19](https://github.com/gagandeepb/Frames-beam/issues/19).\n\n# 0.1.0.2\nAdds dependency
  upper-bounds for `Frames` and `vinyl`  \n\n# 0.1.0.1\nRemoves upper-bounds for most
  dependencies\n\n# 0.1.0.0\nInitial version"
changelog-type: markdown
description: "# Frames-beam\n\n[![Build Status](https://travis-ci.org/gagandeepb/Frames-beam.png)](https://travis-ci.org/gagandeepb/Frames-beam)\n\n##
  Accessing Postgres in a data frame in Haskell\n\nA library for accessing Postgres
  tables as in-memory data structures.\n\nThis library provides helpers for generating
  \ types (at compile time) corresponding to a database schema  and 'canned queries'
  to execute against a database instance. Additionally, it provides utilities to convert
  plain Haskell records (i.e. the format of query results) to `vinyl` records (upon
  which the Frames library is based). Can be used for interactive exploration by loading
  all data in-memory at once (and converting to a data frame), and also in a constant
  memory streaming mode. \n\n## Usage Example \nIn this example we assume there is
  a local Postgres instance with schema and rows given by the small DB-dump present
  in `data/users.sql`.\n\n### A. Interactive Workflow Steps\n1. **Bootstrap database
  schema:** In a new project, assume a file `Example.hs` is present in the `src` directory
  with the code below. You may of course change the string passed to `genBeamSchema`
  to match your database instance of interest.\n```haskell\n-- Example.hs \n{-# LANGUAGE
  DataKinds              #-}\n{-# LANGUAGE FlexibleContexts       #-}\n{-# LANGUAGE
  FlexibleInstances      #-}\n{-# LANGUAGE FunctionalDependencies #-}\n{-# LANGUAGE
  MultiParamTypeClasses  #-}\n{-# LANGUAGE OverloadedStrings      #-}\n{-# LANGUAGE
  TemplateHaskell        #-}\n{-# LANGUAGE TypeApplications       #-}\n{-# LANGUAGE
  TypeFamilies           #-}\n{-# LANGUAGE TypeFamilyDependencies #-}\n{-# LANGUAGE
  TypeOperators          #-}\n{-# LANGUAGE UndecidableInstances   #-}\nmodule Example
  where\n\nimport qualified Data.Conduit.List        as CL\nimport qualified Data.Vinyl.Functor
  \      as VF\nimport qualified Frames                   as F\nimport           Frames.SQL.Beam.Postgres\n\n\n\n$(genBeamSchema
  \"host=localhost dbname=shoppingcart1\")\n```\n\n2. Next, execute `stack build`
  or `stack ghci`. This compilation step, if completed without any errors, will establish
  a connection to your database instance of interest, read its schema, generate corresponding
  Haskell types and put them in a module named `NewBeamSchema` in your `src` directory
  (the file creation step is also part of the compilation process).\n\n3. Assuming
  step 2 worked fine for you and you were using the test DB-dump from the `data` folder
  you should now have a module with code matching that in the `test/NewBeamSchema.hs`
  file of this repository. In case you used some other database instance of your own,
  your generated module would look different.\nImport this module into `Example`:\n\n```haskell\n--
  Example.hs\n-- Extensions elided\nmodule Example where\n\nimport qualified Data.Conduit.List
  \       as CL\nimport qualified Data.Vinyl.Functor       as VF\nimport qualified
  Frames                   as F\nimport           Frames.SQL.Beam.Postgres\n\nimport
  NewBeamSchema\n\n\n$(genBeamSchema \"host=localhost dbname=shoppingcart1\")\n```\n\n4.
  Let's assume the table of interest is `Cart_usersT`. We want to pull rows from this
  table into a data frame to explore it interactively from `ghci`. Note that `beam`
  query results are lists of plain Haskell records whereas `Frames` requires a list
  of `vinyl` records. In order to make this conversion, we add the following two invokations
  of code-generating (Template-Haskell) functions to `Example`:\n\n```haskell\n--
  Example.hs\n-- rest of the module elided\n\nimport NewBeamSchema\n\n\n$(genBeamSchema
  \"host=localhost dbname=shoppingcart1\")\n\nderiveGeneric ''Cart_usersT\nderiveVinyl
  ''Cart_usersT\n```\n...and build your project. This will add some additional code
  into the `Example` module. You can inspect this code by adding the appropriate compiler
  flags to your `.cabal` file.\n\n5. **Querying the DB:**\nIn this step we will execute
  a `SELECT * FROM tbl WHERE...` query and convert the results to a data frame. Note
  that the table declaration (`_cart_users`) and the database declaration (`db`) are
  exported by the `NewBeamSchema` module. More importantly, these declarations are
  autogenerated at compile time, so in case new tables are added, the corresponding
  declarations are automatically available for use.\n\n```haskell\n-- Example.hs\nconnString
  :: ByteString\nconnString = \"host=localhost dbname=shoppingcart1\"\n\n-- selects
  'n' rows from the specified table in the db.\nloadRows1 :: Int -> IO [(Cart_usersT
  Identity)]\nloadRows1 n =\n  withConnection connString $\n    bulkSelectAllRows
  _cart_users db n\n\nloadRows2 :: Int -> IO [(Cart_usersT Identity)]\nloadRows2 n
  =\n  withConnection connString $\n    bulkSelectAllRowsWhere _cart_users db n (\\c
  -> (_cart_usersFirst_name c) `like_` \"J%\")\n```\nNotice the lambda passed to `bulkSelectAllRowsWhere`
  in `loadRows2`. This is a 'filter lambda' that forms the `WHERE ...` part of the
  SQL query and is executed at the DB-level. We will see how to create our own 'filter
  lambdas' in another section below. For now, if we were to enter `ghci` by executing
  `stack ghci` after adding the above code:\n```ghci\nghci>res1 <- loadRows1 5\nghci>:t
  res1\nres1 :: [Cart_usersT Identity]\nghci>:t (map createRecId res1)\n(map createRecId
  res1)\n  :: [F.Rec\n        VF.Identity\n        '[\"_cart_usersEmail\" F.:-> Text,\n
  \         \"_cart_usersFirst_name\" F.:-> Text,\n          \"_cart_usersLast_name\"
  F.:-> Text,\n          \"_cart_usersIs_member\" F.:-> Bool,\n          \"_cart_usersDays_in_queue\"
  F.:-> Int]]\nghci>:t (F.toFrame $ map createRecId res1)\n(F.toFrame $ map createRecId
  res1)\n  :: F.Frame\n       (F.Record\n          '[\"_cart_usersEmail\" F.:-> Text,\n
  \           \"_cart_usersFirst_name\" F.:-> Text,\n            \"_cart_usersLast_name\"
  F.:-> Text,\n            \"_cart_usersIs_member\" F.:-> Bool,\n            \"_cart_usersDays_in_queue\"
  F.:-> Int])\nghci>myFrame = F.toFrame $ map createRecId res1\nghci>:set -XTypeApplications\nghci>:set
  -XTypeOperators\nghci>:set -XDataKinds\nghci>miniFrame = fmap (F.rcast @'[\"_cart_usersEmail\"
  F.:-> Text, \"_cart_usersDays_in_queue\" F.:-> Int]) myFrame\nghci>mapM_ print miniFrame\n{_cart_usersEmail
  :-> \"james@example.com\", _cart_usersDays_in_queue :-> 1}\n{_cart_usersEmail :->
  \"betty@example.com\", _cart_usersDays_in_queue :-> 42}\n{_cart_usersEmail :-> \"james@pallo.com\",
  _cart_usersDays_in_queue :-> 1}\n{_cart_usersEmail :-> \"betty@sims.com\", _cart_usersDays_in_queue
  :-> 42}\n{_cart_usersEmail :-> \"james@oreily.com\", _cart_usersDays_in_queue :->
  1}\n```\nWe could have used `loadRows2` in place of `loadRows1` in order to have
  the `WHERE ...` clause executed at the DB-level.\nNote that in the above, once the
  query results are converted to a data frame, you're free to play with the frame
  in anyway, just like you would for a data frame created from a CSV.\n\n### B. Streaming
  Workflow Steps\n\nOnce you're done working with a small subset of data, and would
  like to scale up your analysis by looking at a larger-subset-of/complete data, then
  it's time to look at writing your own `conduit` to process incoming rows from the
  DB.\n\n1 - 4: Same as 'Interactive Workflow Steps'\n\n5. **Writing your own streaming
  pipeline:**\n\nConsider the following:\n```haskell\nstreamRows :: IO ()\nstreamRows
  = do\n  res <-  withConnection connString $\n            streamingSelectAllPipeline'
  _cart_users db 1000 (\\c -> (_cart_usersFirst_name c) `like_` \"J%\") $\n              (CL.map
  (\\record -> F.rcast @[\"_cart_usersEmail\" F.:-> Text, \"_cart_usersIs_member\"
  F.:-> Bool] record))\n  mapM_ print res\n```\nIn the above, we select all rows from
  the specified table that match a certain pattern (`\"J%\"`), then the function `streamingSelectAllPipeline'`
  converts the query results to vinyl records inside a `conduit` and sends it downstream,
  where we can operate on its output. Here, specifically, we do a column subset of
  the output using `rcast`, and `CL.map` applies `rcast` to every incoming row and
  sends it downstream, where the result gets returned. We then print the list of `vinyl`
  records.\n\nIn order to write your own conduit, all you need to know is that internally
  the conduit flow is as follows:\n\n```haskell\n(\\c -> runConduit $ c .| CL.map
  createRecId\n                      .| recordProcessorConduit\n                      .|
  CL.take nrows)\n```\nIn the above, you supply the `recordProcessorConduit` to the
  `streamingSelectAllPipeline'` function which takes a `vinyl` record as input and
  sends it downstream to the `CL.take`. Note that in all functions in the `Frames.SQL.Beam.Postgres.Streaming`
  module, you need to specify the number of rows you want to return (this is an upper
  bound of sorts, the actual number of rows returned depends on the amount of data
  present in your database).\n\n## A Note on 'Canned Queries' and 'Filter Lambdas'\n\nThere
  are three things needed to execute a canned query (`SELECT * FROM tbl WHERE ...`):\n*
  `PostgresTable a b`: auto generated by BeamSchemaGen module\n* `PostgresDB b`: auto
  generated by BeamSchemaGen module\n* `PostgresFilterLambda a s`: The `WHERE...`
  clause. All filter lambdas are of the form:\n```haskell\n(\\tbl -> (_fieldName tbl)
  `op` constant)\n```\nor\n```haskell\n(\\tbl -> (_fieldName1 tbl) `op` (_fieldName2
  tbl))\n```\nIn the above `op` can be one of : [`==.`, `/=.`, `>.`, `<.`, `<=.`,
  `>=.`, `between_`, `like_`, `in_` ] (some of these are not be applicable to the
  second case). You may use `(&&.)` and `(||.)` to combine expressions inside the
  lambda. To see some actual examples of 'filter lambdas', check out `test/LibSpec.hs`
  in this repository.\n\n## Background Reading:\n\n* About `deriveGeneric` and `deriveVinyl`:
  [Deriving Vinyl Representation From Plain Haskell Records][generic-vinyl]\n* [Frames
  tutorial][frames-tutorial]\n* [Beam tutorial and user-guide][beam-indepth]\n\n\n[generic-vinyl]:
  https://www.gagandeepbhatia.com/blog/deriving-vinyl-representation-from-plain-haskell-records/\n[frames-tutorial]:
  http://acowley.github.io/Frames/\n[beam-indepth]: https://tathougies.github.io/beam/"
description-type: markdown
hash: 85f6802189f7dccbda0e38e86b09d4d2f220db0a70f85f5a1bd48aaeaae25b69
homepage: https://github.com/gagandeepb/Frames-beam
latest: 0.2.0.0
license-name: BSD-3-Clause
maintainer: gagandeepbhatia.in@gmail.com
synopsis: 'A library for accessing Postgres tables as in-memory data structures.   '
test-bench-deps:
  Frames: '>=0.5 && <0.6'
  Frames-beam: '>=0'
  QuickCheck: '>=2.10.1'
  base: '>=4.10.1.0 && <5.0'
  beam-core: '>=0.7.2.1'
  beam-migrate: '>=0.3.2.1'
  beam-postgres: '>=0.3.2.0'
  bytestring: '>=0.10.8.2'
  conduit: '>=1.3.0.2'
  generics-sop: '>=0.3.2.0'
  hspec: '>=2.4.8'
  hspec-core: '>=2.4.8'
  text: '>=1.2.3.0'
  vinyl: '>=0.10 && <0.11'
