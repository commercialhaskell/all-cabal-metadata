homepage: ''
changelog-type: markdown
hash: 90ec8dce37518f6a77a9b2bc10cb6c3ec361e9b6ae5134dfb9a697a18272d8e7
test-bench-deps:
  htoml: -any
  base: -any
  unordered-containers: -any
  hspec: -any
  text: -any
  criterion: -any
  Frames: -any
  HUnit: -any
  vinyl: -any
  pipes: ! '>=4.1.5 && <4.4'
  regex-applicative: -any
  transformers: -any
  temporary: -any
  pretty: -any
  template-haskell: -any
  directory: -any
maintainer: acowley@gmail.com
synopsis: Data frames For working with tabular data files
changelog: ! '# 0.4.0


  - Added table joins in `Data.Vinyl.Joins` (Chris Hammill)


  - Changed types of `mapMethod` and `mapMethodV`


  These now rely on explicit `TypeApplications` rather than `Proxy` values.


  # 0.3.0


  - Pervasive use of `pipes` for CSV data loading


  This provides better exception handling (file handles should be closed more reliably),
  and offers an interface point for customized handling of input texts. An example
  of this latter point is working with particular file encodings.


  A breaking change is that operations that previously returned `IO` values now return
  `MonadSafe` constrained values.


  - Adaptation of `Data.Vinyl.Curry.runcurry` to the Frames `Record` type

  This simply strips the column name information from a row before applying the function
  from `vinyl`.


  # 0.2.1


  - Refactored to use the `CoRec` type provided by `vinyl` >= 0.6.0


  - Fixed bug in typing mostly-numeric columns

  Such columns must be represented as `Text`. Previously, we strove a bit too hard
  to avoid falling back to `Text` resulting in dropping rows containing non-numeric
  values for columns we crammed into a numeric type.


  - Minor optimization of CSV parsing

  In particular, dealing with RFC4180 style quoting


  - GHC-8.2.1 compatibility


  # 0.1.10


  - Added CSV output functions: `produceCSV` and `writeCSV`

  - Added an Eq instance for the `Frame` type



  # 0.1.9


  Fixed column type inference bug that led the inferencer to prefer `Bool` too strongly.


  This was fallout from typing columns whose values are all 0 or 1 as `Bool`.


  # 0.1.6


  Re-export `Frames.CSV.declareColumn` from `Frames`. This makes it much

  easier to manually define column types.


  # 0.1.4


  Use `microlens` instead of `lens-family-core` for demos.


  # 0.1.3


  GHC-8.0.1 compatibility


  # 0.1.2.1


  Improved documentation based on suggestions by Alexander Kjeldaas


  # 0.1.2


  Fixed bug in `Monoid` instance of `Frame` (@dalejordan)


  # 0.1.1.0


  Added `frameConsA`, `frameSnoc`, and `RecordColumns` to help with

  changing row types.


  # 0.1.0.0


  Initial version pushed to hackage.

'
basic-deps:
  pipes-text: ! '>=0.0.2.5 && <0.1'
  base: ! '>=4.8 && <4.12'
  pipes-bytestring: ! '>=2.1.6 && <2.2'
  pipes-group: ! '>=1.0.8 && <1.1'
  text: ! '>=1.1.1.0'
  vinyl: ! '>=0.7 && <0.9'
  pipes-parse: ! '>=3.0 && <3.1'
  pipes: ! '>=4.1 && <5'
  ghc-prim: ! '>=0.3 && <0.6'
  contravariant: -any
  hashable: -any
  readable: ! '>=0.3.1'
  transformers: -any
  deepseq: ! '>=1.4'
  pipes-safe: ! '>=2.2.6 && <2.3'
  template-haskell: -any
  discrimination: -any
  primitive: ! '>=0.6 && <0.7'
  vector: -any
all-versions:
- '0.1.0.0'
- '0.1.1.0'
- '0.1.1.1'
- '0.1.2'
- '0.1.2.1'
- '0.1.3'
- '0.1.4'
- '0.1.6'
- '0.1.8'
- '0.1.9'
- '0.2.0'
- '0.2.1'
- '0.2.1.1'
- '0.3.0'
- '0.3.0.1'
- '0.3.0.2'
- '0.4.0'
author: Anthony Cowley
latest: '0.4.0'
description-type: markdown
description: ! "# Frames\n## Data Frames for Haskell\n\nUser-friendly, type safe,
  runtime efficient tooling for working with\ntabular data deserialized from comma-separated
  values (CSV) files. The\ntype of each row of data is inferred from data, which can
  then be\nstreamed from disk, or worked with in memory.\n\nWe provide streaming and
  in-memory interfaces for efficiently working\nwith datasets that can be safely indexed
  by column names found in the\ndata files themselves. This type safety of column
  access and\nmanipulation is checked at compile time.\n\n## Use Cases\nFor a running
  example, we will use variations of the [prestige.csv](http://vincentarelbundock.github.io/Rdatasets/datasets.html)
  data set. Each row includes 7 columns, but we just want to compute the average ratio
  of `income` to `prestige`.\n\n### Clean Data\nIf you have a CSV data where the values
  of each column may be classified by a single type, and ideally you have a header
  row giving each column a name, you may simply want to avoid writing out the Haskell
  type corresponding to each row. `Frames` provides `TemplateHaskell` machinery to
  infer a Haskell type for each row of your data set, thus preventing the situation
  where your code quietly diverges from your data.\n\nWe generate a collection of
  definitions generated by inspecting the data file at compile time (using `tableTypes`),
  then, at runtime, load that data into column-oriented storage in memory (an *in-core*
  array of structures (AoS)). We're going to compute the average ratio of two columns,
  so we'll use the `foldl` library. Our fold will project the columns we want, and
  apply a function that divides one by the other after appropriate numeric type conversions.
  Here is the entirety of that [program](https://github.com/acowley/Frames/tree/master/demo/UncurryFold.hs).\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell #-}\nimport qualified
  Control.Foldl as L\nimport Data.Vinyl (rcast)\nimport Frames\n\n-- Data set from
  http://vincentarelbundock.github.io/Rdatasets/datasets.html\ntableTypes \"Row\"
  \"data/prestige.csv\"\n\nloadRows :: IO (Frame Row)\nloadRows = inCoreAoS (readTable
  \"data/prestige.csv\")\n\n-- | Compute the ratio of income to prestige for a record
  containing\n-- only those fields.\nratio :: Record '[Income, Prestige] -> Double\nratio
  = runcurry' (\\i p -> fromIntegral i / p)\n\naverageRatio :: IO Double\naverageRatio
  = L.fold (L.premap (ratio . rcast) avg) <$> loadRows\n  where avg = (/) <$> L.sum
  <*> L.genericLength\n```\n\n### Missing Header Row\nNow consider a case where our
  data file lacks a header row (I deleted the first row from `prestige.csv`). We will
  provide our own name for the generated row type, our own column names, and, for
  the sake of demonstration, we will also specify a prefix to be added to every column-based
  identifier (particularly useful if the column names *do* come from a header row,
  and you want to work with multiple CSV files some of whose column names coincide).
  We customize behavior by updating whichever fields of the record produced by `rowGen`
  we care to change, passing the result to `tableTypes'`. [Link to code.](https://github.com/acowley/Frames/tree/master/demo/UncurryFoldNoHeader.hs)\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell #-}\nimport qualified
  Control.Foldl as L\nimport Data.Vinyl (rcast)\nimport Frames\nimport Frames.CSV
  (rowGen, columnNames, tablePrefix, rowTypeName)\n\n-- Data set from http://vincentarelbundock.github.io/Rdatasets/datasets.html\ntableTypes'
  (rowGen \"data/prestigeNoHeader.csv\")\n            { rowTypeName = \"NoH\"\n            ,
  columnNames = [ \"Job\", \"Schooling\", \"Money\", \"Females\"\n                            ,
  \"Respect\", \"Census\", \"Category\" ]\n            , tablePrefix = \"NoHead\"}\n\nloadRows
  :: IO (Frame NoH)\nloadRows = inCoreAoS (readTable \"data/prestigeNoHeader.csv\")\n\n--
  | Compute the ratio of money to respect for a record containing\n-- only those fields.\nratio
  :: Record '[NoHeadMoney, NoHeadRespect] -> Double\nratio = runcurry' (\\m r -> fromIntegral
  m / r)\n\naverageRatio :: IO Double\naverageRatio = L.fold (L.premap (ratio . rcast)
  avg) <$> loadRows\n  where avg = (/) <$> L.sum <*> L.genericLength\n```\n\n### Missing
  Data\nSometimes not every row has a value for every column. I went ahead and blanked
  the `prestige` column of every row whose `type` column was `NA` in `prestige.csv`.
  For example, the first such row now reads,\n\n```\n\"athletes\",11.44,8206,8.13,,3373,NA\n```\n\nWe
  can no longer parse a `Double` for that row, so we will work with row types parameterized
  by a `Maybe` type constructor. We are substantially filtering our data, so we will
  perform this operation in a streaming fashion without ever loading the entire table
  into memory. Our process will be to check if the `prestige` column was parsed, only
  keeping those rows for which it was not, then project the `income` column from those
  rows, and finally throw away `Nothing` elements. [Link to code.](https://github.com/acowley/Frames/tree/master/demo/UncurryFoldPartialData.hs)\n\n```haskell\n{-#
  LANGUAGE DataKinds, FlexibleContexts, QuasiQuotes, TemplateHaskell #-}\nimport qualified
  Control.Foldl as L\nimport Data.Maybe (isNothing)\nimport Frames\nimport Pipes (Producer,
  (>->))\nimport qualified Pipes.Prelude as P\n\n-- Data set from http://vincentarelbundock.github.io/Rdatasets/datasets.html\n--
  The prestige column has been left blank for rows whose \"type\" is\n-- listed as
  \"NA\".\ntableTypes \"Row\" \"data/prestigePartial.csv\"\n\n-- | A pipes 'Producer'
  of our 'Row' type with a column functor\n-- ('ColFun') of 'Maybe'. That is, each
  element of each row may have\n-- failed to parse from the CSV file.\nmaybeRows ::
  MonadSafe m => Producer (ColFun Maybe Row) m ()\nmaybeRows = readTableMaybe \"data/prestigePartial.csv\"\n\n--
  | Return the number of rows with unknown prestige, and the average\n-- income of
  those rows.\nincomeOfUnknownPrestige :: IO (Int, Double)\nincomeOfUnknownPrestige
  =\n  runSafeEffect . L.purely P.fold avg $\n    maybeRows >-> P.filter prestigeUnknown
  >-> P.map getIncome >-> P.concat\n  where avg = (\\s l -> (l, s / fromIntegral l))
  <$> L.sum <*> L.length\n        getIncome = fmap fromIntegral . rget' income'\n
  \       prestigeUnknown = isNothing . rget' prestige'\n```\n\n## Tutorial\nFor comparison
  to working with data frames in other languages, see the\n[tutorial](http://acowley.github.io/Frames/).\n\n##
  Demos\nThere are various\n[demos](https://github.com/acowley/Frames/tree/master/demo)
  in the repository. Be sure to run the `getdata` build target to download the data
  files used by the demos! You can also download the data files manually and put them
  in a `data` directory in the directory from which you will be running the executables.\n\n##
  Benchmarks\nThe [benchmark](benchmarks/InsuranceBench.hs) shows several ways of\ndealing
  with data when you want to perform multiple traversals.\n\nAnother [demo](benchmarks/BenchDemo.hs)
  shows how to fuse multiple\npasses into one so that the full data set is never resident
  in\nmemory. A [Pandas version](benchmarks/panda.py) of a similar program\nis also
  provided for comparison.\n\nThis is a trivial program, but shows that performance
  is comparable to\nPandas, and the memory savings of a compiled program are substantial.\n\n![Trivial
  Benchmark](https://pbs.twimg.com/media/B71az_CCUAAgscq.png:large)\n"
license-name: BSD3
