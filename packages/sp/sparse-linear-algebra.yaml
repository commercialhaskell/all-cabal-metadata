homepage: https://github.com/ocramz/sparse-linear-algebra
changelog-type: markdown
hash: aad7be41ca5222248710d6840d34f7f3b939755af48b2700d338d7ff2907283a
test-bench-deps:
  exceptions: -any
  mwc-random: -any
  base: -any
  hspec: -any
  containers: -any
  matrix-market-attoparsec: -any
  mtl: '>=2.2.1'
  sparse-linear-algebra: -any
  scientific: -any
  QuickCheck: '>=2.8.2'
  primitive: '>=0.6.1.0'
maintainer: zocca.marco gmail
synopsis: Numerical computing in native Haskell
changelog: "\t0.3.1\n\t* Changed `SpMatrix` to use `foldlWithKey'` for efficiency
  (Joshua Moerman)\n\t\n\t* Bumped LTS to 11.3 (GHC 8.2.2)\n\t\n\t* Removed unneeded
  dependencies from stack.yaml\n\n\t0.3\n\t* Fixed a number of instances, un-commented
  tests (Joshua Moerman)\n\t\n\t* Documented issues with complex number support (Joshua
  Moerman)\n\t\n\t0.2.9.9\n\t* Moved to IntMap.Strict (Gregory Schwartz)\n\t\n\t*
  Stackage LTS bump to 10.4 (GHC 8.2)\n\t\n\t0.2.9.7\n\tImproved pretty printer:\n\n\t*
  Fixed display precision (e.g. 2 decimal digits), fixed column width output for vectors
  and matrices\n\t\n\t* Small and large values (wrt fixed precision) switch to scientific
  notation\n\t\n\t0.2.9.4\n\tExceptions constructors are exported by Numeric.LinearAlgebra.Sparse\n\n\n\t0.2.9.1\n\t*
  Uses classes from `vector-space` such as AdditiveGroup, VectorSpace and InnerSpace\n\t\n\t*
  QuickCheck tests for algebraic properties, such as matrix-vector products and soon
  more abstract ones e.g. positive semi-definite matrices\n\t\n\t* Getting rid of
  `error` in favor of MonadThrow exceptions for high-level operations such as matrix
  algorithms\n"
basic-deps:
  exceptions: -any
  base: '>=4.7 && <4.17'
  hspec: -any
  containers: -any
  mtl: '>=2.2.1'
  vector-algorithms: -any
  transformers: -any
  QuickCheck: '>=2.8.2'
  primitive: -any
  vector: -any
all-versions:
- 0.2.9.4
- 0.2.9.5
- 0.2.9.6
- 0.2.9.7
- '0.3'
- 0.3.1
author: Marco Zocca
latest: 0.3.1
description-type: markdown
description: "# sparse-linear-algebra\n\nNumerical computation in native Haskell\n\n[![Hackage](https://img.shields.io/hackage/v/sparse-linear-algebra.svg)](https://hackage.haskell.org/package/sparse-linear-algebra)
  \ [![Build Status](https://travis-ci.org/ocramz/sparse-linear-algebra.png)](https://travis-ci.org/ocramz/sparse-linear-algebra)\n[![sparse-linear-algebra](http://stackage.org/package/sparse-linear-algebra/badge/lts)](http://stackage.org/lts/package/sparse-linear-algebra)\n[![sparse-linear-algebra](http://stackage.org/package/sparse-linear-algebra/badge/nightly)](http://stackage.org/nightly/package/sparse-linear-algebra)\n\nThis
  library provides common numerical analysis functionality, without requiring any
  external bindings. It aims to serve as an experimental platform for scientific computation
  in a purely functional setting.\n\n\n## State of the library \n\nMar 14, 2018: Mostly
  functional, but there are still a few (documented) bugs. Complex number support
  is still incomplete, so the users are advised to not rely on that for the time being.
  The issues related to Complex number handling are tracked in #50, #51, #12, #30.\n\n\n##
  News\n\nOct 7, 2017: The library is evolving in a number of ways, to reflect performance
  observations and user requests:\n\n* typeclasses and instances for primitive types
  will become `sparse-linear-algebra-core`, along with a typeclass-oriented reformulation
  of the numerical algorithms that used to depend on the nested IntMap representation.\nThis
  will let other developers build on top of this library, in the spirit of `vector-space`
  and `linear`.\n\n* The `vector`-based backend is being reworked.\n\n* An `accelerate`-based
  backend is under development [6, 7].\n\n\n## Contents\n\n* Iterative linear solvers
  (`<\\>`)\n\n    * Generalized Minimal Residual (GMRES) (non-Hermitian systems) \n\n
  \   * BiConjugate Gradient (BCG)\n\n    * Conjugate Gradient Squared (CGS)\n\n    *
  BiConjugate Gradient Stabilized (BiCGSTAB) (non-Hermitian systems)\n\n    * Moore-Penrose
  pseudoinverse (`pinv`) (rectangular systems)\n\n* Direct linear solvers\n\n    *
  LU-based (`luSolve`); forward and backward substitution (`triLowerSolve`, `triUpperSolve`)\n
  \   \n* Matrix factorization algorithms\n\n    * QR (`qr`)\n\n    * LU (`lu`)\n\n
  \   * Cholesky (`chol`)\n\n    * Arnoldi iteration (`arnoldi`)\n\n* Eigenvalue algorithms\n\n
  \   * QR (`eigsQR`)\n\n    * QR-Arnoldi (`eigsArnoldi`) \n\n\n\n* Utilities : Vector
  and matrix norms, matrix condition number, Givens rotation, Householder reflection\n\n*
  Predicates : Matrix orthogonality test (A^T A ~= I)\n\n\n\n### Under development\n\n*
  Eigenvalue algorithms\n\n    * Rayleigh quotient iteration (`eigRayleigh`)\n\n*
  Matrix factorization algorithms\n\n    * Golub-Kahan-Lanczos bidiagonalization (`gklBidiag`)\n
  \  \n    * Singular value decomposition (SVD)\n\n* Iterative linear solvers\n\n
  \   * Transpose-Free Quasi-Minimal Residual (TFQMR)\n\n---------\n\n## Examples\n\nThe
  module `Numeric.LinearAlgebra.Sparse` contains the user interface.\n\n### Creation
  of sparse data\n\nThe `fromListSM` function creates a sparse matrix from a collection
  of its entries in (row, column, value) format. This is its type signature:\n\n    fromListSM
  :: Foldable t => (Int, Int) -> t (IxRow, IxCol, a) -> SpMatrix a\n\nand, in case
  you have a running GHCi session (the terminal is denoted from now on by `λ>`), you
  can try something like this:\n\n    λ> amat = fromListSM (3,3) [(0,0,2),(1,0,4),(1,1,3),(1,2,2),(2,2,5)]
  :: SpMatrix Double\n\nSimilarly, `fromListSV` is used to create sparse vectors:
  \n\n    fromListSV :: Int -> [(Int, a)] -> SpVector a\n    \n\nAlternatively, the
  user can copy the contents of a list to a (dense) SpVector using\n\n    fromListDenseSV
  :: Int -> [a] -> SpVector a\n\n\n\n### Displaying sparse data\n\nBoth sparse vectors
  and matrices can be pretty-printed using `prd`:\n\n    λ> prd amat\n\n    ( 3 rows,
  3 columns ) , 5 NZ ( density 55.556 % )\n\n    2.00   , _      , _      \n    4.00
  \  , 3.00   , 2.00   \n    _      , _      , 5.00       \n\n*Note (sparse storage)*:
  sparse data should only contain non-zero entries not to waste memory and computation.\n\n*Note
  (approximate output)*: `prd` rounds the results to two significant digits, and switches
  to scientific notation for large or small values. Moreover, values which are indistinguishable
  from 0 (see the `Numeric.Eps` module) are printed as `_`. \n\n\n### Matrix factorizations,
  matrix product\n\nThere are a few common matrix factorizations available; in the
  following example we compute the LU factorization of matrix `amat` and verify it
  with the matrix-matrix product `##` of its factors :\n\n    λ> (l, u) <- lu amat\n
  \   λ> prd $ l ## u\n    \n    ( 3 rows, 3 columns ) , 9 NZ ( density 100.000 %
  )\n\n    2.00   , _      , _      \n    4.00   , 3.00   , 2.00   \n    _      ,
  _      , 5.00       \n\n\nNotice that the result is _dense_, i.e. certain entries
  are numerically zero but have been inserted into the result along with all the others
  (thus taking up memory!).\nTo preserve sparsity, we can use a sparsifying matrix-matrix
  product `#~#`, which filters out all the elements x for which `|x| <= eps`, where
  `eps` (defined in `Numeric.Eps`) depends on the numerical type used (e.g. it is
  10^-6 for `Float`s and 10^-12 for `Double`s).\n\n    λ> prd $ l #~# u\n    \n    (
  3 rows, 3 columns ) , 5 NZ ( density 55.556 % )\n\n    2.00   , _      , _      \n
  \   4.00   , 3.00   , 2.00   \n    _      , _      , 5.00 \n\n\nA matrix is transposed
  using the `transpose` function.\n\nSometimes we need to compute matrix-matrix transpose
  products, which is why the library offers the infix operators `#^#` (i.e. matrix
  transpose * matrix) and `##^` (matrix * matrix transpose):\n\n    λ> amat' = amat
  #^# amat\n    λ> prd amat'\n    \n    ( 3 rows, 3 columns ) , 9 NZ ( density 100.000
  % )\n\n    20.00  , 12.00  , 8.00   \n    12.00  , 9.00   , 6.00   \n    8.00   ,
  6.00   , 29.00      \n\n    \n    λ> lc <- chol amat'\n    λ> prd $ lc ##^ lc\n
  \   \n    ( 3 rows, 3 columns ) , 9 NZ ( density 100.000 % )\n\n    20.00  , 12.00
  \ , 8.00   \n    12.00  , 9.00   , 10.80  \n    8.00   , 10.80  , 29.00      \n\n\nIn
  the last example we have also shown the Cholesky decomposition (M = L L^T where
  L is a lower-triangular matrix), which is only defined for symmetric positive-definite
  matrices.\n\n### Linear systems\n\nLarge sparse linear systems are best solved with
  iterative methods. `sparse-linear-algebra` provides a selection of these via the
  `<\\>` (inspired by Matlab's \"backslash\" function. Currently this method uses
  GMRES as default) :\n\n    λ> b = fromListDenseSV 3 [3,2,5] :: SpVector Double\n
  \   λ> x <- amat <\\> b\n    λ> prd x\n\n    ( 3 elements ) ,  3 NZ ( density 100.000
  % )\n\n    1.50   , -2.00  , 1.00      \n\n\nThe result can be verified by computing
  the matrix-vector action `amat #> x`, which should (ideally) be very close to the
  right-hand side `b` :\n\n    λ> prd $ amat #> x\n\n    ( 3 elements ) ,  3 NZ (
  density 100.000 % )\n\n    3.00   , 2.00   , 5.00       \n    \n\nThe library also
  provides a forward-backward substitution solver (`luSolve`) based on a triangular
  factorization of the system matrix (usually LU). This should be the preferred for
  solving smaller, dense systems. Using the LU factors defined previously we can cross-verify
  the two solution methods:\n\n    λ> x' <- luSolve l u b\n    λ> prd x'\n\n    (
  3 elements ) ,  3 NZ ( density 100.000 % )\n\n    1.50   , -2.00  , 1.00     \n\n\n\n\n\n\n\n\n\n##
  License\n\nGPL3, see LICENSE\n\n## Credits\n\nInspired by\n\n* `linear` : https://hackage.haskell.org/package/linear\n*
  `vector-space` : https://hackage.haskell.org/package/vector-space\n* `sparse-lin-alg`
  : https://github.com/laughedelic/sparse-lin-alg\n\n## References\n\n[1] Y. Saad,
  Iterative Methods for Sparse Linear Systems, 2nd ed., 2000\n\n[2] G.H. Golub and
  C.F. Van Loan, Matrix Computations, 3rd ed., 1996\n\n[3] T.A. Davis, Direct Methods
  for Sparse Linear Systems, 2006\n\n[4] L.N. Trefethen, D. Bau, Numerical Linear
  Algebra, SIAM, 1997\n\n[5] W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery,
  Numerical Recipes in Fortran 77, 2nd ed., 1992\n\n[6] M. M. T. Chakravarty, et al.,
  Accelerating Haskell array codes with multicore GPUs - DAMP'11\n\n[7] [`accelerate`](http://hackage.haskell.org/package/accelerate)"
license-name: GPL-3.0-only
