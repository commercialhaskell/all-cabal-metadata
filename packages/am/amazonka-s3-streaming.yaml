homepage: https://github.com/Axman6/amazonka-s3-streaming#readme
changelog-type: markdown
hash: ea653a3b28923282afea5bdab135d4d233749ea19cda2528c0c3392645673e36
test-bench-deps: {}
maintainer: Alex.Mason@data61.csiro.au
synopsis: Provides conduits to upload data to S3 using the Multipart API
changelog: ! "# Changelog - amazonka-s3-streaming\n\n# 0.2.0.3\n * Make all library
  generated messages use Debug level not Info\n\n# 0.2.0.2\n * Update to mmorph <
  1.2\n\n## 0.2.0.1\n * Fixed a bug with the printf format strings which would lead
  to a crash (Thanks @JakeOShannessy\n   for reporting).\n\n## 0.2.0.0\n * Fixed a
  potential bug with very large uploads where the chunksize might be too small\n   for
  the limit of 10,000 chunks per upload (#6).\n * Change API to allow the user to
  specify a chunk size for streaming if the user knows\n   more about the data than
  we do.\n * Allow the user to specify how many concurrent threads to use for `concurrentUpload`
  as\n   as well as chunk size (#4).\n * Better specify cabal dependency ranges."
basic-deps:
  http-client: ! '>=0.4 && <0.6'
  amazonka: ! '>=1.3 && <1.6'
  exceptions: ! '>=0.8.2.1 && <0.9'
  bytestring: ! '>=0.10.8.0 && <0.11'
  base: ! '>=4.6 && <5'
  text: -any
  amazonka-s3-streaming: -any
  dlist: ! '>=0.8 && <0.9'
  conduit: ! '>=1.2.6.6 && <1.3'
  conduit-extra: -any
  mmap: ! '>=0.5 && <0.6'
  lens: ! '>=4.13 && <5.0'
  amazonka-core: ! '>=1.3 && <1.6'
  mtl: ! '>=2.2.1 && <2.3'
  mmorph: ! '>=1.0.6 && <1.2'
  lifted-async: ! '>=0.9 && <0.10'
  deepseq: ! '>=1.2 && <1.5'
  resourcet: ! '>=1.1.7.4 && <1.2'
  amazonka-s3: ! '>=1.3 && <1.6'
all-versions:
- '0.1.0.0'
- '0.1.0.1'
- '0.1.0.2'
- '0.1.0.3'
- '0.1.0.4'
- '0.2.0.1'
- '0.2.0.2'
- '0.2.0.3'
- '0.2.0.4'
author: Alex Mason
latest: '0.2.0.4'
description-type: markdown
description: ! '# amazonka-s3-streaming [![Build Status](https://travis-ci.org/axman6/amazonka-s3-streaming.svg?branch=master)](https://travis-ci.org/axman6/amazonka-s3-streaming)


  Provides a conduit based streaming interface and a concurrent interface to uploading
  data to S3 using the Multipart API. Also provides method to upload files or bytestrings
  of known size in parallel.


  The documentation can be found on [Hackage](https://hackage.haskell.org/package/amazonka-s3-streaming).

'
license-name: BSD3
