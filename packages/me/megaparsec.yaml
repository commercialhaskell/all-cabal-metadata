homepage: https://github.com/mrkkrp/megaparsec
changelog-type: markdown
hash: 34f00245390eb90a5642ec5a7eb82c6ae15268a97d456386fc92982cffedd8bd
test-bench-deps:
  bytestring: ! '>=0.2 && <0.11'
  base: ! '>=4.7 && <5.0'
  hspec: ! '>=2.0 && <3.0'
  text: ! '>=0.2 && <1.3'
  megaparsec: -any
  criterion: ! '>=0.6.2.1 && <1.5'
  containers: ! '>=0.5 && <0.6'
  weigh: ! '>=0.0.4'
  mtl: ! '>=2.0 && <3.0'
  transformers: ! '>=0.4 && <0.6'
  deepseq: ! '>=1.3 && <1.5'
  scientific: ! '>=0.3.1 && <0.4'
  QuickCheck: ! '>=2.7 && <2.12'
  hspec-expectations: ! '>=0.5 && <0.9'
maintainer: Mark Karpov <markkarpov92@gmail.com>
synopsis: Monadic parser combinators
changelog: ! "## Megaparsec 6.5.0\n\n* Added `Text.Megaparsec.Internal`, which exposes
  some internal data\n  structures and data constructor of `ParsecT`.\n\n## Megaparsec
  6.4.1\n\n* `scientific` now correctly backtracks after attempting to parse fractional\n
  \ and exponent parts of a number. `float` correctly backtracks after\n  attempting
  to parse optional exponent part (when it comes after fractional\n  part, otherwise
  it's obligatory).\n\n## Megaparsec 6.4.0\n\n* `Text.Megaparsec` now re-exports `Control.Monad.Combinators`
  instead of\n  `Control.Applicative.Combinators` from `parser-combinators` because
  the\n  monadic counterparts of the familiar combinators are more efficient and\n
  \ not as leaky.\n\n  This may cause minor breakage in certain cases:\n\n  * You
  import `Control.Applicative` and in that case there will be a name\n    conflict
  between `Control.Applicative.many` and\n    `Control.Monad.Combinator.many` now
  (the same for `some`).\n\n  * You define a polymorphic helper in terms of combinator(s)
  from\n    `Control.Applicative.Combinators` and use `Applicative` or `Alternative`\n
  \   constraint. In this case you'll have to adjust the constraint to be\n    `Monad`
  or `MonadPlus` respectively.\n\n  Also note that the new `Control.Monad.Combinators`
  module we re-export now\n  re-exports `empty` from `Control.Applicative`.\n\n* Fix
  the `atEnd` parser. It now does not produce hints, so when you use it,\n  it won't
  contribute to the “expecting end of input” component of parse\n  error.\n\n## Megaparsec
  6.3.0\n\n* Added an `IsString` instance for `ParsecT`. Now it is possible to\n  write
  `\"abc\"` rather than `string \"abc\"`.\n\n* Added the `customFailure` combinator,
  which is a special case of\n  `fancyFailure`.\n\n* Made implementation of `sconcat`
  and `mconcat` of `ParsecT` more\n  efficient.\n\n## Megaparsec 6.2.0\n\n* `float`
  in `Text.Megaparsec.Char.Lexer` and `Text.Megaparsec.Byte.Lexer`\n  now does not
  accept plain integers. This is the behavior we had in version\n  5 of the library.\n\n##
  Megaparsec 6.1.1\n\n* Fixed the bug when `tokens` used `cok` continuation even when
  matching an\n  empty chunk. Now it correctly uses `eok` in this case.\n\n## Megaparsec
  6.1.0\n\n* Improved rendering of offending line in `parseErrorPretty'` in the\n
  \ presence of tab characters.\n\n* Added `parseErrorPretty_`, which is just like
  `parseErrorPretty'` but\n  allows to specify tab width to use.\n\n* Adjusted hint
  generation so when we backtrack a consuming parser with\n  `try`, we do not create
  hints from its parse error (because it's further\n  in input stream!). This was
  a quite subtle bug that stayed unnoticed for\n  several years apparently.\n\n##
  Megaparsec 6.0.2\n\n* Allow `parser-combinators-0.2.0`.\n\n## Megaparsec 6.0.1\n\n*
  Fixed a typo in `README.md`.\n\n* Added some text that clarifies how to parametrize
  the `ParseError` type.\n\n## Megaparsec 6.0.0\n\n### General\n\n* Re-organized the
  module hierarchy. Some modules such as\n  `Text.Megaparsec.Prim` do not exist anymore.
  Stream definitions were moved\n  to `Text.Megaparsec.Stream`. Generic combinators
  are now re-exported from\n  the `Control.Applicative.Combinators` from the package\n
  \ `parser-combinators`. Just import `Text.Megaparsec` and you should be OK.\n  Add
  `Text.Megaparsec.Char` if you are working with a stream of `Char`s or\n  `Text.Megaparsec.Byte`
  if you intend to parse binary data, then add\n  qualified modules you need (permutation
  parsing, lexing, expression\n  parsing, etc.). `Text.Megaparsec.Lexer` was renamed
  to\n  `Text.Megaparec.Char.Lexer` because many functions in it has the `Token s\n
  \ ~ Char` constraint. There is also `Text.Megaparsec.Byte.Lexer` now,\n  although
  it has fewer functions.\n\n* Dropped per-stream modules, the `Parser` type synonym
  is to be defined\n  manually by user.\n\n* Added a `MonadFix` instance for `ParsecT`.\n\n*
  More lightweight dependency tree, dropped `exceptions` and `QuickCheck`\n  dependencies.\n\n*
  Added dependency on `case-insensitive`.\n\n### Source positions\n\n* Now `Pos` contains
  an `Int` inside, not `Word`.\n\n* Dropped `unsafePos` and changed type of `mkPos`
  so it throws from pure\n  code if its argument is not a positive `Int`.\n\n* Added
  `pos1` constant that represents the `Pos` with value 1 inside.\n\n* Made `InvalidPosException`
  contain the invalid `Int` value that was passed\n  to `mkPos`.\n\n### Parse errors\n\n*
  Changed the definition of `ParseError` to have separate data constructors\n  for
  “trivial” errors (unexpected/expected tokens) and “fancy” errors\n  (everything
  else).\n\n* Removed the `ErrorComponent` type class, added `ErrorFancy` instead.\n
  \ `ErrorFancy` is a sum type which can represent `fail` messages, incorrect\n  indentation,
  and custom data (we use `Void` for that by default to\n  “disable” it). This is
  better than the typeclass-based approach because\n  every instance of `ErrorComponent`
  needed to have constructors for `fail`\n  and indentation massages anyway, leading
  to duplication of code (for\n  example for parse error component rendering).\n\n*
  Added `Functor` instances for `ErrorItem` and `ErrorFancy`.\n\n* Added the function
  `errorPos` to get error positions from `ParseError`\n  (previously it was a record
  selector in `ParseError`).\n\n* Control characters in parse error are displayed
  in a readable form even\n  when they are part of strings, for example: `{<newline>`
  (`{` followed by\n  the newline character). Previously control characters were rendered
  in\n  readable form only as standalone tokens.\n\n* Added `Text.Megaparsec.Error.Builder`
  module to help construct\n  `ParseError`s easily. It is useful for testing and debugging.
  Previously\n  we had something like that in the `hspec-megaparsec` package, but
  it does\n  not hurt to ship it with the library.\n\n* Added `parseErrorPretty'`
  allowing to display offending line in parse\n  errors.\n\n* Added `LineToken` type
  class for tokens that support operations necessary\n  for selecting and displaying
  relevant line of input (used in\n  `parseErrorPretty'`).\n\n* Added `parseTest'`
  function that is just like `parseTest`, but also prints\n  offending line in parse
  errors. This is powered by the new\n  `parseErrorPretty'`.\n\n### Stream\n\n* Introduced
  the new `Text.Megaparsec.Stream` module that is the home of\n  `Stream` type class.
  In version 6, the type class has been extended\n  significantly to improve performance
  and make some combinators more\n  general.\n\n### Combinators\n\n* Changed signatures
  of `failure` and `token`, they only can signal trivial\n  errors now.\n\n* Added
  a new method of `MonadParsec` type class called `fancyFailure` for\n  signalling
  non-trivial failures. Signatures of some functions (`failure`,\n  `token`) have
  been changed accordingly.\n\n* Added `takeWhileP`, `takeWhile1P` and `takeP` to
  `MonadParsec`.\n\n* Added `takeRest` non-primitive combinator to consume the rest
  of input.\n\n* Added `atEnd` which returns `True` when end of input has been reached.\n\n*
  Dropped `oneOf'` and `noneOf'` from `Text.Megaparsec.Char`. These were\n  seldom
  (if ever) used and are easily re-implemented.\n\n* Added `notChar` in `Text.Megaparsec.Char`.\n\n*
  Added `space1` in `Text.Megaprasec.Char`. This parser is like `space` but\n  requires
  at least one space character to be present to succeed.\n\n* Added new module `Text.Megaparsec.Byte`,
  which is similar to\n  `Text.Megaparsec.Char`, but for token streams of the type
  `Word8` instead\n  of `Char`.\n\n* `integer` was dropped from `Text.Megaparec.Char.Lexer`.
  Use `decimal`\n  instead.\n\n* `number` was dropped from `Text.Megaparec.Char.Lexer`.
  Use `scientific`\n  instead.\n\n* `decimal`, `octal`, and `hexadecimal` are now
  polymorphic in their return\n  type and can be used to parse any instance of `Integral`.\n\n*
  `float` is now polymorphic in its return type and can be used to parse any\n  instance
  of `RealFloat`.\n\n* Added new module `Text.Megaparsec.Byte.Lexer`, which provides
  some\n  functions (white space and numeric helpers) from\n  `Text.Megaparsec.Char.Lexer`
  for streams with token type `Word8`.\n\n## Megaparsec 5.3.1\n\n* Various updates
  to the docs.\n\n* Allowed `QuickCheck-2.10`.\n\n## Megaparsec 5.3.0\n\n* Added the
  `match` combinator that allows to get collection of consumed\n  tokens along with
  result of parsing.\n\n* Added the `region` combinator which allows to process parse
  errors\n  happening when its argument parser is run.\n\n* Added the `getNextTokenPosition`,
  which returns position where the next\n  token in the stream begins.\n\n* Defined
  `Semigroup` and `Monoid` instances of `ParsecT`.\n\n* Dropped support for GHC 7.6.\n\n*
  Added an `ErrorComponent` instance for `()`.\n\n## Megaparsec 5.2.0\n\n* Added `MonadParsec`
  instance for `RWST`.\n\n* Allowed `many` to run parsers that do not consume input.
  Previously this\n  signalled an `error` which was ugly. Of course, in most cases
  giving\n  `many` a parser that do not consume input will lead to non-termination\n
  \ bugs, but there are legal cases when this should be allowed. The test\n  suite
  now contains an example of this. Non-termination issues is something\n  inherited
  from the power Megaparsec gives (with more power comes more\n  responsibility),
  so that `error` case in `many` really does not solve the\n  problem, it was just
  a little ah-hoc guard we got from Parsec's past.\n\n* The criterion benchmark was
  completely re-written and a new weigh\n  benchmark to analyze memory consumption
  was added.\n\n* Performance improvements: `count` (marginal improvement, simpler\n
  \ implementation), `count'` (considerable improvement), and `many`\n  (marginal
  improvement, simpler implementation).\n\n* Added `stateTokensProcessed` field to
  parser state and helper functions\n  `getTokensProcessed` and `setTokensProcessed`.
  The field contains number\n  of processed tokens so far. This allows, for example,
  create wrappers that\n  return just parsed fragment of input stream alongside with
  result of\n  parsing. (It was possible before, but very inefficient because it required\n
  \ traversing entire input stream twice.)\n\n* `IndentNone` option of `indentBlock`
  now picks whitespace after it like\n  its sisters `IndentMany` and `IndentSome`
  do, see #161.\n\n* Fixed a couple of quite subtle bugs in `indentBlock` introduced
  by\n  changing behaviour of `skipLineComment` in version 5.1.0. See #178 for\n  more
  information.\n\n## Megaparsec 5.1.2\n\n* Stopped using property tests with `dbg`
  helper to avoid flood of debugging\n  info when test suite is run.\n\n* Fixed the
  build with `QuickCheck` versions older than 2.9.0.\n\n## Megaparsec 5.1.1\n\n* Exported
  the `observing` primitive from `Text.Megaparsec`.\n\n## Megaparsec 5.1.0\n\n* Defined
  `displayException` for `ParseError`, so exceptions are displayed\n  in human-friendly
  form now. This works with GHC 7.10 and later.\n\n* Line comments parsed by `skipLineComment`
  now may end at the end of input\n  and do not necessarily require a newline to be
  parsed correctly. See #119.\n\n* Exposed `parseErrorTextPretty` function in `Text.Megaparsec.Error`
  to\n  allow to render `ParseError`s without stack of source positions.\n\n* Eliminated
  the `old-tests` test suite — Parsec legacy. The cases that are\n  not already *obviously*
  covered in the main test suite were included into\n  it.\n\n* Added `Arbitrary`
  instances for the following data types: `Pos`,\n  `SourcePos`, `ErrorItem`, `Dec`,
  `ParseError` and `State`. This should\n  make testing easier without the need to
  add orphan instances every time.\n  The drawback is that we start to depend on `QuickCheck`,
  but that's a fair\n  price.\n\n* The test suite now uses the combination of Hspec
  and the\n  `hpesc-megaparsec` package, which also improved the latter (that package\n
  \ is the recommended way to test Megaparsec parsers).\n\n* The `try` combinator
  now truly backtracks parser state when its argument\n  parser fails (either consuming
  input or not). Most users will never notice\n  the difference though. See #142.\n\n*
  Added the `dbg` function that should be helpful for debugging.\n\n* Added `observing`
  primitive combinator that allows to “observe” parse\n  errors without ending parsing
  (they are returned in `Left`, while normal\n  results are wrapped in `Right`).\n\n*
  Further documentation improvements.\n\n## Megaparsec 5.0.1\n\n* Derived `NFData`
  instances for `Pos`, `InvalidPosException`, `SourcePos`,\n  `ErrorItem`, `Dec`,
  `ParseError`, and `State`.\n\n* Derived `Data` instance for `ParseError`, `Data`
  and `Typeable` instances\n  for `SourcePos` and `State`.\n\n* Minor documentation
  improvements.\n\n## Megaparsec 5.0.0\n\n### General changes\n\n* Removed `parseFromFile`
  and `StorableStream` type-class that was necessary\n  for it. The reason for removal
  is that reading from file and then parsing\n  its contents is trivial for every
  instance of `Stream` and this function\n  provides no way to use newer methods for
  running a parser, such as\n  `runParser'`. So, simply put, it adds little value
  and was included in 4.x\n  versions for compatibility reasons.\n\n* Moved position-advancing
  function from arguments of `token` and `tokens`\n  functions to `Stream` type class
  (named `updatePos`). The new function\n  allows to handle custom streams of tokens
  where every token contains\n  information about its position in stream better (for
  example when stream\n  of tokens is produced with happy/alex).\n\n* Support for
  include files (stack of positions instead of flat position)\n  added. The new functions
  `pushPosition` and `popPosition` can be used to\n  move “vertically” in the stack
  of positions. `getPosition` and\n  `setPosition` still work on top (“current file”)
  level, but user can get\n  full stack via `getParserState` if necessary. Note that
  `ParseError` and\n  pretty-printing for it also support the new feature.\n\n* Added
  type function `Token` associated with `Stream` type class. The\n  function returns
  type of token corresponding to specific token stream.\n\n* Type `ParsecT` (and also
  type synonym `Parsec`) are now parametrized over\n  type of custom component in
  parse errors.\n\n* Parameters of `MonadParsec` type class are: `e` — type of custom
  component\n  in parse errors, `s` — type of input stream, and `m` — type of underlying\n
  \ monad.\n\n* Type of `failure` primitive combinator was changed, now it accepts
  three\n  arguments: set of unexpected items, set of expected items, and set of\n
  \ custom data.\n\n* Type of `token` primitive combinator was changed, now in case
  of failure a\n  triple-tuple is returned with elements corresponding to arguments
  of\n  `failure` primitive. The `token` primitive can also be optionally given an\n
  \ argument of token type to use in error messages (as expected item) in case\n  of
  end of input.\n\n* `unexpected` combinator now accepts argument of type `ErrorItem`
  instead\n  of plain `String`.\n\n* General performance improvements and improvements
  in speed of some\n  combinators, `manyTill` in particular.\n\n### Error messages\n\n*
  The module `Text.Megaparsec.Pos` was completely rewritten. The new module\n  uses
  `Pos` data type with smart constructors to ensure that things like\n  line and column
  number can be only positive. `SourcePos` on the other hand\n  does not require smart
  constructors anymore and its constructors are\n  exported. `Show` and `Read` instances
  of `SourcePos` are derived and\n  pretty-printing is done with help of `sourcePosPretty`
  function.\n\n* The module `Text.Megaparsec.Error` was completely rewritten. A number
  of\n  new types and type-classes are introduced: `ErrorItem`, `Dec`,\n  `ErrorComponent`,
  and `ShowErrorComponent`. `ParseError` does not need\n  smart constructors anymore
  and its constructor and field selectors are\n  exported. It uses sets (from the
  `containers` package) instead of sorted\n  lists to enumerate unexpected and expected
  items. The new definition is\n  also parametrized over token type and custom data
  type which can be passed\n  around as part of parse error. Default “custom data”
  component is `Dec`,\n  which see. All in all, we have completely well-typed and
  extensible error\n  messages now. `Show` and `Read` instances of `ParseError` are
  derived and\n  pretty-printing is done with help of `parseErrorPretty`.\n\n* The
  module `Text.Megaparsec.ShowToken` was eliminated and type class\n  `ShowToken`
  was moved to `Text.Megaparsec.Error`. The only method of that\n  class in now named
  `showTokens` and it works on streams of tokens, where\n  single tokes are represented
  by `NonEmpty` list with single element.\n\n### Built-in combinators\n\n* Combinators
  `oneOf`, `oneOf'`, `noneOf`, and `noneOf'` now accept any\n  instance of `Foldable`,
  not only `String`.\n\n### Lexer\n\n* Error messages about incorrect indentation
  levels were greatly improved.\n  Now every such message contains information about
  desired ordering between\n  “reference” indentation level and actual indentation
  level as well as\n  values of these levels. The information is stored in `ParseError`
  in\n  well-typed form and can be pretty-printed when necessary. As part of this\n
  \ improvement, type of `indentGuard` was changed.\n\n* `incorrectIndent` combinator
  is introduced in `Text.Megaparsec.Lexer`\n  module. It allows to fail with detailed
  information regarding incorrect\n  indentation.\n\n* Introduced `scientific` parser
  that can parse arbitrary big numbers\n  without error or memory overflow. `float`
  still returns `Double`, but it's\n  defined in terms of `scientific` now. Since
  `Scientific` type can reliably\n  represent integer values as well as floating point
  values, `number` now\n  returns `Scientific` instead of `Either Integer Double`
  (`Integer` or\n  `Double` can be extracted from `Scientific` value anyway). This
  in turn\n  makes `signed` parser more natural and general, because we do not need\n
  \ ad-hoc `Signed` type class anymore.\n\n* Added `skipBlockCommentNested` function
  that should help parse possibly\n  nested block comments.\n\n* Added `lineFold`
  function that helps parse line folds.\n\n## Megaparsec 4.4.0\n\n* Now state returned
  on failure is the exact state of parser at the moment\n  when it failed, which makes
  incremental parsing feature much better and\n  opens possibilities for features
  like “on-the-fly” recovering from parse\n  errors.\n\n* The `count` combinator now
  works with `Applicative` instances (previously\n  it worked only with instances
  of `Alternative`). It's now also faster.\n\n* `tokens` and parsers built upon it
  (such as `string` and `string'`)\n  backtrack automatically on failure now, that
  is, when they fail, they\n  never consume any input. This is done to make their
  consumption model\n  match how error messages are reported (which becomes an important
  thing as\n  user gets more control with primitives like `withRecovery`). This means,\n
  \ in particular, that it's no longer necessary to use `try` with\n  `tokens`-based
  parsers. This new feature *does not* affect performance in\n  any way.\n\n* New
  primitive parser `withRecovery` added. The parser allows to recover\n  from parse
  errors “on-the-fly” and continue parsing. Once parsing is\n  finished, several parse
  errors may be reported or ignored altogether.\n\n* `eitherP` combinator added.\n\n*
  Removed `Enum` instance of `Message` type. This was Parsec's legacy that\n  we should
  eliminate now. `Message` does not constitute enumeration,\n  `toEnum` was never
  properly defined for it. The idea to use `fromEnum` to\n  determine type of `Message`
  is also ugly, for this purpose new functions\n  `isUnexpected`, `isExpected`, and
  `isMessage` are defined in\n  `Text.Megaparsec.Error`.\n\n* Minor tweak in signature
  of `MonadParsec` type class. Collection of\n  constraints changed from `Alternative
  m, Monad m, Stream s t` to\n  `Alternative m, MonadPlus m, Stream s t`. This is
  done to make it easier\n  to write more abstract code with older GHC where such
  primitives as\n  `guard` are defined for instances of `MonadPlus`, not `Alternative`.\n\n##
  Megaparsec 4.3.0\n\n* Canonicalized `Applicative`/`Monad` instances. Thanks to Herbert
  Valerio\n  Riedel.\n\n* Custom messages in `ParseError` are printed each on its
  own line.\n\n* Now accumulated hints are not used with `ParseError` records that
  have\n  only custom messages in them (created with `Message` constructor, as\n  opposed
  to `Unexpected` or `Expected`). This strips “expected” line from\n  custom error
  messages where it's unlikely to be relevant anyway.\n\n* Added higher-level combinators
  for indentation-sensitive grammars:\n  `indentLevel`, `nonIndented`, and `indentBlock`.\n\n##
  Megaparsec 4.2.0\n\n* Made `newPos` constructor and other functions in `Text.Megaparsec.Pos`\n
  \ smarter. Now it's impossible to create `SourcePos` with non-positive line\n  number
  or column number. Unfortunately we cannot use `Numeric.Natural`\n  because we need
  to support older versions of `base`.\n\n* `ParseError` is now a monoid. `mergeError`
  is used as `mappend`.\n\n* Added functions `addErrorMessages` and `newErrorMessages`
  to add several\n  messages to existing error and to construct error with several
  attached\n  messages respectively.\n\n* `parseFromFile` now lives in `Text.Megaparsec.Prim`.
  Previously we had 5\n  nearly identical definitions of the function, varying only
  in\n  type-specific `readFile` function. Now the problem is solved by\n  introduction
  of `StorableStream` type class. All supported stream types\n  are instances of the
  class out of box and thus we have polymorphic version\n  of `parseFromFile`.\n\n*
  `ParseError` is now instance of `Exception` (and `Typeable`).\n\n* Introduced `runParser'`
  and `runParserT'` functions that take and return\n  parser state. This makes it
  possible to partially parse input, resume\n  parsing, specify non-standard initial
  textual position, etc.\n\n* Introduced `failure` function that allows to fail with
  arbitrary\n  collection of messages. `unexpected` is now defined in terms of\n  `failure`.
  One consequence of this design decision is that `failure` is\n  now method of `MonadParsec`,
  while `unexpected` is not.\n\n* Removed deprecated combinators from `Text.Megaparsec.Combinator`:\n\n
  \   * `chainl`\n    * `chainl1`\n    * `chainr`\n    * `chainr1`\n\n* `number` parser
  in `Text.Megaparsec.Lexer` now can be used with `signed`\n  combinator to parse
  either signed `Integer` or signed `Double`.\n\n## Megaparsec 4.1.1\n\n* Fixed bug
  in implementation of `sepEndBy` and `sepEndBy1` and removed\n  deprecation notes
  for these functions.\n\n* Added tests for `sepEndBy` and `sepEndBy1`.\n\n## Megaparsec
  4.1.0\n\n* Relaxed dependency on `base`, so that minimal required version of `base`\n
  \ is now 4.6.0.0. This allows Megaparsec to compile with GHC 7.6.x.\n\n* `Text.Megaparsec`
  and `Text.Megaparsec.Prim` do not export data types\n  `Consumed` and `Reply` anymore
  because they are rather low-level\n  implementation details that should not be visible
  to end-user.\n\n* Representation of file name and textual position in error messages
  was\n  made conventional.\n\n* Fixed some typos is documentation and other materials.\n\n##
  Megaparsec 4.0.0\n\n### General changes\n\n* Renamed `many1` → `some` as well as
  other parsers that had `many1` part in\n  their names.\n\n* The following functions
  are now re-exported from `Control.Applicative`:\n  `(<|>)`, `many`, `some`, `optional`.
  See #9.\n\n* Introduced type class `MonadParsec` in the style of MTL monad\n  transformers.
  Eliminated built-in user state since it was not flexible\n  enough and can be emulated
  via stack of monads. Now all tools in\n  Megaparsec work with any instance of `MonadParsec`,
  not only with\n  `ParsecT`.\n\n* Added new function `parseMaybe` for lightweight
  parsing where error\n  messages (and thus file name) are not important and entire
  input should be\n  parsed. For example it can be used when parsing of single number
  according\n  to specification of its format is desired.\n\n* Fixed bug with `notFollowedBy`
  always succeeded with parsers that don't\n  consume input, see #6.\n\n* Flipped
  order of arguments in the primitive combinator `label`, see #21.\n\n* Renamed `tokenPrim`
  → `token`, removed old `token`, because `tokenPrim` is\n  more general and original
  `token` is little used.\n\n* Made `token` parser more powerful, now its second argument
  can return\n  `Either [Message] a` instead of `Maybe a`, so it can influence error\n
  \ message when parsing of token fails. See #29.\n\n* Added new primitive combinator
  `hidden p` which hides “expected” tokens in\n  error message when parser `p` fails.\n\n*
  Tab width is not hard-coded anymore. It can be manipulated via\n  `getTabWidth`
  and `setTabWidth`. Default tab-width is `defaultTabWidth`,\n  which is 8.\n\n###
  Error messages\n\n* Introduced type class `ShowToken` and improved representation
  of\n  characters and strings in error messages, see #12.\n\n* Greatly improved quality
  of error messages. Fixed entire\n  `Text.Megaparsec.Error` module, see #14 for more
  information. Made\n  possible normal analysis of error messages without “render
  and re-parse”\n  approach that previous maintainers had to practice to write even
  simplest\n  tests, see module `Utils.hs` in `old-tests` for example.\n\n* Reduced
  number of `Message` constructors (now there are only `Unexpected`,\n  `Expected`,
  and `Message`). Empty “magic” message strings are ignored now,\n  all the library
  now uses explicit error messages.\n\n* Introduced hint system that greatly improves
  quality of error messages and\n  made code of `Text.Megaparsec.Prim` a lot clearer.\n\n###
  Built-in combinators\n\n* All built-in combinators in `Text.Megaparsec.Combinator`
  now work with any\n  instance of `Alternative` (some of them even with `Applicaitve`).\n\n*
  Added more powerful `count'` parser. This parser can be told to parse from\n  `m`
  to `n` occurrences of some thing. `count` is defined in terms of\n  `count'`.\n\n*
  Removed `optionMaybe` parser, because `optional` from\n  `Control.Applicative` does
  the same thing.\n\n* Added combinator `someTill`.\n\n* These combinators are considered
  deprecated and will be removed in future:\n\n    * `chainl`\n    * `chainl1`\n    *
  `chainr`\n    * `chainr1`\n    * `sepEndBy`\n    * `sepEndBy1`\n\n### Character
  parsing\n\n* Renamed some parsers:\n\n    * `alphaNum` → `alphaNumChar`\n    * `digit`
  → `digitChar`\n    * `endOfLine` → `eol`\n    * `hexDigit` → `hexDigitChar`\n    *
  `letter` → `letterChar`\n    * `lower` → `lowerChar`\n    * `octDigit` → `octDigitChar`\n
  \   * `space` → `spaceChar`\n    * `spaces` → `space`\n    * `upper` → `upperChar`\n\n*
  Added new character parsers in `Text.Megaparsec.Char`:\n\n    * `asciiChar`\n    *
  `charCategory`\n    * `controlChar`\n    * `latin1Char`\n    * `markChar`\n    *
  `numberChar`\n    * `printChar`\n    * `punctuationChar`\n    * `separatorChar`\n
  \   * `symbolChar`\n\n* Descriptions of old parsers have been updated to accent
  some\n  Unicode-specific moments. For example, old description of `letter` stated\n
  \ that it parses letters from “a” to “z” and from “A” to “Z”. This is wrong,\n  since
  it used `Data.Char.isAlpha` predicate internally and thus parsed\n  many more characters
  (letters of non-Latin languages, for example).\n\n* Added combinators `char'`, `oneOf'`,
  `noneOf'`, and `string'` which are\n  case-insensitive variants of `char`, `oneOf`,
  `noneOf`, and `string`\n  respectively.\n\n### Lexer\n\n* Rewritten parsing of numbers,
  fixed #2 and #3 (in old Parsec project these\n  are number 35 and 39 respectively),
  added per bug tests.\n\n    * Since Haskell report doesn't say anything about sign,
  `integer` and\n      `float` now parse numbers without sign.\n\n    * Removed `natural`
  parser, it's equal to new `integer` now.\n\n    * Renamed `naturalOrFloat` → `number`
  — this doesn't parse sign too.\n\n    * Added new combinator `signed` to parse all
  sorts of signed numbers.\n\n* Transformed `Text.Parsec.Token` into `Text.Megaparsec.Lexer`.
  Little of\n  Parsec's code remains in the new lexer module. New module doesn't impose\n
  \ any assumptions on user and should be vastly more useful and\n  general. Hairy
  stuff from original Parsec didn't get here, for example\n  built-in Haskell functions
  are used to parse escape sequences and the like\n  instead of trying to re-implement
  the whole thing.\n\n### Other\n\n* Renamed the following functions:\n\n    * `permute`
  → `makePermParser`\n    * `buildExpressionParser` → `makeExprParser`\n\n* Added
  comprehensive QuickCheck test suite.\n\n* Added benchmarks.\n\n## Parsec 3.1.9\n\n*
  Many and various updates to documentation and package description\n  (including
  the homepage links).\n\n* Add an `Eq` instance for `ParseError`.\n\n* Fixed a regression
  from 3.1.6: `runP` is again exported from module\n  `Text.Parsec`.\n\n## Parsec
  3.1.8\n\n* Fix a regression from 3.1.6 related to exports from the main module.\n\n##
  Parsec 3.1.7\n\n* Fix a regression from 3.1.6 related to the reported position of
  error\n  messages. See bug #9 for details.\n\n* Reset the current error position
  on success of `lookAhead`.\n\n## Parsec 3.1.6\n\n* Export `Text` instances from
  `Text.Parsec`.\n\n* Make `Text.Parsec` exports more visible.\n\n* Re-arrange `Text.Parsec`
  exports.\n\n* Add functions `crlf` and `endOfLine` to `Text.Parsec.Char` for handling\n
  \ input streams that do not have normalized line terminators.\n\n* Fix off-by-one
  error in `Token.charControl`.\n\n## Parsec 3.1.4 & 3.1.5\n\n* Bump dependency on
  `text`.\n\n## Parsec 3.1.3\n\n* Fix a regression introduced in 3.1.2 related to
  positions reported by\n  error messages.\n"
basic-deps:
  bytestring: ! '>=0.2 && <0.11'
  case-insensitive: ! '>=1.2 && <1.3'
  base: ! '>=4.7 && <5.0'
  parser-combinators: ! '>=0.4 && <2.0'
  text: ! '>=0.2 && <1.3'
  containers: ! '>=0.5 && <0.6'
  mtl: ! '>=2.0 && <3.0'
  transformers: ! '>=0.4 && <0.6'
  deepseq: ! '>=1.3 && <1.5'
  scientific: ! '>=0.3.1 && <0.4'
all-versions:
- '4.0.0'
- '4.1.0'
- '4.1.1'
- '4.2.0'
- '4.3.0'
- '4.4.0'
- '5.0.0'
- '5.0.1'
- '5.1.0'
- '5.1.1'
- '5.1.2'
- '5.2.0'
- '5.3.0'
- '5.3.1'
- '6.0.0'
- '6.0.1'
- '6.0.2'
- '6.1.0'
- '6.1.1'
- '6.2.0'
- '6.3.0'
- '6.4.0'
- '6.4.1'
- '6.5.0'
author: ! 'Megaparsec contributors,

  Paolo Martini <paolo@nemail.it>,

  Daan Leijen <daan@microsoft.com>'
latest: '6.5.0'
description-type: markdown
description: ! "# Megaparsec\n\n[![License FreeBSD](https://img.shields.io/badge/license-FreeBSD-brightgreen.svg)](http://opensource.org/licenses/BSD-2-Clause)\n[![Hackage](https://img.shields.io/hackage/v/megaparsec.svg?style=flat)](https://hackage.haskell.org/package/megaparsec)\n[![Stackage
  Nightly](http://stackage.org/package/megaparsec/badge/nightly)](http://stackage.org/nightly/package/megaparsec)\n[![Stackage
  LTS](http://stackage.org/package/megaparsec/badge/lts)](http://stackage.org/lts/package/megaparsec)\n[![Build
  Status](https://travis-ci.org/mrkkrp/megaparsec.svg?branch=master)](https://travis-ci.org/mrkkrp/megaparsec)\n\n*
  [Features](#features)\n    * [Core features](#core-features)\n    * [Error messages](#error-messages)\n
  \   * [Alex support](#alex-support)\n    * [Character and binary parsing](#character-and-binary-parsing)\n
  \   * [Permutation parsing](#permutation-parsing)\n    * [Expression parsing](#expression-parsing)\n
  \   * [Lexer](#lexer)\n* [Documentation](#documentation)\n* [Tutorials](#tutorials)\n*
  [Performance](#performance)\n* [Comparison with other solutions](#comparison-with-other-solutions)\n
  \   * [Megaparsec vs Attoparsec](#megaparsec-vs-attoparsec)\n    * [Megaparsec vs
  Parsec](#megaparsec-vs-parsec)\n    * [Megaparsec vs Trifecta](#megaparsec-vs-trifecta)\n
  \   * [Megaparsec vs Earley](#megaparsec-vs-earley)\n* [Related packages](#related-packages)\n*
  [Prominent projects that use Megaparsec](#prominent-projects-that-use-megaparsec)\n*
  [Links to announcements and blog posts](#links-to-announcements-and-blog-posts)\n*
  [Authors](#authors)\n* [Contribution](#contribution)\n* [License](#license)\n\nThis
  is an industrial-strength monadic parser combinator library. Megaparsec\nis a feature-rich
  package that strikes a nice balance between speed,\nflexibility, and quality of
  parse errors.\n\n## Features\n\nThe project provides flexible solutions to satisfy
  common parsing needs. The\nsection describes them shortly. If you're looking for
  comprehensive\ndocumentation, see the [section about documentation](#documentation).\n\n###
  Core features\n\nThe package is built around `MonadParsec`, an MTL-style monad transformer.\nAll
  tools and features work with all instances of `MonadParsec`. You can\nachieve various
  effects combining monad transformers, i.e. building a\nmonadic stack. Since the
  common monad transformers like `WriterT`, `StateT`,\n`ReaderT` and others are instances
  of the `MonadParsec` type class, you can\nwrap `ParsecT` *in* these monads, achieving,
  for example, backtracking\nstate.\n\nOn the other hand `ParsecT` is an instance
  of many type classes as well. The\nmost useful ones are `Monad`, `Applicative`,
  `Alternative`, and\n`MonadParsec`.\n\nMegaparsec includes all functionality that
  is available in Parsec plus\nfeatures some combinators that are missing in other
  parsing libraries:\n\n* `failure` allows to fail reporting a parse error with unexpected
  and\n  expected items.\n* `fancyFailure` allows to fail reporting custom error messages.\n*
  `withRecovery` allows to recover from parse errors “on-the-fly” and\n  continue
  parsing. Once parsing is finished, several parse errors may be\n  reported or ignored
  altogether.\n* `observing` allows to “observe” parse errors without ending parsing
  (they\n  are returned in `Left`, while normal results are wrapped in `Right`).\n\nIn
  addition to that, Megaparsec 6 features high-performance combinators\nsimilar to
  those found in Attoparsec:\n\n* `tokens` makes it easy to parse several tokens in
  a row (`string` and\n  `string'` are built on top of this primitive). This is about
  100 times\n  faster than matching a string token by token. `tokens` returns “chunk”
  of\n  original input, meaning that if you parse `Text`, it'll return `Text`\n  without
  any repacking.\n* `takeWhile` and `takeWhile1` are about 150 times faster than approaches\n
  \ involving `many`, `manyTill` and other similar combinators.\n* `takeP` allows
  to grab n tokens from the stream and returns them as a\n  “chunk” of the stream.\n\nSo
  now that we have matched the main “performance boosters” of Attoparsec,\nMegaparsec
  6 is not significantly slower than Attoparsec if you write your\nparser carefully
  (see also [the section about performance](#performance)).\n\nMegaparsec can currently
  work with the following types of input stream\nout-of-the-box:\n\n* `String` = `[Char]`\n*
  `ByteString` (strict and lazy)\n* `Text` (strict and lazy)\n\nIt's also simple to
  make it work with custom token streams, and Megaparsec\nusers have done so many
  times.\n\n### Error messages\n\nMegaparsec 5 introduced well-typed error messages
  and the ability to use\ncustom data types to adjust the library to specific domain
  of interest. No\nneed to use a shapeless bunch of strings.\n\nThe design of parse
  errors has been revised in version 6 significantly, but\ncustom errors are still
  easy (probably even easier now).\n\n### Alex support\n\nMegaparsec works well with
  streams of tokens produced by tools like Alex.\nThe design of the `Stream` type
  class has been changed significantly in\nversion 6, but user can still work with
  custom streams of tokens without\nproblems.\n\n### Character and binary parsing\n\nMegaparsec
  has decent support for Unicode-aware character parsing. Functions\nfor character
  parsing live in the\n[`Text.Megaparsec.Char`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec-Char.html)\nmodule.
  Similarly, there is\n[`Text.Megaparsec.Byte`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec-Byte.html)\nmodule
  for parsing streams of bytes.\n\n### Permutation parsing\n\nFor those who are interested
  in parsing of permutation phrases, there is\n[`Text.Megaparsec.Perm`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec-Perm.html).\nYou
  have to import the module explicitly, it's not included in the\n`Text.Megaparsec`
  module.\n\n### Expression parsing\n\nMegaparsec has a solution for parsing of expressions.
  Take a look at\n[`Text.Megaparsec.Expr`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec-Expr.html).\nYou
  have to import the module explicitly, it's not included in the\n`Text.Megaparsec`.\n\nGiven
  a table of operators that describes their fixity and precedence, you\ncan construct
  a parser that will parse any expression involving the\noperators. See documentation
  for comprehensive description of how it works.\n\n### Lexer\n\n[`Text.Megaparsec.Char.Lexer`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec-Char-Lexer.html)\nis
  a module that should help you write your lexer. If you have used `Parsec`\nin the
  past, this module “fixes” its particularly inflexible\n`Text.Parsec.Token`.\n\n`Text.Megaparsec.Char.Lexer`
  is intended to be imported using a qualified\nimport, it's not included in `Text.Megaparsec`.
  The module doesn't impose\nhow you should write your parser, but certain approaches
  may be more elegant\nthan others. An especially important theme is parsing of white
  space,\ncomments, and indentation.\n\nThe design of the module allows you quickly
  solve simple tasks and doesn't\nget in your way when you want to implement something
  less standard.\n\nSince Megaparsec 5, all tools for indentation-sensitive parsing
  are\navailable in `Text.Megaparsec.Char.Lexer` module—no third party packages\nrequired.\n\n`Text.Megaparsec.Byte.Lexer`
  is also available for users who wish to parse\nbinary data.\n\n## Documentation\n\nMegaparsec
  is well-documented. See the [current version of Megaparsec\ndocumentation on Hackage](https://hackage.haskell.org/package/megaparsec).\n\n##
  Tutorials\n\nYou can find Megaparsec tutorials\n[here](https://markkarpov.com/learn-haskell.html#megaparsec-tutorials).
  They\nshould provide sufficient guidance to help you to start with your parsing\ntasks.
  The site also has instructions and tips for Parsec users who decide\nto migrate
  to Megaparsec.\n\n## Performance\n\nDespite being flexible, Megaparsec is also quite
  fast. Here is how\nMegaparsec 6.4.0 compares to Attoparsec 0.13.2.0 (the fastest
  widely used\nparsing library in the Haskell ecosystem):\n\nTest case         | Execution
  time | Allocated | Max residency\n------------------|---------------:|----------:|-------------:\nCSV
  (Attoparsec)  |       57.14 μs |   397,912 |        10,560\nCSV (Megaparsec)  |
  \      76.27 μs |   557,272 |         9,120\nLog (Attoparsec)  |       244.2 μs
  | 1,181,120 |        11,144\nLog (Megaparsec)  |       315.2 μs | 1,485,776 |        11,392\nJSON
  (Attoparsec) |       14.39 μs |   132,496 |         9,048\nJSON (Megaparsec) |       26.70
  μs |   233,336 |         9,424\n\nThe benchmarks were created to guide development
  of Megaparsec 6 and can be\nfound [here](https://github.com/mrkkrp/parsers-bench).\n\nIf
  you think your Megaparsec parser is not efficient enough, take a look at\n[these\ninstructions](https://markkarpov.com/megaparsec/writing-a-fast-parser.html).\n\n##
  Comparison with other solutions\n\nThere are quite a few libraries that can be used
  for parsing in Haskell,\nlet's compare Megaparsec with some of them.\n\n### Megaparsec
  vs Attoparsec\n\n[Attoparsec](https://github.com/bos/attoparsec) is another prominent
  Haskell\nlibrary for parsing. Although the both libraries deal with parsing, it's\nusually
  easy to decide which you will need in particular project:\n\n* *Attoparsec* is faster
  but not that feature-rich. It should be used when\n  you want to process large amounts
  of data where performance matters more\n  than quality of error messages.\n\n* *Megaparsec*
  is good for parsing of source code or other human-readable\n  texts. It has better
  error messages and it's implemented as monad\n  transformer.\n\nSo, if you work
  with something human-readable where size of input data is\nusually not huge, just
  go with Megaparsec, otherwise Attoparsec may be a\nbetter choice.\n\nSince version
  6, Megaparsec features the same fast primitives that\nAttoparsec has, so in many
  cases the difference in speed is not that big.\nMegaparsec now aims to be “one size
  fits all” ultimate solution to parsing,\nso it can be used even to parse low-level
  binary formats.\n\n### Megaparsec vs Parsec\n\nSince Megaparsec is a fork of Parsec,
  we are bound to list the main\ndifferences between the two libraries:\n\n* Better
  error messages. We test our error messages using numerous\n  QuickCheck (generative)
  tests. Good error messages are just as important\n  for us as correct return values
  of our parsers. Megaparsec will be\n  especially useful if you write a compiler
  or an interpreter for some\n  language.\n\n* Megaparsec 6 can show the line on which
  parse error happened as part of\n  parse error. This makes it a lot easier to figure
  out where the error\n  happened.\n\n* Some quirks and “buggy features” (as well
  as plain bugs) of original\n  Parsec are fixed. There is no undocumented surprising
  stuff in Megaparsec.\n\n* Better support for Unicode parsing in `Text.Megaparsec.Char`.\n\n*
  Megaparsec has more powerful combinators and can parse languages where\n  indentation
  matters out-of-the-box.\n\n* Comprehensive test suite covering nearly 100% of our
  code. Compare that to\n  absence\n\n* We have benchmarks to detect performance regressions.\n\n*
  Better documentation, with 100% of functions covered, without typos and\n  obsolete
  information, with working examples. Megaparsec's documentation is\n  well-structured
  and doesn't contain things useless to end users.\n\n* Megaparsec's code is clearer
  and doesn't contain “magic” found in original\n  Parsec.\n\n* Megaparsec has well-typed
  error messages and custom error messages.\n\n* Megaparsec can recover from parse
  errors “on the fly” and continue\n  parsing.\n\n* Megaparsec allows to conditionally
  process parse errors *inside your\n  parser* before parsing is finished. In particular,
  it's possible to define\n  regions in which parse errors, should they happen, will
  get a “context\n  tag”, e.g. we could build a context stack like “in function definition\n
  \ foo”, “in expression x”, etc. This is not possible with Parsec.\n\n* Megaparsec
  is faster and supports efficient operations on top of `tokens`,\n  `takeWhileP`,
  `takeWhile1P`, `takeP` like Attoparsec.\n\nIf you want to see a detailed change
  log, `CHANGELOG.md` may be helpful.\nAlso see [this original announcement](https://notehub.org/w7037)
  for another\ncomparison.\n\n### Megaparsec vs Trifecta\n\n[Trifecta](https://hackage.haskell.org/package/trifecta)
  is another Haskell\nlibrary featuring good error messages. It's probably good, but
  also\nunder-documented, and has unfixed [bugs and\nflaws](https://github.com/ekmett/trifecta/issues).
  Other reasons one may\nquestion choice of Trifecta is his/her parsing library:\n\n*
  Complicated, doesn't have any tutorials available, and documentation\n  doesn't
  help at all.\n\n* Trifecta can parse `String` and `ByteString` natively, but not
  `Text`.\n\n* Trifecta's error messages may be different with their own features,
  but\n  certainly not as flexible as Megaparsec's error messages in the latest\n
  \ versions.\n\n* Depends on `lens`. This means you'll pull in half of Hackage as
  transitive\n  dependencies. Also if you're not into `lens` and would like to keep
  your\n  code “vanilla”, you may not like the API.\n\n[Idris](https://www.idris-lang.org/)
  has recently switched from Trifecta to\nMegaparsec which allowed it to [have better
  error messages and fewer\ndependencies](https://twitter.com/edwinbrady/status/950084043282010117?s=09).\n\n###
  Megaparsec vs Earley\n\n[Earley](https://hackage.haskell.org/package/Earley) is
  a newer library that\nallows to safely (it your code compiles, then it probably
  works) parse\ncontext-free grammars (CFG). Megaparsec is a lower-level library compared
  to\nEarley, but there are still enough reasons to choose it over Earley:\n\n* Megaparsec
  is faster.\n\n* Your grammar may be not context-free or you may want introduce some
  sort\n  of state to the parsing process. Almost all non-trivial parsers require\n
  \ something of this sort. Even if your grammar is context-free, state may\n  allow
  to add some additional niceties. Earley does not support that.\n\n* Megaparsec's
  error messages are more flexible allowing to include\n  arbitrary data in them,
  return multiple error messages, mark regions that\n  affect any error that happens
  in those regions, etc.\n\n* The approach Earley uses differs from the conventional
  monadic parsing. If\n  you work not alone, people you work with, especially beginners,
  will be\n  much more productive with libraries taking more traditional path to\n
  \ parsing like Megaparsec.\n\nIOW, Megaparsec is less safe but also more powerful.\n\n##
  Related packages\n\nThe following packages are designed to be used with Megaparsec
  (open a PR if\nyou want to add something to the list):\n\n* [`hspec-megaparsec`](https://hackage.haskell.org/package/hspec-megaparsec)—utilities\n
  \ for testing Megaparsec parsers with with\n  [Hspec](https://hackage.haskell.org/package/hspec).\n*
  [`cassava-megaparsec`](https://hackage.haskell.org/package/cassava-megaparsec)—Megaparsec\n
  \ parser of CSV files that plays nicely with\n  [Cassava](https://hackage.haskell.org/package/cassava).\n*
  [`tagsoup-megaparsec`](https://hackage.haskell.org/package/tagsoup-megaparsec)—a\n
  \ library for easily using\n  [TagSoup](https://hackage.haskell.org/package/tagsoup)
  as a token type in\n  Megaparsec.\n\n## Prominent projects that use Megaparsec\n\nThe
  following are some prominent projects that use Megaparsec:\n\n* [Idris](https://github.com/idris-lang/Idris-dev)—a
  general-purpose\n  functional programming language with dependent types\n* [Hledger](https://github.com/simonmichael/hledger)—an
  accounting tool\n* [MMark](https://github.com/mmark-md/mmark)—strict markdown processor
  for\n  writers\n* [Stache](https://github.com/stackbuilders/stache)—Mustache templates
  for\n  Haskell\n* [Language Puppet](https://github.com/bartavelle/language-puppet)—library\n
  \ for manipulating Puppet manifests\n\n## Links to announcements and blog posts\n\nHere
  are some blog posts mainly announcing new features of the project and\ndescribing
  what sort of things are now possible:\n\n* [Evolution of error messages](https://markkarpov.com/post/evolution-of-error-messages.html)\n*
  [A major upgrade to Megaparsec: more speed, more power](https://markkarpov.com/post/megaparsec-more-speed-more-power.html)\n*
  [Latest additions to Megaparsec](https://markkarpov.com/post/latest-additions-to-megaparsec.html)\n*
  [Announcing Megaparsec 5](https://markkarpov.com/post/announcing-megaparsec-5.html)\n*
  [Megaparsec 4 and 5](https://markkarpov.com/post/megaparsec-4-and-5.html)\n* [The
  original Megaparsec 4.0.0 announcement](https://notehub.org/w7037)\n\n## Authors\n\nThe
  project was started and is currently maintained by Mark Karpov. You can\nfind the
  complete list of contributors in the `AUTHORS.md` file in the\nofficial repository
  of the project. Thanks to all the people who propose\nfeatures and ideas, although
  they are not in `AUTHORS.md`, without them\nMegaparsec would not be that good.\n\n##
  Contribution\n\nIssues (bugs, feature requests or otherwise feedback) may be reported
  in\n[the GitHub issue tracker for this project](https://github.com/mrkkrp/megaparsec/issues).\n\nPull
  requests are also welcome (and yes, they will get attention and will be\nmerged
  quickly if they are good).\n\n## License\n\nCopyright © 2015–2018 Megaparsec contributors\\\nCopyright
  © 2007 Paolo Martini\\\nCopyright © 1999–2000 Daan Leijen\n\nDistributed under FreeBSD
  license.\n"
license-name: BSD2
