all-versions:
- 0.1.0.0
- 0.1.0.1
- 0.1.0.2
- 0.1.0.3
- 1.0.0.0
- 1.0.0.1
- 1.0.0.2
- 1.0.0.3
- 1.0.0.4
- 1.0.1.0
- 1.0.2.0
author: Qqwy / Marten
basic-deps:
  base: '>=4.7 && <5'
  binary: '>=0.8.9 && <0.9'
  bytestring: '>=0.11.0 && <0.13'
  containers: '>=0.6.0 && <0.7'
  deepseq: '>=1.4.0 && <1.6'
  hashable: '>=1.4.0 && <1.5'
  random: '>=1.2 && <2'
  text: '>=2.0 && <2.2'
  text-short: '>=0.1.0 && <0.2'
changelog: |
  # Changelog for `symbolize`

  All notable changes to this project will be documented in this file.

  The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
  and this project adheres to the
  [Haskell Package Versioning Policy](https://pvp.haskell.org/).

  ## Unreleased

  ## 1.0.2.0

  - Adds `Textual.toShortTextUnsafe` and related `internUnsafe` and `internUnsafe#`; these skip UTF-8 validity checks. Very useful when working with trusted serialized data.
    - rename `intern##` to `internUnsafe##` (the old name is marked as deprecated.)
  - Cleans up `mkWeakSymbol` to be slightly less sketchy in the presence of `accursedUnutterablePerformIO`; thanks @fatho!

  ## 1.0.1.0

  - Add `Data.Data` instance
  - Add `Data.Binary` instance

  ## 1.0.0.4

  - Minor documentation improvements

  ## 1.0.0.3

  - Minor documentation improvements

  ## 1.0.0.2

  - Minor documentation improvements

  ## 1.0.0.1

  - Minor documentation improvements

  ## 1.0.0.0 - 2025-02-17

  Completely overhauled implementation:
  - The old implementation used `newtype Symbol = Symbol Word`, adding Weak-pointers to this `Word`.
    - This was brittle, since those `Word`s would often get inlined, potentially triggering weak-pointer finalization (too) early.
    - The symbol table had to keep track of mappings in both directions.
    - Int also meant that `unintern` required access to the symbol table.
  - The new implementation uses `newtype Symbol# = Symbol# ByteArray#`, and adds weak pointers to this unlifted `ByteArray#`.
    - Much safer, this is how `mkWeak` is intended to be used.
    - The symbol table now only needs to store 'TextHash -> Weak Symbol', and is essentially just a 'weak hashset'. Less than half the memory usage!
    - Much faster `unintern`, as it no longer needs access to the symbol table but is a simple pointer dereference.

  ## 0.1.0.1 / 0.1.0.2 - 2023-11-24
  Fixes in the README and package description only, for better rendering on Hackage.

  ## 0.1.0.0 - 2023-11-24
  Initial version
changelog-type: markdown
description: "# Symbolize\n[![Hackage](http://img.shields.io/hackage/v/symbolize.svg)](https://hackage.haskell.org/package/symbolize)\n[![HackageDocumentation](https://img.shields.io/badge/documentation-available-blue)](https://hackage.haskell.org/package/symbolize/docs/Symbolize.html)\n[![test](https://github.com/Qqwy/haskell-symbolize/actions/workflows/test.yaml/badge.svg?branch=main)](https://github.com/Qqwy/haskell-symbolize/actions/workflows/test.yaml)\n\nHaskell
  library implementing a global Symbol Table, with garbage collection.\n\n[API Documentation](https://hackage.haskell.org/package/symbolize/docs/Symbolize.html)\n\n
  \ \nSymbols, also known as Atoms or Interned Strings, are a common technique\nto
  reduce memory usage and improve performance when using many small strings:\n\nA
  Symbol represents a string (any `Textual`, so String, Text, ShortText, ByteString,
  ShortByteString, etc.)\n\nJust like `ShortText`, `ShortByteString` and `ByteArray`,
  a `Symbol` has an optimized memory representation,\ndirectly wrapping a primitive
  `ByteArray#`.\n\nFurthermore, a global symbol table keeps track of which values
  currently exist, ensuring we always deduplicate symbols.\nThis therefore allows
  us to:\n- Check for equality between symbols in constant-time (using pointer equality)\n-
  Calculate the hash in constant-time (using `StableName`)\n- Keep the memory footprint
  of repeatedly-seen strings low.\n\nThis is very useful if you're frequently comparing
  strings\nand the same strings might come up many times.\nIt also makes Symbol a
  great candidate for a key in e.g. a `HashMap` or `HashSet`.\n\nThe global symbol
  table is implemented using weak pointers,\nwhich means that unused symbols will
  be garbage collected.\nAs such, you do not need to be concerned about memory leaks\n(as
  is the case with many other symbol table implementations).\n\nSymbols are considered
  'the same' regardless of whether they originate\nfrom a `String`, (lazy or strict,
  normal or short) `Data.Text`, (lazy or strict, normal or short) `Data.ByteString`
  etc.\n\nThe main advantages of Symbolize over other symbol table implementations
  are:\n\n- Garbage collection: Symbols which are no longer used are automatically
  cleaned up.\n- Support for any `Textual` type, including `String`, (strict and lazy)
  `Data.Text`, (strict and lazy) `Data.ByteString`, `ShortText`, `ShortByteString`,
  etc.\n- Great memory usage:\n    - `Symbol`s are simply a (lifted) wrapper around
  a `ByteArray#`, which is nicely unpacked by GHC.\n    - The symbol table is an `IntMap`
  that contains weak pointers to these same `ByteArray#`s and their associated `StableName#`s\n-
  Great performance:\n    - `unintern` is a simple pointer-dereference\n    - calls
  to `lookup` are free of atomic memory barriers (and never have to wait on a concurrent
  thread running `intern`)\n- Thread-safe\n\n## Basic usage\n\nThis module is intended
  to be imported qualified, e.g.\n\n\n```haskell\nimport Symbolize (Symbol)\nimport
  qualified Symbolize\n```\n\nTo intern a string, use `intern`:\n\n```haskell\n>>>
  hello = Symbolize.intern \"hello\"\n>>> world = Symbolize.intern \"world\"\n>>>
  (hello, world)\n(Symbolize.intern \"hello\",Symbolize.intern \"world\")\n```\n\nInterning
  supports any `Textual` type, so you can also use `Data.Text` or `Data.ByteString`
  etc.:\n\n```haskell\n>>> import Data.Text (Text)\n>>> niceCheeses = fmap Symbolize.intern
  ([\"Roquefort\", \"Camembert\", \"Brie\"] :: [Text])\n>>> niceCheeses\n[Symbolize.intern
  \"Roquefort\",Symbolize.intern \"Camembert\",Symbolize.intern \"Brie\"]\n```\n\nAnd
  if you are using OverloadedStrings, you can use the `IsString` instance to intern
  constants:\n\n```haskell\n>>> hello2 = (\"hello\" :: Symbol)\n>>> hello2\nSymbolize.intern
  \"hello\"\n```\n\nComparisons between symbols run in O(1) time:\n\n```haskell\n>>>
  hello == hello2\nTrue\n>>> hello == world\nFalse\n```\n\nTo get back the textual
  value of a symbol, use `unintern`:\n\n```haskell\n>>> Symbolize.unintern hello\n\"hello\"\n```\n\nIf
  you only want to check whether a string is already interned, use `lookup`:\n\n```haskell\n>>>
  Symbolize.lookup \"hello\"\nJust (Symbolize.intern \"hello\")\n```\n\nSymbols make
  great keys for `Data.HashMap` and `Data.HashSet`.\nHashing them is a no-op and they
  are guaranteed to be unique:\n\n```haskell\n>>> import qualified Data.Hashable as
  Hashable\n>>> Hashable.hash hello\n0\n>>> fmap Hashable.hash niceCheeses\n[2,3,4]\n```\n\nFor
  introspection, you can look at how many symbols currently exist:\n\n```haskell\n>>>
  Symbolize.globalSymbolTableSize\n5\n>>> [unintern (intern (show x)) | x <- [1..5]]\n[\"1\",\"2\",\"3\",\"4\",\"5\"]\n>>>
  Symbolize.globalSymbolTableSize\n10\n```\n\nUnused symbols will be garbage-collected,
  so you don't have to worry about memory leaks:\n\n```haskell\n>>> System.Mem.performGC\n>>>
  Symbolize.globalSymbolTableSize\n5\n```\n\nFor deeper introspection, you can look
  at the Show instance of the global symbol table:\n/(Note that the exact format is
  subject to change.)/\n\n```haskell\n>>> Symbolize.globalSymbolTable\nGlobalSymbolTable
  { size = 5, symbols = [\"Brie\",\"Camembert\",\"Roquefort\",\"hello\",\"world\"]
  }\n```\n"
description-type: markdown
hash: dace8ca07764ac35eb5747c9d6289490706a21b5c9e4e339f74ff26aa869f0cd
homepage: https://github.com/Qqwy/haskell-symbolize#readme
latest: 1.0.2.0
license-name: BSD-3-Clause
maintainer: qqwy@gmx.com
synopsis: Efficient global Symbol table, with Garbage Collection.
test-bench-deps:
  async: '>=0'
  base: '>=4.7 && <5'
  binary: '>=0.8.9 && <0.9'
  bytestring: '>=0.11.0 && <0.13'
  containers: '>=0.6.0 && <0.7'
  deepseq: '>=1.4.0 && <1.6'
  doctest-parallel: '>=0'
  hashable: '>=1.4.0 && <1.5'
  hedgehog: '>=0'
  random: '>=1.2 && <2'
  symbolize: '>=0'
  tasty: '>=0'
  tasty-golden: '>=0'
  tasty-hedgehog: '>=0'
  tasty-hunit: '>=0'
  text: '>=2.0 && <2.2'
  text-short: '>=0.1.0 && <0.2'
