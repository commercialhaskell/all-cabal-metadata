homepage: https://github.com/jamesdbrock/replace-megaparsec
changelog-type: markdown
hash: 062c6a860a50811f80dbdbf492dbcd794bd656601e460510c9c267df403bb886
test-bench-deps:
  bytestring: -any
  base: -any
  hspec: '>=2.0.0 && <3.0.0'
  text: -any
  megaparsec: -any
  replace-megaparsec: -any
maintainer: James Brock <jamesbrock@gmail.com>
synopsis: Find, replace, split string patterns with Megaparsec parsers (instead of
  regex)
changelog: |+
  # Revision history for replace-megaparsec

  ## 1.5.0.0 -- 2023-05-30

  Upgrade to GHC v9.4.4, text v2.0.1

  Text does not work with GHC v9.4.3

  Test
  * exitcode-stdio-1.0 instead of detailed-0.9
  * HSpec instead of Cabal Distribution.TestSuite

  Added megaparsec version bounds #36

  ## 1.4.5.0 -- 2022-04-14

  Minor documentation changes.

  Confirmed tests pass for text v2.

  ## 1.4.4.0 -- 2020-12-04

  Add `splitCapT` and `breakCapT`.

  ## 1.4.3.0 -- 2020-09-28

  Bugfix sepCap backtracking when sep fails

  See [#33](https://github.com/jamesdbrock/replace-megaparsec/issues/33)

  ## 1.4.1.0 -- 2020-05-07

  anyTill use getInput instead of takeRest

  ## 1.4.0.0 -- 2020-05-06

  __Running Parsers__: Add `splitCap` and `breakCap`.

  __Parser Combinators__: Add `anyTill`.

  Remove `Show` and `Typeable` constraints on `streamEditT`.

  ## 1.3.0.0 -- 2020-03-06

  `sepCap` won't throw.

  Don't throw an exception on an unreachable error case, just bottom.
  Remove type constraints for `Exception`.

  ## 1.2.1.0 -- 2020-01-01

  Allow any error parameter, not just `Void`.

  ## 1.2.0.0 -- 2019-10-31

  Benchmark improvements

  Specializations of the `sepCap` function, guided by
  [replace-benchmark](https://github.com/jamesdbrock/replace-benchmark).

  ### New benchmarks

  | Program                                           | dense     | sparse   |
  | :---                                              |      ---: |     ---: |
  | `Replace.Megaparsec.streamEdit` `String`          | 454.95ms  | 375.04ms |
  | `Replace.Megaparsec.streamEdit` `ByteString`      | 529.99ms  | 73.76ms  |
  | `Replace.Megaparsec.streamEdit` `Text`            | 547.47ms  | 139.21ms |

  ### Old benchmarks

  | Program                                           | dense     | sparse   |
  | :---                                              |      ---: |     ---: |
  |  `Replace.Megaparsec.streamEdit`     `String`     | 454.95ms  | 375.04ms |
  |  `Replace.Megaparsec.streamEdit`     `ByteString` | 611.98ms  | 433.26ms |
  |  `Replace.Megaparsec.streamEdit`     `Text`       | 592.66ms  | 353.32ms |

  ## 1.1.5.0 -- 2019-10-08

  * Move benchmarks to [__replace-benchmark__](https://github.com/jamesdbrock/replace-benchmark)

  ## 1.1.0.0 -- 2019-09-01

  * Add benchmark suite.
  * In `streamEditT`, replace `fold` with `mconcat`. The benchmarks now show
    linear scaling instead of quadratic.

  ## 1.0.1.0 -- 2019-08-28

  * Add test suite.
  * `sepCap` will treats `sep` as failing if it succeeds but consumes no input.

  ## 1.0.0.0 -- 2019-08-24

  * First version.

basic-deps:
  bytestring: '>=0.2 && <1.0'
  base: '>=4.0 && <5.0'
  parser-combinators: '>=1.2.0 && <2.0.0'
  text: '>=0.2 && <3.0'
  megaparsec: '>=7.0.0 && <10.0.0'
all-versions:
- 1.0.0.0
- 1.0.1.0
- 1.1.0.0
- 1.1.1.0
- 1.1.2.0
- 1.1.3.0
- 1.1.4.0
- 1.1.5.0
- 1.2.0.0
- 1.2.1.0
- 1.3.0.0
- 1.3.1.0
- 1.3.2.0
- 1.4.0.0
- 1.4.1.0
- 1.4.2.0
- 1.4.3.0
- 1.4.4.0
- 1.4.5.0
- 1.5.0.0
- 1.5.0.1
author: James Brock <jamesbrock@gmail.com>
latest: 1.5.0.1
description-type: markdown
description: "# replace-megaparsec\n\n[![Hackage](https://img.shields.io/hackage/v/replace-megaparsec.svg?style=flat)](https://hackage.haskell.org/package/replace-megaparsec)\n[![Stackage
  Nightly](http://stackage.org/package/replace-megaparsec/badge/nightly)](http://stackage.org/nightly/package/replace-megaparsec)\n[![Stackage
  LTS](http://stackage.org/package/replace-megaparsec/badge/lts)](http://stackage.org/lts/package/replace-megaparsec)\n\n*
  [Usage Examples](#usage-examples)\n* [In the Shell](#in-the-shell)\n* [Alternatives](#alternatives)\n*
  [Benchmarks](#benchmarks)\n* [Hypothetically Asked Questions](#hypothetically-asked-questions)\n\n__replace-megaparsec__
  is for finding text patterns, and also\nreplacing or splitting on the found patterns.\nThis
  activity is traditionally done with regular expressions,\nbut __replace-megaparsec__
  uses\n[__megaparsec__](http://hackage.haskell.org/package/megaparsec)\nparsers instead
  for the pattern matching.\n\n__replace-megaparsec__ can be used in the same sort
  of “pattern capture”\nor “find all” situations in which one would use Python\n[`re.findall`](https://docs.python.org/3/library/re.html#re.findall)\nor\nPerl
  [`m//`](https://perldoc.perl.org/functions/m.html),\nor\nUnix [`grep`](https://www.gnu.org/software/grep/).\n\n__replace-megaparsec__
  can be used in the same sort of “stream editing”\nor “search-and-replace” situations
  in which one would use Python\n[`re.sub`](https://docs.python.org/3/library/re.html#re.sub),\nor\nPerl
  [`s///`](https://perldoc.perl.org/functions/s.html),\nor Unix\n[`sed`](https://www.gnu.org/software/sed/manual/html_node/The-_0022s_0022-Command.html),\nor\n[`awk`](https://www.gnu.org/software/gawk/manual/gawk.html).\n\n__replace-megaparsec__
  can be used in the same sort of “string splitting”\nsituations in which one would
  use Python\n[`re.split`](https://docs.python.org/3/library/re.html#re.split)\nor
  Perl\n[`split`](https://perldoc.perl.org/functions/split.html).\n\nSee [__replace-attoparsec__](https://hackage.haskell.org/package/replace-attoparsec)\nfor
  the\n[__attoparsec__](http://hackage.haskell.org/package/attoparsec)\nversion.\n\n##
  Why would we want to do pattern matching and substitution with parsers instead of
  regular expressions?\n\n* Haskell parsers have a nicer syntax than\n  [regular expressions](https://en.wikipedia.org/wiki/Regular_expression),\n
  \ which are notoriously\n  [difficult to read](https://en.wikipedia.org/wiki/Write-only_language).\n\n*
  Regular expressions can do “group capture” on sections of the matched\n  pattern,
  but they can only return stringy lists of the capture groups. Parsers\n  can construct
  typed data structures based on the capture groups, guaranteeing\n  no disagreement
  between the pattern rules and the rules that we're using\n  to build data structures
  based on the pattern matches.\n\n  For example, consider\n  scanning a string for
  numbers. A lot of different things can look like a number,\n  and can have leading
  plus or minus signs, or be in scientific notation, or\n  have commas, or whatever.
  If we try to parse all of the numbers out of a string\n  using regular expressions,
  then we have to make sure that the regular expression\n  and the string-to-number
  conversion function agree about exactly what is\n  and what isn't a numeric string.
  We can get into an awkward situation in which\n  the regular expression says it
  has found a numeric string but the\n  string-to-number conversion function fails.
  A typed parser will perform both\n  the pattern match and the conversion, so it
  will never be in that situation.\n  [Parse, don't validate.](https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/)\n\n*
  Regular expressions are only able to pattern-match\n  [regular](https://en.wikipedia.org/wiki/Chomsky_hierarchy#The_hierarchy)\n
  \ grammars.\n  Megaparsec parsers are able pattern-match context-free grammars,
  and\n  even context-sensitive grammars, if needed. See below for\n  an example of
  lifting a `Parser` into a `State` monad for context-sensitive\n  pattern-matching.\n\n*
  The replacement expression for a traditional regular expression-based\n  substitution
  command is usually just a string template in which\n  the *Nth* “capture group”
  can be inserted with the syntax `\\N`. With\n  this library, instead of a template,
  we get\n  an `editor` function which can perform any computation, including IO.\n\n#
  Usage Examples\n\nThe examples depend on these imports.\n\n```haskell\nimport Data.Void\nimport
  Replace.Megaparsec\nimport Text.Megaparsec\nimport Text.Megaparsec.Char\nimport
  Text.Megaparsec.Char.Lexer\n```\n\n## Split strings with `splitCap`\n\n### Find
  all pattern matches, capture the matched text and the parsed result\n\nSeparate
  the input string into sections which can be parsed as a hexadecimal\nnumber with
  a prefix `\"0x\"`, and sections which can't. Parse the numbers.\n\n```haskell\nlet
  hexparser = chunk \"0x\" *> hexadecimal :: Parsec Void String Integer\nsplitCap
  (match hexparser) \"0xA 000 0xFFFF\"\n```\n```haskell\n[Right (\"0xA\",10), Left
  \" 000 \", Right (\"0xFFFF\",65535)]\n```\n\n### Find all pattern matches, capture
  only the locations of the matched patterns\n\nFind all of the sections of the stream
  which are letters. Capture a list of\nthe offsets of the beginning of every pattern
  match.\n\n```haskell\nimport Data.Either\nlet letterOffset = getOffset <* some letterChar
  :: Parsec Void String Int\nrights $ splitCap letterOffset \" a  bc \"\n```\n```haskell\n[1,4]\n```\n###
  Pattern match balanced parentheses\n\nFind groups of balanced nested parentheses.
  This is an example of a\n“context-free” grammar, a pattern that can't be expressed
  by a regular\nexpression. We can express the pattern with a recursive parser.\n\n```haskell\nimport
  Data.Functor (void)\nimport Data.Bifunctor (second)\nlet parens :: Parsec Void String
  ()\n    parens = do\n        char '('\n        manyTill\n            (void (noneOf
  \"()\") <|> void parens)\n            (char ')')\n        pure ()\n\nsecond fst
  <$> splitCap (match parens) \"(()) (()())\"\n```\n```haskell\n[Right \"(())\",Left
  \" \",Right \"(()())\"]\n```\n\n## Edit strings with `streamEdit`\n\nThe following
  examples show how to search for a pattern in a string of text\nand then edit the
  string of text to substitute in some replacement text\nfor the matched patterns.\n\n###
  Pattern match and replace with a constant\n\nReplace all carriage-return-newline
  occurances with newline.\n\n```haskell\nlet crnl = chunk \"\\r\\n\" :: Parsec Void
  String String\nstreamEdit crnl (const \"\\n\") \"1\\r\\n2\\r\\n\"\n```\n```haskell\n\"1\\n2\\n\"\n```\n\n###
  Pattern match and edit the matches\n\nReplace alphabetic characters with the next
  character in the alphabet.\n\n```haskell\nlet somelet = some letterChar :: Parsec
  Void String String\nstreamEdit somelet (fmap succ) \"HAL 9000\"\n```\n```haskell\n\"IBM
  9000\"\n```\n\n### Pattern match and maybe edit the matches, or maybe leave them
  alone\n\nFind all of the string sections *`s`* which can be parsed as a\nhexadecimal
  number *`r`*,\nand if *`r≤16`*, then replace *`s`* with a decimal number. Uses the\n[`match`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec.html#v:match)\ncombinator.\n\n```haskell\nlet
  hexparser = chunk \"0x\" *> hexadecimal :: Parsec Void String Integer\nstreamEdit
  (match hexparser) (\\(s,r) -> if r<=16 then show r else s) \"0xA 000 0xFFFF\"\n```\n```haskell\n\"10
  000 0xFFFF\"\n```\n\n### Pattern match and edit the matches with IO with [`streamEditT`](https://hackage.haskell.org/package/replace-megaparsec/docs/Replace-Megaparsec.html#v:streamEditT)\n\nFind
  an environment variable in curly braces and replace it with its\nvalue from the
  environment.\n\n```haskell\nimport System.Environment (getEnv)\nlet bracevar = char
  '{' *> manyTill anySingle (char '}') :: ParsecT Void String IO String\nstreamEditT
  bracevar getEnv \"- {HOME} -\"\n```\n```haskell\n\"- /home/jbrock -\"\n```\n\n###
  Context-sensitive pattern match and edit the matches with [`streamEditT`](https://hackage.haskell.org/package/replace-megaparsec/docs/Replace-Megaparsec.html#v:streamEditT)\n\nCapitalize
  the third letter in a string. The `capThird` parser searches for\nindividual letters,
  and it needs to remember how many times it has run so\nthat it can match successfully
  only on the third time that it finds a letter.\nTo enable the parser to remember
  how many times it has run, we'll\ncompose the parser with a `State` monad from\nthe
  `mtl` package. (Run in `ghci` with `cabal v2-repl -b mtl`). Because it has\nstateful
  memory, this parser is an example of a “context-sensitive” grammar.\n\n```haskell\nimport
  qualified Control.Monad.State.Strict as MTL\nimport Control.Monad.State.Strict (get,
  put, evalState)\nimport Data.Char (toUpper)\n\nlet capThird :: ParsecT Void String
  (MTL.State Int) String\n    capThird = do\n        x <- letterChar\n        i <-
  get\n        let i' = i+1\n        put i'\n        if i'==3 then pure [x] else empty\n\nflip
  evalState 0 $ streamEditT capThird (pure . fmap toUpper) \"a a a a a\"\n```\n```haskell\n\"a
  a A a a\"\n```\n\n\n### Pattern match, edit the matches, and count the edits with
  [`streamEditT`](https://hackage.haskell.org/package/replace-megaparsec/docs/Replace-Megaparsec.html#v:streamEditT)\n\nFind
  and capitalize no more than three letters in a string, and return the \nedited string
  along with the number of letters capitalized. To enable the\neditor function to
  remember how many letters it has capitalized, we'll \nrun `streamEditT` in the `State`
  monad from the `mtl` package. Use this\ntechnique to get the same functionality
  as Python\n[`re.subn`](https://docs.python.org/3/library/re.html#re.subn).\n\n```haskell\nimport
  qualified Control.Monad.State.Strict as MTL\nimport Control.Monad.State.Strict (get,
  put, runState)\nimport Data.Char (toUpper)\n\nlet editThree :: Char -> MTL.State
  Int String\n    editThree x = do\n        i <- get\n        if i<3\n            then
  do\n                put $ i+1\n                pure [toUpper x]\n            else
  pure [x]\n\nflip runState 0 $ streamEditT letterChar editThree \"a a a a a\"\n```\n```haskell\n(\"A
  A A a a\",3)\n```\n\n\n### Non-greedy pattern repetition\n\nThis is not a feature
  of this library, but it’s\na useful technique to know.\n\nHow do we do non-greedy
  repetition of a pattern `p`, like we would in Regex\nby writing `p*?`?\n\nBy using
  the\n[`manyTill_`](https://hackage.haskell.org/package/parser-combinators/docs/Control-Monad-Combinators.html#v:manyTill_)
  combinator. To repeat pattern `p` non-greedily, write\n`manyTill_ p q` where `q`
  is the entire rest of the parser.\n\nFor example, this parse fails because `many`
  repeats the pattern `letterChar`\ngreedily.\n\n```haskell\nflip parseMaybe \"aab\"
  $ do\n  a <- many letterChar\n  b <- single 'b'\n  pure (a,b)\n```\n```haskell\nNothing\n```\n\nTo
  repeat pattern `letterChar` non-greedily, use `manyTill_`.\n\n```haskell\nflip parseMaybe
  \"aab\" $ do\n  (a,b) <- manyTill_ letterChar $ do\n    single 'b'\n  pure (a,b)\n```\n```haskell\nJust
  (\"aa\",'b')\n```\n\n\n# In the Shell\n\nIf we're going to have a viable `sed` replacement
  then we want to be able\nto use it easily from the command line. This\n[Stack script
  interpreter](https://docs.haskellstack.org/en/stable/GUIDE/#script-interpreter)\nscript
  will find decimal numbers in a stream and replace them with their double.\n\n```haskell\n#!/usr/bin/env
  stack\n{- stack\n  script\n  --resolver lts-16\n  --package megaparsec\n  --package
  replace-megaparsec\n-}\n-- https://docs.haskellstack.org/en/stable/GUIDE/#script-interpreter\n\nimport
  Data.Void\nimport Text.Megaparsec\nimport Text.Megaparsec.Char\nimport Text.Megaparsec.Char.Lexer\nimport
  Replace.Megaparsec\n\nmain = interact $ streamEdit (decimal :: Parsec Void String
  Int) (show . (*2))\n```\n\nIf you have\n[The Haskell Tool Stack](https://docs.haskellstack.org/en/stable/README/)\ninstalled
  then you can just copy-paste this into a file named `doubler.hs` and\nrun it. (On
  the first run Stack may need to download the dependencies.)\n\n```bash\n$ chmod
  u+x doubler.hs\n$ echo \"1 6 21 107\" | ./doubler.hs\n2 12 42 214\n```\n\n\n# Alternatives\n\nSome
  libraries that one might consider instead of this one.\n\n<http://hackage.haskell.org/package/regex-applicative>\n\n<http://hackage.haskell.org/package/pcre-heavy>\n\n<http://hackage.haskell.org/package/lens-regex-pcre>\n\n<http://hackage.haskell.org/package/regex>\n\n<http://hackage.haskell.org/package/pipes-parse>\n\n<http://hackage.haskell.org/package/stringsearch>\n\n<http://hackage.haskell.org/package/substring-parser>\n\n<http://hackage.haskell.org/package/pcre-utils>\n\n<http://hackage.haskell.org/package/template>\n\n#
  Benchmarks\n\nThese benchmarks are intended to measure the wall-clock speed\nof
  *everything except the actual pattern-matching*. Speed of the\npattern-matching
  is the responsibility of the\n[__megaparsec__](http://hackage.haskell.org/package/megaparsec)
  and\n[__attoparsec__](http://hackage.haskell.org/package/attoparsec)\nlibraries.\n\nThe
  benchmark task is to find all of the one-character patterns `x` in a\ntext stream
  and replace them by a function which returns the constant\nstring `oo`. So, like
  the regex `s/x/oo/g`.\n\nWe have two benchmark input cases, which we call __dense__
  and __sparse__.\n\nThe __dense__ case is one megabyte of alternating spaces and
  `x`s\nlike\n\n```\nx x x x x x x x x x x x x x x x x x x x x x x x x x x x\n```\n\nThe
  __sparse__ case is one megabyte of spaces with a single `x` in the middle\nlike\n\n```\n
  \                        x\n```\n\nEach benchmark program reads the input from `stdin`,
  replaces `x` with `oo`,\nand writes the result to `stdout`. The time elapsed is
  measured by `perf stat`,\nand the best observed time is recorded.\n\nSee [replace-benchmark](https://github.com/jamesdbrock/replace-benchmark)\nfor
  details.\n\n| Program                                           | dense     | sparse
  \  |\n| :---                                              |      ---: |     ---:
  |\n| [Python 3.7.4 `re.sub`][sub] *repl* function      | 89.23ms   | 23.98ms  |\n|
  [Perl 5 `s///ge`][s]                              | 180.65ms  | 5.02ms   |\n| [`Replace.Megaparsec.streamEdit`][m]
  `String`     | 441.94ms  | 375.04ms |\n| [`Replace.Megaparsec.streamEdit`][m] `ByteString`
  | 529.99ms  | 73.76ms  |\n| [`Replace.Megaparsec.streamEdit`][m] `Text`       |
  547.47ms  | 139.21ms |\n| [`Replace.Attoparsec.ByteString.streamEdit`][ab]  | 394.12ms
  \ | 41.13ms  |\n| [`Replace.Attoparsec.Text.streamEdit`][at]        | 515.26ms  |
  46.10ms  |\n| [`Text.Regex.Applicative.replace`][ra] `String`   | 1083.98ms | 646.40ms
  |\n| [`Text.Regex.PCRE.Heavy.gsub`][ph] `Text`         | > 10min   | 14.29ms  |\n|
  [`Control.Lens.Regex.ByteString.match`][lb]       | > 10min   | 4.27ms   |\n| [`Control.Lens.Regex.Text.match`][lt]
  \            | > 10min   | 14.74ms  |\n\n[sub]: https://docs.python.org/3/library/re.html#re.sub\n[s]:
  https://perldoc.perl.org/functions/s.html\n[m]: https://hackage.haskell.org/package/replace-megaparsec/docs/Replace-Megaparsec.html#v:streamEdit\n[ab]:
  https://hackage.haskell.org/package/replace-attoparsec/docs/Replace-Attoparsec-ByteString.html#v:streamEdit\n[at]:
  https://hackage.haskell.org/package/replace-attoparsec/docs/Replace-Attoparsec-Text.html#v:streamEdit\n[ra]:
  http://hackage.haskell.org/package/regex-applicative/docs/Text-Regex-Applicative.html#v:replace\n[ss]:
  http://hackage.haskell.org/package/stringsearch/docs/Data-ByteString-Search.html#v:replace\n[ph]:
  http://hackage.haskell.org/package/pcre-heavy/docs/Text-Regex-PCRE-Heavy.html#v:gsub\n[lb]:
  https://hackage.haskell.org/package/lens-regex-pcre/docs/Control-Lens-Regex-ByteString.html#v:match\n[lt]:
  https://hackage.haskell.org/package/lens-regex-pcre/docs/Control-Lens-Regex-Text.html#v:match\n\n\n#
  Hypothetically Asked Questions\n\n1. *Could we write this library for __parsec__?*\n\n
  \  No, because the\n   [`match`](https://hackage.haskell.org/package/megaparsec/docs/Text-Megaparsec.html#v:match)\n
  \  combinator doesn't exist for __parsec__. (I can't find it anywhere.\n   [Can
  it be written?](http://www.serpentine.com/blog/2014/05/31/attoparsec/#from-strings-to-buffers-and-cursors))\n\n2.
  *Is this a good idea?*\n\n   You may have\n   [heard it suggested](https://stackoverflow.com/questions/57667534/how-can-i-use-a-parser-in-haskell-to-find-the-locations-of-some-substrings-in-a/57712672#comment101804063_57667534)\n
  \  that monadic parsers are better for pattern-matching when\n   the input stream
  is mostly signal, and regular expressions are better\n   when the input stream is
  mostly noise.\n\n   The premise of this library is that monadic parsers are great
  for finding\n   small signal patterns in a stream of otherwise noisy text.\n\n   Our
  reluctance to forego the speedup opportunities afforded by restricting\n   ourselves
  to regular grammars is an old superstition about\n   opportunities which\n   [remain
  mostly unexploited anyway](https://swtch.com/~rsc/regexp/regexp1.html).\n   The
  performance compromise of allowing stack memory allocation (a.k.a. pushdown\n   automata,
  a.k.a. context-free grammar) was once considered\n   [controversial for *general-purpose*
  programming languages](https://vanemden.wordpress.com/2014/06/18/how-recursion-got-into-programming-a-comedy-of-errors-3/).\n
  \  I think we\n   can now resolve that controversy the same way for pattern matching
  languages.\n"
license-name: BSD-2-Clause
