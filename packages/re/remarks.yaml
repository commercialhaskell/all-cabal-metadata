all-versions:
- 0.1.0
- 0.1.1
- 0.1.2
- 0.1.3
- 0.1.4
- 0.1.5
- 0.1.6
- 0.1.7
- 0.1.8
- 0.1.9
- 0.1.10
- 0.1.11
- 0.1.12
- 0.1.13
author: Oleks Shturmov <oleks@oleks.info>, Michael Kirkedal
basic-deps:
  GenericPretty: '>=1.2.1'
  base: '>=4.7 && <5'
  containers: '>=0.5.7.1'
  directory: '>=1.2.6.2'
  filepath: '>=1.4.1.0'
  pretty: '>=1.1.3.3'
  remarks: '>=0'
changelog: ''
changelog-type: ''
description: "# `remarks` — A DSL for marking student work\n\n[![License: BSD 3-Clause](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](LICENSE)\n[![Travis
  CI (Linux + macOS) Status](https://travis-ci.org/DIKU-EDU/remarks.svg)](https://travis-ci.org/DIKU-EDU/remarks)\n[![AppVeyor
  (Windows) Status\"](https://ci.appveyor.com/api/projects/status/g0hviw442o2bl8yi?svg=true)](https://ci.appveyor.com/project/DIKU-EDU/remarks)\n\nWhen
  judging student performance, it is useful to have both small, composable,\nquantitative
  judgements, and qualitative remarks. This makes both spreadsheets\nand mere text-files
  ill-suited for marking student work.  Although\n[org-mode](http://orgmode.org/)
  can solve this problem to a great extent, it\nbecomes a heavy tool in the light
  of having to mark hundreds of students in a\ndistributed fashion. With org-mode,
  everything is in one file, while global,\nintra-student statistics are not needed
  until all the students have been fully\nmarked.\n\n## Design Goals\n\n  1. One,
  or several, human-readable/editable file(s) _per student_.\n  2. git-friendly file
  format.\n  3. Export options to spreadsheet-formats.\n  4. Synchronization options
  with Dropbox and/or Google Drive.\n\nGoal 4 is not necessarily related to `remarks`,
  but is related to marking\nstudent work with external examiners, who are not always
  willing to use more\nexplicit version-control systems, such as git.\n\n## Usage\n\nUser
  features:\n\n* `remarks check [<file>]` checks that the file system structure is\n
  \ well-formed. For instance, checks that all explicitly stated point sums\n  are
  correct.\n* `remarks show [<file>]` checks the file system structure as above, and
  shows\n  the overall judgement for each given argument.\n* `remarks summary [--depth
  <depth>] [<file>]` checks and summarizes the points.\n  Depth 0 (default) lists
  just the top-level judgements.\n* `remarks pending [--depth <depth>] [<file>]` shown
  the corrections that has not\n  been completed. Can be cut at a given depth; depth
  0 lists just the top-level judgements.\n* `remarks export [--format \"<format>\"]
  [<file>]` exports corrections to a semicolon separated \n  list. The format is a
  semicolon separated string of properties.\n* `remarks exportHTML [<file>]` exports
  all corrections to a dynamic html-table.\nDeveloper features:\n\n* `remarks parse
  [<file>]` parses the given files and shows their ASTs.\n\n## Installation\n\n`remarks`
  is on [Hackage](http://hackage.haskell.org/package/remarks), so you\ncan use [Cabal](https://www.haskell.org/cabal/):\n\n```\n$
  cabal install remarks\n```\n\nIf you clone the repository, or [download the\nsources](https://github.com/DIKU-EDU/remarks/releases),
  you get two further\noptions:\n\n* If you are using the purely functional package
  manager\n  [Nix](https://nixos.org/nix/), you can do this:\n\n  ```\n  $ nix-build\n
  \ ```\n\n  This will create a symlink `result`, pointing to the directory in your
  Nix\n  store, containing the binary.\n\n* Or, if using [Stack](https://docs.haskellstack.org/en/stable/README/),
  you\n  can do this:\n\n  ```\n  $ stack build\n  $ stack install\n  ```\n\n## Syntax\n\nA
  `.mrk` file is a list of judgements.\n\nA judgement starts with a header mark (a
  sequence of `#`), a title (followed by\na `:`), given points (followed by `/`),
  and maximum points (followed by a line\nbreak). The number of `#` determines the
  _depth_ of the header, and every file\n_must_ start at depth 1, but may have multiple
  depth 1 judgements. Headings may\nbe arbitrarily nested, but must sum up correctly.
  For instance, here is a file\ncontaining only quantitative remarks:\n\n```\n# Theory:
  27/50\n## Question 1: 10/10\n## Question 2: 10/20\n## Question 3: 7/20\n# Practice:
  35/50\n## Task 1: 20/25\n## Task 2: 15/25\n```\n\nThe header of a judgement may
  be followed by qualitative remarks. Remarks begin\nwith an indent (two spaces),
  and a mood mark:\n\n  * `*` for neutral/structural remarks;\n  * `+` for positive
  remarks;\n  * `-` for negative remarks;\n  * `?` for impartial remarks.\n\nImpartial
  remarks are good for judgements where the mood is left to be judged\nby a higher
  authority. For instance, when a teaching assistant is uncertain,\nand would like
  to let the teacher decide, or the solution cannot be used to\nmake a judgement about
  this point.\n\nStructural remarks are good for listing things to look for. For instance,
  a\n(template) judgement for an operating systems exercise might look something\nlike
  this:\n\n```\n## T1: /15\n\n### Formal requirements: /5\n  * Has code\n  * Has XML
  in a reloadable/testable form\n  * Has an explanation\n\n### Quality assessment:
  /10\n  * Understands semaphores\n  * Understands deadlocks\n  * Understands starvation\n
  \ * Avoids deadlocks\n  * Avoids starvation\n  * Avoids race conditions\n  * Has
  a good degree of multiprogramming\n  * Solves the problem\n\n### Bonus: +0\n  *
  Has an accompanying implementation / simulation\n```\n\nOnce filled in by a teaching
  assistant, this may look something like this:\n\n```\n## T1: 9/15\n\n### Formal
  requirements: 5/5\n  * Has code\n    + Yes.\n  * Has XML in a reloadable/testable
  form\n    + Yes.\n  * Has an explanation\n    + Yes.\n\n### Quality assessment:
  2/10\n  * Understands semaphores\n    - Seems to treat them as counters. Report
  doesn't talk about procuring or\n      vacating at all.\n    - Checks semaphore
  value directly.\n    - Seems to have mixed up procure and vacate.\n  * Understands
  deadlocks\n    - If more than 5 cars arrive, then only 5 cars will be allowed to
  drive\n      through, and everything will then deadlock.\n  * Understands starvation\n
  \   ? Seems to, but this is hard to judge.\n  * Avoids deadlocks\n    ? See above.\n
  \ * Avoids starvation\n    ? Can't judge this.\n  * Avoids race conditions\n    -
  Uses a busy loop in attempt to synchronize.\n    - There is a race condition after
  the busy loop.\n  * Has a good degree of multiprogramming\n    + It's a ticket system,
  so it could be okay.\n  * Solves the problem\n    + In a complicated way, but yes.\n\n###
  Bonus: +2\n  * Has an accompanying implementation / simulation\n    + Yes!\n```\n\nBonus-judgements
  _must_ have the title `Bonus`, but they don't have to be there\nif you don't like
  them. The presence of bonus judgments also allows points to\nsum up to more than
  the given maximum. This is regarded as a feature.\n\n## Points and Sums\n\nYou do
  not need to manually enter sums. Points are only required for the\nbottom-most judgements.
  Given the template above you can do a `remarks check`\nto check if all necessary
  points have been given. This makes a \"pointless\"\ntemplate a rather useful starting
  point for grading.\n\nPoints can be integers or half-points, that is, the number
  may end in `.5`.\nPlease note, `.5` is exactly representable in an IEEE-754 (the
  internal\nrepresentation of points), so no numerical imprecision occurs when dealing
  with\nhalf-points. Maximum points may only be integers (the internal representation\nof
  maximum points is still an IEEE-754 double to avoid numerical conversions).\n\n##
  Files and Directories\n\nThe file-format is kept \"git-friendly\" by keeping it
  comprehensible in\nplain-text, and allowing for independent marking by splitting
  the remarks for a\nstudent into multiple files.\n\nThe simplest setup is to have
  one `.mrk` file per student (e.g.\n[basic.mrk](samples/organization/basic.mrk)).\n\nTo
  support more exotic setups, `remarks` can also work with directories:\n\n  * If
  supplied with a directory path, `remarks` looks for files ending in\n    `.mrk`
  inside that directory, and comprehends the files as above, in\n    lexicographic
  filename order (e.g.,\n    [directory-with-mrk-files](samples/organization/directory-with-mrk-files)).\n\n
  \ * If there exists a directory `<basename>` for any `<basename>.mrk`,\n    `<basename>`
  is recursively searched for further `.mrk` files. Their\n    contents is appended,
  in lexicographic filename order, to the last\n    top-level judgement of `<basename>.mrk`\n
  \   [mixed-directory](samples/organization/mixed-directory)).\n\nSee the [organization
  samples](samples/organization) for some examples of how\njudgements may be structured
  using files and directories.\n\n```\n├── basic.mrk\n├── directory-with-mrk-files\n│  
  ├── 01-theory.mrk\n│   └── 02-practice.mrk\n└── mixed-directory\n    ├── 01-theory.mrk\n
  \   ├── 02-practice\n    │   ├── Task1.mrk\n    │   └── Task2.mrk\n    └── 02-practice.mrk\n```\n\n`basic.mrk`,
  `directory-with-mrk-files`, and `mixed-directory` all parse to the\nsame judgements.
  In particular, the output from the following `remarks`\ncommands is identical:\n\n```\n$
  cd samples/organization/\n$ remarks parse basic.mrk\n$ remarks parse directory-with-mrk-files\n$
  remarks parse mixed-directory\n```\n"
description-type: markdown
hash: f61e70a487026225d9c60a795c53a3dbfe240315d9ad5a1e74171c099e84e5a1
homepage: https://github.com/DIKU-EDU/remarks#readme
latest: 0.1.13
license-name: BSD-3-Clause
maintainer: oleks@oleks.info
synopsis: A DSL for marking student work
test-bench-deps:
  GenericPretty: '>=1.2.1'
  base: '>=0'
  remarks: '>=0'
  tasty: '>=0.11.0.4'
  tasty-golden: '>=2.3.1.1'
  tasty-hunit: '>=0.9.2'
