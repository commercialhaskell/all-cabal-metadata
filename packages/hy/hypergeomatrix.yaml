homepage: https://github.com/stla/hypergeomatrix#readme
changelog-type: markdown
hash: 92d6594d329e4949dd8129825527e3dff8d2ece88c9ae83d87140a26b9e36129
test-bench-deps:
  base: '>=4.7 && <5'
  tasty-hunit: -any
  hypergeomatrix: -any
  tasty: -any
maintainer: laurent_step@outlook.fr
synopsis: Hypergeometric function of a matrix argument
changelog: |-
  1.0.0.0
  -------
  * initial release
basic-deps:
  base: '>=4.7 && <5'
  cyclotomic: '>=1.1.1 && <1.2'
  array: '>=0.5.4.0 && <0.6'
  containers: '>=0.6.4.1 && <0.7'
all-versions:
- 1.0.0.0
author: StÃ©phane Laurent
latest: 1.0.0.0
description-type: markdown
description: "# hypergeomatrix\n\n## Evaluation of the hypergeometric function of
  a matrix argument (Koev & Edelman's algorithm)\n\nLet $(a\\_1, \\ldots, a\\_p)$
  and $(b\\_1, \\ldots, b\\_q)$ be two vectors of real or \ncomplex numbers, possibly
  empty, $\\alpha > 0$ and $X$ a real symmetric or a \ncomplex Hermitian matrix. \nThe
  corresponding *hypergeometric function of a matrix argument* is defined by \n\n$${}\\_pF\\_q^{(\\alpha)}
  \\left(\\begin{matrix} a\\_1, \\ldots, a\\_p \\\\\\\\ b\\_1, \\ldots, b\\_q\\end{matrix};
  X\\right) = \\sum\\_{k=0}^{\\infty}\\sum\\_{\\kappa \\vdash k} \\frac{{(a\\_1)}\\_{\\kappa}^{(\\alpha)}
  \\cdots {(a\\_p)}\\_{\\kappa}^{(\\alpha)}} {{(b\\_1)}\\_{\\kappa}^{(\\alpha)} \\cdots
  {(b\\_q)}\\_{\\kappa}^{(\\alpha)}} \\frac{C\\_{\\kappa}^{(\\alpha)}(X)}{k!}.$$\n\nThe
  inner sum is over the integer partitions $\\kappa$ of $k$ (which we also \ndenote
  by $|\\kappa| = k$). The symbol ${(\\cdot)}\\_{\\kappa}^{(\\alpha)}$ is the \n*generalized
  Pochhammer symbol*, defined by\n\n$${(c)}^{(\\alpha)}\\_{\\kappa} = \\prod\\_{i=1}^{\\ell}\\prod\\_{j=1}^{\\kappa\\_i}
  \\left(c - \\frac{i-1}{\\alpha} + j-1\\right)$$\n\nwhen $\\kappa = (\\kappa\\_1,
  \\ldots, \\kappa\\_\\ell)$. \nFinally, $C\\_{\\kappa}^{(\\alpha)}$ is a *Jack function*.
  \nGiven an integer partition $\\kappa$ and $\\alpha > 0$, and a \nreal symmetric
  or complex Hermitian matrix $X$ of order $n$, \nthe Jack function \n\n$$C\\_{\\kappa}^{(\\alpha)}(X)
  = C\\_{\\kappa}^{(\\alpha)}(x\\_1, \\ldots, x\\_n)$$\n\nis a symmetric homogeneous
  polynomial of degree $|\\kappa|$ in the \neigen values $x\\_1$, $\\ldots$, $x\\_n$
  of $X$. \n\nThe series defining the hypergeometric function does not always converge.
  \nSee the references for a discussion about the convergence. \n\nThe inner sum in
  the definition of the hypergeometric function is over \nall partitions $\\kappa
  \\vdash k$ but actually \n$C\\_{\\kappa}^{(\\alpha)}(X) = 0$ when $\\ell(\\kappa)$,
  the number of non-zero \nentries of $\\kappa$, is strictly greater than $n$.\n\nFor
  $\\alpha=1$, $C\\_{\\kappa}^{(\\alpha)}$ is a *Schur polynomial* and it is \na *zonal
  polynomial* for $\\alpha = 2$. \nIn random matrix theory, the hypergeometric function
  appears for $\\alpha=2$ \nand $\\alpha$ is omitted from the notation, implicitely
  assumed to be $2$. \n\nKoev and Edelman (2006) provided an efficient algorithm for
  the evaluation \nof the truncated series \n\n$$\\sideset{\\_p^m}{\\_q^{(\\alpha)}}F
  \\left(\\begin{matrix} a\\_1, \\ldots, a\\_p \\\\\\\\ b\\_1, \\ldots, b\\_q\\end{matrix};
  X\\right) = \\sum\\_{k=0}^{m}\\sum\\_{\\kappa \\vdash k} \\frac{{(a\\_1)}\\_{\\kappa}^{(\\alpha)}
  \\cdots {(a\\_p)}\\_{\\kappa}^{(\\alpha)}} {{(b\\_1)}\\_{\\kappa}^{(\\alpha)} \\cdots
  {(b\\_q)}\\_{\\kappa}^{(\\alpha)}} \n\\frac{C\\_{\\kappa}^{(\\alpha)}(X)}{k!}.$$\n\nHereafter,
  $m$ is called the *truncation weight of the summation* \n(because $|\\kappa|$ is
  called the weight of $\\kappa$), the vector \n$(a\\_1, \\ldots, a\\_p)$ is called
  the vector of *upper parameters* while \nthe vector $(b\\_1, \\ldots, b\\_q)$ is
  called the vector of *lower parameters*. \nThe user has to supply the vector $(x\\_1,
  \\ldots, x\\_n)$ of the eigenvalues \nof $X$. \n\nFor example, to compute\n\n$$\\sideset{\\_2^{15}}{\\_3^{(2)}}F
  \\left(\\begin{matrix} 3, 4 \\\\\\\\ 5, 6, 7\\end{matrix}; 0.1, 0.4\\right)$$\n\nyou
  have to enter \n\n```haskell\nhypergeomat 15 2 [3.0, 4.0], [5.0, 6.0, 7.0] [0.1,
  0.4]\n```\n\nWe said that the hypergeometric function is defined for a real symmetric
  \nmatrix or a complex Hermitian matrix $X$. Thus the eigenvalues of $X$ \nare real.
  However we do not impose this restriction in `hypergeomatrix`. \nThe user can enter
  any list of real or complex numbers for the eigenvalues. \n\n### Gaussian rational
  numbers\n\nThe library allows to use **Gaussian rational numbers**, i.e. complex
  numbers \nwith a rational real part and a rational imaginary part. The Gaussian
  rational \nnumber $a + ib$ is obtained with `a +: b`, e.g. `(2%3) +: (5%2)`. The
  imaginary \nunit usually denoted by $i$ is represented by `e(4)`:\n\n```haskell\nghci>
  import Math.HypergeoMatrix\nghci> import Data.Ratio\nghci> alpha = 2%1\nghci> a
  = (2%7) +: (1%2)\nghci> b = (1%2) +: (0%1)\nghci> c = (2%1) +: (3%1)\nghci> x1 =
  (1%3) +: (1%4)\nghci> x2 = (1%5) +: (1%6)\nghci> hypergeomat 3 alpha [a, b] [c]
  [x1, x2]\n26266543409/25159680000 + 155806638989/3698472960000*e(4)\n```\n\n###
  Univariate case\n\nFor $n = 1$, the hypergeometric function of a matrix argument
  is known as the \n[generalized hypergeometric function](https://mathworld.wolfram.com/HypergeometricFunction.html).
  \nIt does not depend on $\\alpha$. The case of $\\sideset{\\_{2\\thinspace}^{}}{\\_1^{}}F$
  is the most known, \nthis is the Gauss hypergeometric function. Let's check a value.
  It is known that\n\n$$\\sideset{\\_{2\\thinspace}^{}}{\\_1^{}}F \\left(\\begin{matrix}
  1/4, 1/2 \\\\\\\\ 3/4\\end{matrix}; 80/81\\right) = 1.8.$$\n\nSince $80/81$ is close
  to $1$, the convergence is slow. We compute the truncated series below \nfor $m
  = 300$.\n\n```haskell\nghci> h <- hypergeomat 300 2 [1/4, 1/2] [3/4] [80/81]\nghci>
  h\n1.7990026528192298\n```\n\n\n## References\n\n- Plamen Koev and Alan Edelman.
  \n*The efficient evaluation of the hypergeometric function of a matrix argument*.\nMathematics
  of computation, vol. 75, n. 254, 833-846, 2006.\n\n- Robb Muirhead. \n*Aspects of
  multivariate statistical theory*. \nWiley series in probability and mathematical
  statistics. \nProbability and mathematical statistics. \nJohn Wiley & Sons, New
  York, 1982.\n\n- A. K. Gupta and D. K. Nagar. \n*Matrix variate distributions*.
  \nChapman and Hall, 1999.\n"
license-name: BSD-3-Clause
