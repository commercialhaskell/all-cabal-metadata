homepage: https://github.com/stla/hypergeomatrix#readme
changelog-type: markdown
hash: 1018f7e1a45ca651c09064fd11bf1308734722d07a2e2679463acb309993543d
test-bench-deps:
  base: '>=4.7 && <5'
  tasty-hunit: '>=0.10.0.3 && <0.11'
  hypergeomatrix: -any
  tasty: '>=1.4.2.3 && <1.5'
maintainer: laurent_step@outlook.fr
synopsis: Hypergeometric function of a matrix argument
changelog: |
  1.0.0.0
  -------
  * initial release

  1.1.0.0
  -------
  * upgrade version bounds of the 'containers' dependency
  * fixed LaTeX code in README
basic-deps:
  base: '>=4.7 && <5'
  cyclotomic: '>=1.1.1 && <1.2'
  array: '>=0.5.4.0 && <0.6'
  containers: '>=0.6.5.1 && <0.7'
all-versions:
- 1.0.0.0
- 1.1.0.0
author: StÃ©phane Laurent
latest: 1.1.0.0
description-type: markdown
description: "# hypergeomatrix\n\n## Evaluation of the hypergeometric function of
  a matrix argument (Koev & Edelman's algorithm)\n\nLet $(a_1, \\ldots, a_p)$ and
  $(b_1, \\ldots, b_q)$ be two vectors of real or \ncomplex numbers, possibly empty,
  $\\alpha > 0$ and $X$ a real symmetric or a \ncomplex Hermitian matrix. \nThe corresponding
  *hypergeometric function of a matrix argument* is defined by \n\n$${}_pF_q^{(\\alpha)}
  \\left(\\begin{matrix} a_1, \\ldots, a_p \\\\\\\\ b_1, \\ldots, b_q\\end{matrix};
  X\\right) = \\sum_{k=0}^{\\infty}\\sum_{\\kappa \\vdash k} \\frac{{(a_1)}_{\\kappa}^{(\\alpha)}
  \\cdots {(a_p)}_{\\kappa}^{(\\alpha)}} {{(b_1)}_{\\kappa}^{(\\alpha)} \\cdots {(b_q)}_{\\kappa}^{(\\alpha)}}
  \\frac{C_{\\kappa}^{(\\alpha)}(X)}{k!}.$$\n\nThe inner sum is over the integer partitions
  $\\kappa$ of $k$ (which we also \ndenote by $|\\kappa| = k$). The symbol ${(\\cdot)}_{\\kappa}^{(\\alpha)}$
  is the \n*generalized Pochhammer symbol*, defined by\n\n$${(c)}^{(\\alpha)}_{\\kappa}
  = \\prod_{i=1}^{\\ell}\\prod_{j=1}^{\\kappa_i} \\left(c - \\frac{i-1}{\\alpha} +
  j-1\\right)$$\n\nwhen $\\kappa = (\\kappa_1, \\ldots, \\kappa_\\ell)$. \nFinally,
  $C_{\\kappa}^{(\\alpha)}$ is a *Jack function*. \nGiven an integer partition $\\kappa$
  and $\\alpha > 0$, and a \nreal symmetric or complex Hermitian matrix $X$ of order
  $n$, \nthe Jack function \n\n$$C_{\\kappa}^{(\\alpha)}(X) = C_{\\kappa}^{(\\alpha)}(x_1,
  \\ldots, x_n)$$\n\nis a symmetric homogeneous polynomial of degree $|\\kappa|$ in
  the \neigen values $x_1$, $\\ldots$, $x_n$ of $X$. \n\nThe series defining the hypergeometric
  function does not always converge. \nSee the references for a discussion about the
  convergence. \n\nThe inner sum in the definition of the hypergeometric function
  is over \nall partitions $\\kappa \\vdash k$ but actually \n$C_{\\kappa}^{(\\alpha)}(X)
  = 0$ when $\\ell(\\kappa)$, the number of non-zero \nentries of $\\kappa$, is strictly
  greater than $n$.\n\nFor $\\alpha=1$, $C_{\\kappa}^{(\\alpha)}$ is a *Schur polynomial*
  and it is \na *zonal polynomial* for $\\alpha = 2$. \nIn random matrix theory, the
  hypergeometric function appears for $\\alpha=2$ \nand $\\alpha$ is omitted from
  the notation, implicitely assumed to be $2$. \n\nKoev and Edelman (2006) provided
  an efficient algorithm for the evaluation \nof the truncated series \n\n$$\\sideset{_p^m}{_q^{(\\alpha)}}F
  \\left(\\begin{matrix} a_1, \\ldots, a_p \\\\\\\\ b_1, \\ldots, b_q\\end{matrix};
  X\\right) = \\sum_{k=0}^{m}\\sum_{\\kappa \\vdash k} \\frac{{(a_1)}_{\\kappa}^{(\\alpha)}
  \\cdots {(a_p)}_{\\kappa}^{(\\alpha)}} {{(b_1)}_{\\kappa}^{(\\alpha)} \\cdots {(b_q)}_{\\kappa}^{(\\alpha)}}
  \n\\frac{C_{\\kappa}^{(\\alpha)}(X)}{k!}.$$\n\nHereafter, $m$ is called the *truncation
  weight of the summation* \n(because $|\\kappa|$ is called the weight of $\\kappa$),
  the vector \n$(a_1, \\ldots, a_p)$ is called the vector of *upper parameters* while
  \nthe vector $(b_1, \\ldots, b_q)$ is called the vector of *lower parameters*. \nThe
  user has to supply the vector $(x_1, \\ldots, x_n)$ of the eigenvalues \nof $X$.
  \n\nFor example, to compute\n\n$$\\sideset{_2^{15}}{_3^{(2)}}F \\left(\\begin{matrix}
  3, 4 \\\\\\\\ 5, 6, 7\\end{matrix}; 0.1, 0.4\\right)$$\n\nyou have to enter \n\n```haskell\nhypergeomat
  15 2 [3.0, 4.0], [5.0, 6.0, 7.0] [0.1, 0.4]\n```\n\nWe said that the hypergeometric
  function is defined for a real symmetric \nmatrix or a complex Hermitian matrix
  $X$. Thus the eigenvalues of $X$ \nare real. However we do not impose this restriction
  in `hypergeomatrix`. \nThe user can enter any list of real or complex numbers for
  the eigenvalues. \n\n### Gaussian rational numbers\n\nThe library allows to use
  **Gaussian rational numbers**, i.e. complex numbers \nwith a rational real part
  and a rational imaginary part. The Gaussian rational \nnumber $a + ib$ is obtained
  with `a +: b`, e.g. `(2%3) +: (5%2)`. The imaginary \nunit usually denoted by $i$
  is represented by `e(4)`:\n\n```haskell\nghci> import Math.HypergeoMatrix\nghci>
  import Data.Ratio\nghci> alpha = 2%1\nghci> a = (2%7) +: (1%2)\nghci> b = (1%2)
  +: (0%1)\nghci> c = (2%1) +: (3%1)\nghci> x1 = (1%3) +: (1%4)\nghci> x2 = (1%5)
  +: (1%6)\nghci> hypergeomat 3 alpha [a, b] [c] [x1, x2]\n26266543409/25159680000
  + 155806638989/3698472960000*e(4)\n```\n\n### Univariate case\n\nFor $n = 1$, the
  hypergeometric function of a matrix argument is known as the \n[generalized hypergeometric
  function](https://mathworld.wolfram.com/HypergeometricFunction.html). \nIt does
  not depend on $\\alpha$. The case of $\\sideset{_{2\\thinspace}^{}}{_1^{}}F$ is
  the most known, \nthis is the Gauss hypergeometric function. Let's check a value.
  It is known that\n\n$$\\sideset{_{2\\thinspace}^{}}{_1^{}}F \\left(\\begin{matrix}
  1/4, 1/2 \\\\\\\\ 3/4\\end{matrix}; 80/81\\right) = 1.8.$$\n\nSince $80/81$ is close
  to $1$, the convergence is slow. We compute the truncated series below \nfor $m
  = 300$.\n\n```haskell\nghci> h <- hypergeomat 300 2 [1/4, 1/2] [3/4] [80/81]\nghci>
  h\n1.7990026528192298\n```\n\n\n## References\n\n- Plamen Koev and Alan Edelman.
  \n*The efficient evaluation of the hypergeometric function of a matrix argument*.\nMathematics
  of computation, vol. 75, n. 254, 833-846, 2006.\n\n- Robb Muirhead. \n*Aspects of
  multivariate statistical theory*. \nWiley series in probability and mathematical
  statistics. \nProbability and mathematical statistics. \nJohn Wiley & Sons, New
  York, 1982.\n\n- A. K. Gupta and D. K. Nagar. \n*Matrix variate distributions*.
  \nChapman and Hall, 1999.\n"
license-name: BSD-3-Clause
