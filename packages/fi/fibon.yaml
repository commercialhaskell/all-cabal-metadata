all-versions:
- 0.1.0
- 0.2.0
author: David M Peixotto
basic-deps:
  Cabal: '>=1.8 && <1.9'
  attoparsec: '>=0.8 && <0.9'
  base: '>=4 && <5'
  bytestring: '>=0.9 && <0.10'
  bytestring-lexing: '>=0.2 && <0.3'
  cereal: '>=0.3 && <0.4'
  containers: '>=0'
  directory: '>=1.0 && <1.1'
  filepath: '>=1.1 && <1.2'
  hslogger: '>=1.0 && <1.1'
  mtl: '>=1.1 && <1.2'
  old-locale: '>=1.0 && <1.1'
  old-time: '>=1.0 && <1.1'
  process: '>=1.0 && <1.1'
  regex-compat: '>=0.93 && <0.94'
  statistics: '>=0.6 && <0.7'
  syb: '>=0.1 && <0.2'
  tabular: '>=0.2 && <0.3'
  time: '>=1.1 && <1.2'
  vector: '>=0.6 && <0.7'
changelog: ''
changelog-type: ''
description: "Fibon in a Flash\n===================================================================\n
  \   $ git clone git://github.com/dmpots/fibon.git\n    $ cd fibon\n    $ git submodule
  update --init benchmarks\n    $ cabal configure && cabal build\n    $ ./dist/build/fibon-run/fibon-run\n\nIntroduction\n===================================================================\nFibon
  is a set of tools for running and analyzing benchmark programs in\nHaskell. Most
  importantly, it includes an optional set of new [benchmarks][2]\nincluding many
  programs taken from the [Hackage][1] open source repository.\n\nFibon is a pure
  Haskell framework for running and analyzing benchmarks. Cabal\nis used for building
  the benchmarks, and the benchmark harness, configuration\nfiles, and benchmark descriptions
  are all written in Haskell. The benchmark\ndescriptions and run configurations are
  all statically compiled into the\nbenchmark runner to ensure that configuration
  errors are found at compile\ntime.\n\nThe Fibon tools are not tied to any compiler
  infrastructure and can build\nbenchmarks using any compiler supported by cabal.
  However, there are some\nextra features available when using GHC to build the benchmarks:\n\n
  \ * Support in config files for inplace GHC HEAD builds\n  * Support in `fibon-run`
  for collecting GC stats from GHC compiled programs\n  * Support in `fibon-analyse`
  for reading GC stats from Fibon result files\n\nBenchmarks\n------------------\nFibon
  makes it easy to use either the Fibon benchmarks or your own\nset of benchmarks.
  Benchmarks are stored in the\n`benchmarks/Fibon/Benchmarks` directory. This directory
  is setup as\na [git submodule][3] which means you can easily grab the standard\nsuite
  or use a suite kept under your own source control.\n\nThe default suite of benchmarks
  is stored in the\n[fibon-benchmarks][2] repository on github.\n\nBenchmark Groups\n------------------\nBenchmarks
  are named and organized into groups based on the filesystem\norganization. For example,
  a benchmark in the directory\n`benchmarks/Fibon/Benchmarks/Hackage/Agum` will have
  the name `Agum`\nan be in the benchmark group `Hackage`.\n\nExecutables\n------------------\nThe
  fibon package builds three tools:\n\n1. `fibon-run` - runs the benchmarks\n2. `fibon-analyze`
  - analyzes the results of a run\n3. `fibon-init` - utility used when adding new
  benchmarks\n\nSize and Tune\n------------------\nFibon benchmarks can be run with
  two different input sizes: `Test` and `Ref`.\nThe `Test` size is useful to make
  sure that a benchmark can run successfully,\nbut will not give meaningful timings.
  The `Ref` size should be used when\nreporting results.\n\nFibon benchmarks can be
  run under two different tune settings (e.g.\ncompiler optimization settings). The
  `Base` and `Peak` settings can\nbe configured anyway you want to make the desired
  comparison.\n\nDirectory Structure\n--------------------\nSource directories\n\n
  \   ./benchmarks -- benchmark code\n    ./config     -- config files\n    ./lib
  \       -- common files used by several executables\n    ./tools      -- source
  code for executables\n\nWorking directories\n\n    ./log        -- logging output
  from benchmark runs\n    ./run        -- working directory for benchmark runs\n\nGetting
  the Benchmarks\n===================================================================\nThe
  benchmarks are kept in a separate repository as a git\nsubmodule. You can get the
  Fibon benchmarks by updating the\nsubmodule from within your Fibon working directory\n\n
  \   $ git submodule update --init benchmarks\n\nThis will checkout the benchmarks
  from the [fibon-benchmarks][2]\nrepository and place them in your working copy.\n\nRunning
  Benchmarks\n===================================================================\nThe
  available benchmarks and configurations are discovered when the\nFibon package is
  configured. Benchmarks are searched for in the\n`benchmarks/Fibon/Benchmarks` directory
  and configuration files are\nsearched for in the `config` directory. If a configuration
  file or\nbenchmark is added, you will need to re-run `cabal configure` to\nmake
  them available to the fibon-run tool.\n\nConfiguration\n---------------\nFibon comes
  with a default configuration. The default configuration\nwill run all benchmarks
  with the `Base` setting of `-O0` and a\n`Peak` setting of `-O2` on the `Ref` size.
  A configuration file can\nbe used to specify more complicated configurations.\n\nYou
  can get some example configuration by doing\n    $ git submodule update --init config\n\nThis
  will checkout a repository of config files. Note that currently\nthese files contain
  some user and machine-specific configurations,\nbut should be a useful starting
  point.\n\nYou can also command line options to selectively run benchmarks,\ngroups,
  sizes, and tune settings as described below.\n\nRunning\n---------------\nBenchmarks
  are run with the `fibon-run` tool. Running `fibon-run`\nwith no arguments will use
  the default config file. An alternate\nconfig file can be specified with the `-c`
  flag. Also, you can give\na list of benchmarks or groups to run on the command line.
  Use\n`--help` to see a full list of options.\n\nRunning the benchmarks will produce
  some logging to standard out and\ncreate four output files in the `log` directory.\n\n1.
  `*.LOG` - the full log of the run\n2. `*.SUMMARY` - the mean runtimes of each benchmark\n3.
  `*.RESULTS`  - the full results in binary format (pass to `fibon-analyse`)\n4. `*.RESULTS.SHOW`
  - the full results in text format (pass to `fibon-analyse`)\n\nAnalyzing Benchmark
  Results\n===================================================================\nBenchmarks
  can be analyzed by the `fibon-analyse` tool.\n\n    $ fibon-analyse log/000.default.RESULTS\nor\n\n
  \   $ fibon-analyse log/000.default.RESULTS.SHOW\n\nThe binary results (`.RESULT`)
  file is much faster to parse. It\ncontains a serialization of a list of `FibonResult`
  structures. The\n`.SHOW` file contains a `FibonResult` on each line which can be\nparsed
  by using the `read` function.\n\nAdding New Benchmarks\n===================================================================\n\nNew
  benchmarks are added by putting the appropriate files in the\n`benchmarks/Fibon/Benchmarks`
  directory. Each folder in this directory\nrepresents a benchmark group. The benchmarks
  and groups are found at\nconfiguration time (i.e. when running `cabal configure`
  for the fibon\npackage). You can exclude a benchmark or a group by prefixing the
  name with\nand underscore (`_`).\n\nTo add a new benchmark create a new folder in
  a benchmark group. If the\nbenchmark program has been cabalized, you can typically
  just do a\n`cabal unpack` of the benchmark. The benchmark folder must contain:\n\n
  \ 1. A cabal file describing how to build the benchmark\n  2. A benchmark description
  for Fibon stored in `Fibon/Instance.hs`\n\nThe `fibon-init` tool will read a cabal
  file from the current directory and generate the Fibon subfolder and a stub `Instance.hs`
  file.\n\nThe `Fibon` subfolder of a benchmark contains all of the data that Fibon
  needs\nto build and execute the benchmark. The benchmark instance file describes
  any\nrequried build flags, inputs, and outputs for the benchmark. It is a standard\nHaskell
  module that must export the `mkInstance` function. The `mkInstance`\nfunction takes
  a benchmark size and returns a `BenchmarkInstance` structure.\nAn example instance
  file is show below.\n\n    module Fibon.Benchmarks.Hackage.Bzlib.Fibon.Instance(\n
  \     mkInstance\n    )\n    where\n    import Fibon.BenchmarkInstance\n\n    sharedConfig
  = BenchmarkInstance {\n        flagConfig = FlagConfig {\n            configureFlags
  = []\n          , buildFlags     = []\n          , runFlags       = []\n          }\n
  \       , stdinInput     = Nothing\n        , output         = []\n        , exeName
  \       = \"hsbzip\"\n      }\n    flgCfg = flagConfig sharedConfig\n\n    mkInstance
  Test = sharedConfig {\n          flagConfig = flgCfg {\n              runFlags =
  [\"bzlib.cabal.bz2\"]\n          }\n          , output    = [(OutputFile \"bzlib.cabal.bz2.roundtrip\",\n
  \                         Diff       \"bzlib.cabal.bz2\")]\n        }\n    mkInstance
  Ref  = sharedConfig {\n          flagConfig = flgCfg {\n              runFlags =
  [\"mito.aa.bz2\"]\n          }\n          , output   = [(OutputFile \"mito.aa.bz2.roundtrip\",\n
  \                        Diff       \"mito.aa.bz2\")]\n        }\n\nThe input and
  expected output data should also be stored in the `Fibon`\nsubdirectory of the benchmark.
  When the benchmark is run, the contents of the\ninput and output directories for
  the benchmark size will be copied to the\nworking directory where the benchmark
  is run. There can also be an `all`\ndirectory which whose data will be copied for
  all input sizes. None of the\ndata directories are required, but if they exist they
  must be organized like\nthis:\n\n        data/all/input\n        data/all/output\n
  \       data/ref/input\n        data/ref/output\n        data/test/input\n        data/test/output\n\nBenchmark
  Notes\n===================================================================\nGhc612\n
  \ The Repa and Dph groups will not work properly.\n\nGhc610\n  The Repa and Dph
  groups will not work properly.\n  \n  ChameneosRedux\n    Does not work with -O0.
  Gets \"thread blocked indefinitely\"\n    exception\n\n  Mandelbrot\n    The Test
  size gives different result, but the Ref size is ok.\n    Think it is just some
  kind of floating point wibbles.\n\n[1]: http://hackage.haskell.org\n[2]: http://github.com/dmpots/fibon-benchmarks\n[3]:
  http://www.kernel.org/pub/software/scm/git/docs/user-manual.html#submodules\n"
description-type: markdown
hash: 59d1fb1ecf26dfca994e717e9dae78206fa2faaca19a3ff20a7ff6811dc8a7fe
homepage: http://github.com/dmpots/fibon/wiki
latest: 0.2.0
license-name: BSD-3-Clause
maintainer: dmp@rice.edu
synopsis: 'Tools for running and analyzing Haskell benchmarks '
test-bench-deps: {}
