all-versions:
- 0.0.1.0
- 0.0.1.1
- 0.0.2.0
- 0.0.3.0
- 0.0.4.0
- 0.0.5.0
- 0.0.6.0
- 0.0.7.0
- 0.0.8.0
- 0.0.9.0
- 0.1.0.0
- 0.1.1.0
- 0.1.2.0
- 0.1.3.0
- 0.1.4.0
- 0.1.5.0
author: phoityne.hs@gmail.com
basic-deps:
  base: '>=4.18 && <5'
  optparse-applicative: '>=0'
  pms-application-service: '>=0'
  pms-domain-model: '>=0'
  pms-domain-service: '>=0'
  pms-infra-cmdrun: '>=0'
  pms-infra-filesystem: '>=0'
  pms-infra-procspawn: '>=0'
  pms-infra-serial: '>=0'
  pms-infra-socket: '>=0'
  pms-infra-watch: '>=0'
  pms-infrastructure: '>=0'
  pms-ui-notification: '>=0'
  pms-ui-request: '>=0'
  pms-ui-response: '>=0'
  safe-exceptions: '>=0'
changelog: |
  # Revision history for pty-mcp-server

  ## 0.1.5.0 -- 2025-12-31

  * Add file system tools.

  ## 0.1.4.0 -- 2025-09-23

  * Support base64 image tool response.

  ## 0.1.3.0 -- 2025-09-15

  * Fixed validateMessage.

  ## 0.1.2.0 -- 2025-09-07

  * Support invalidChars configs.

  ## 0.1.1.0 -- 2025-08-24

  * Fixed exception handle.

  ## 0.1.0.0 -- 2025-08-17

  * Fixed proc-message.

  ## 0.0.9.0 -- 2025-08-11

  * Fixed encoding.

  ## 0.0.8.0 -- 2025-08-11

  * Fixed encoding.

  ## 0.0.8.0 -- 2025-07-27

  * Fixed resources templates.

  ## 0.0.7.0 -- 2025-07-20

  * Added proc tool.

  ## 0.0.6.0 -- 2025-07-13

  * Added serial tool.

  ## 0.0.5.0 -- 2025-07-06

  * Added resources interface.

  ## 0.0.4.0 -- 2025-06-29

  * Added prompts interface.

  ## 0.0.3.0 -- 2025-06-22

  * Added file change monitoring for tools-list.json.

  ## 0.0.2.0 -- 2025-06-15

  * Updated the README.

  ## 0.0.1.0 -- 2025-05-31

  * First version.
changelog-type: markdown
description: "# pty-mcp-server\n\n----\n## ⚠️ Caution\n\n**Do not grant unrestricted
  control to AI.**  \nUnsupervised use or misuse may lead to unintended consequences.
  \ \nAll AI systems must remain strictly under human oversight and control.  \nUse
  responsibly, with full awareness and at your own risk.  \n\n----\n## \U0001F4D8
  Overview\n\n**`pty-mcp-server`** is a Haskell implementation of an **MCP (Model
  Context Protocol) server** that enables AI agents to dynamically acquire and control
  **PTY (pseudo-terminal) sessions**, allowing interaction with real system environments
  through terminal-based interfaces.\n\nThe server communicates exclusively via **standard
  input/output (stdio)**, ensuring simple and secure integration with MCP clients.
  Through this interface, AI agents can execute commands, retrieve system states,
  and apply configurations—just as a human operator would through a terminal.\n\n---\n\n###
  \U0001F3AF Purpose\n\n- Provide AI agents with **TTY-based control capabilities**
  \ \n- Enable **automated configuration, inspection, and operation** using CLI tools
  \ \n- Facilitate **AI-driven workflows for system development, diagnostics, and
  remote interaction**  \n- Allow AI agents to access and operate on **systems beyond
  the reach of static scripts or APIs**  \n- Support **Infrastructure as Code (IaC)**
  scenarios requiring **interactive or stateful terminal workflows**  \n- Assist in
  **system integration** across heterogeneous environments and legacy systems  \n-
  Empower **AI agents to support DevOps, IaC, and integration pipelines** by operating
  tools that require human-like terminal interaction  \n\n---\n\n### \U0001F527 Example
  Use Cases\n\n- **Dynamic execution of CLI tools** that require a PTY environment
  \ \n  (e.g., embedded systems over serial or SSH-based terminals)  \n- **REPL automation**:
  driving GHCi or other CLI-based interactive interpreters  \n- **Interactive debugging**
  of Haskell applications or shell-based workflows  \n- **System diagnostics** through
  scripted or interactive bash sessions  \n- **Remote server management** using SSH
  \ \n- **Hands-on system operation** where CLI behavior cannot be emulated via non-interactive
  scripting  \n- **Network device interaction**: configuring routers, switches, or
  appliances via console  \n- **AI-assisted IaC workflows**: executing Terraform,
  Ansible, or shell-based deploy scripts that involve prompts, state reconciliation,
  or real-time input  \n- **AI-driven system integration testing** across multiple
  environments and CLI tools  \n- **Legacy system automation** where GUI/API is unavailable
  and only terminal interaction is supported  \n\n\n---\n\n## User Guide (Usage and
  Setup)\n\n### Features\n\n`pty-mcp-server` provides the following built-in tools
  for powerful and flexible automation:\n\n#### Available Tools\n- **`pty-connect`**
  \ \n  Runs a command via a pseudo-terminal (pty) to interact with external tools
  or services, with optional arguments.\n\n- **`pty-terminate`**  \n  Forcefully terminates
  an active pseudo-terminal (PTY) connection.\n\n- **`pty-message`**  \n  pms-messages
  is a tool for sending structured instructions or commands to a running PTY session.
  It abstracts direct terminal input, allowing the LLM (MCP client) to interact with
  the PTY process in a controlled and programmable way.\n\n- **`pty-bash`**  \n  pty-bash
  is a tool that launches a bash shell in a pseudo terminal (PTY). It allows the LLM
  (MCP client) to interact with a real Linux shell in an interactive terminal (PTY).
  This enables AI to run system commands, collect information, and handle prompts
  or TUI-based tools as if operated by a human, making it effective for dynamic Linux-based
  automation and diagnostics.\n\n- **`pty-ssh`**  \n  Establishes an SSH session in
  a pseudo-terminal with the specified arguments, allowing interaction with remote
  systems.\n\n- **`pty-telnet`**  \n  Launches the telnet command within a pseudo-terminal
  (PTY) session. This allows interactive communication with a remote Telnet server,
  enabling the AI to respond to prompts such as 'login:' or 'Password:' just like
  a human user. The PTY environment ensures that the terminal behaves like a real
  TTY device, which is required for many Telnet servers.\n\n- **`pty-cabal`**  \n
  \ Launches a cabal repl session within a specified project directory, loading a
  target Haskell file.  \n  Supports argument passing and live code interaction.\n\n-
  **`pty-stack`**  \n  Launches a stack repl session in a pseudo-terminal using the
  specified project directory, main source file, and arguments.\n\n- **`pty-ghci`**
  \ \n  Launches a GHCi session in a pseudo-terminal using the specified project directory,
  main source file, and arguments.\n\n- **`proc-spawn`**  \n  Spawns an external process
  using the specified arguments and enables interactive communication via standard
  input and output. Unlike PTY-based execution, this communicates directly with the
  process using the runProcess function without allocating a pseudo-terminal. Suitable
  for non-TUI, stdin/stdout-based interactive programs.\n\n- **`proc-terminate`**
  \ \n  Forcefully terminates a running process created via runProcess.\n\n- **`proc-message`**
  \ \n  Sends structured text-based instructions or commands to a subprocess started
  with runProcess. It provides a programmable interface for interacting with the process
  via standard input.\n\n- **`proc-cmd`**  \n  The `proc-cmd` tool launches the Windows
  Command Prompt (`cmd.exe`) as a subprocess. It allows the AI to interact with the
  standard Windows shell environment, enabling execution of batch commands, file operations,
  and system configuration tasks in a familiar terminal interface.\n\n- **`proc-ps`**
  \ \n  `proc-ps` launches the Windows PowerShell (`powershell.exe`) as a subprocess.
  It provides an interactive command-line environment where the AI can execute PowerShell
  commands, scripts, and system administration tasks. The shell is started with default
  options to keep it open and ready for further input.\n\n- **`proc-ssh`**  \n  `proc-ssh`
  launches an SSH client (`ssh`) as a subprocess using `runProcess`. It enables the
  AI to initiate remote connections to other systems via the Secure Shell protocol.
  The tool can be used to execute remote commands, access remote shells, or tunnel
  services over SSH. The required `arguments` field allows specifying the target user,
  host, and any SSH options (e.g., `-p`, `-i`, `-L`).\n\n- **`proc-telnet`**  \n  A
  tool that runs Telnet sessions by internally using PuTTY's plink executable. This
  enables interactive Telnet connections on Windows without requiring an external
  pseudo-terminal emulator like winpty. Users supply the Telnet command arguments,
  which are passed directly to plink to establish the session. (Note: plink.exe must
  be available in the system PATH.)\n\n- **`proc-plink`**  \n  A Windows tool that
  launches an interactive console application via plink, a command-line SSH and Telnet
  client. Suitable for executing SSH or Telnet sessions directly without needing an
  external PTY emulator. (Note: plink.exe must be available in the system PATH.)\n\n-
  **`socket-open`**  \n  This tool initiates a socket connection to the specified
  host and port.\n\n- **`socket-close`**  \n  This tool close active socket connection
  that was previously established using the 'socket-opne' tool.\n\n- **`socket-read`**
  \ \n  Reads the specified number of bytes from the socket. The 'size' parameter
  indicates how many bytes to read.\n\n- **`socket-write`**  \n  Write a sequence
  of bytes to the socket\n\n- **`socket-message`**  \n  This tool sends a specified
  string to the active socket connection, then waits for a recognizable prompt from
  the remote side. Upon detecting the prompt, it captures and returns all output received
  prior to it.\n\n- **`socket-telnet`**  \n  A simple Telnet-like communication tool
  over raw TCP sockets. This tool connects to a specified host and port, sends and
  receives data, and removes any Telnet IAC (Interpret As Command) sequences from
  the communication stream. Note: This is a simplified Telnet implementation and does
  not support full Telnet protocol features.\n\n\n- **`serial-open`**  \n  Opens a
  serial port connection to a specified device with a given baud rate. Commonly used
  to access on-premises hardware or network devices via console.\n\n- **`serial-close`**
  \ \n  This tool close active serial connection that was previously established using
  the 'serial-open' tool.\n\n- **`serial-read`**  \n  Reads the specified number of
  bytes from the serial. The 'size' parameter indicates how many bytes to read.\n\n-
  **`serial-write`**  \n  Write a sequence of bytes to the serial.\n\n- **`serial-message`**
  \ \n  This tool sends a specified string to the active socket connection, then waits
  for a recognizable prompt from the remote side. Upon detecting the prompt, it captures
  and returns all output received prior to it.\n\n- **`pms-list-dir`**  \n  List the
  contents of a directory at the specified path.\n\n- **`pms-read-file`**  \n  Read
  the contents of a file at the specified path.\n\n- **`pms-write-file`**  \n  Write
  contents to a file at the specified path.\n\n- **`Scriptable CLI Integration`**
  \ \n  The `pty-mcp-server` supports execution of shell scripts associated with registered
  tools defined in `tools-list.json`. Each tool must be registered by name, and a
  corresponding shell script (`.sh`) should exist in the configured `tools/` directory.\n\n
  \ This design supports AI-driven workflows by exposing tool interfaces through a
  predictable scripting mechanism. The AI can issue tool invocations by name, and
  the server transparently manages execution and interaction.  \n  To add a new tool:\n
  \   1. Create a shell script named `your-tool.sh` in the `tools/` directory.\n    2.
  Add an entry in `tools-list.json` with the name `\"your-tool\"` and appropriate
  metadata.\n    3. No need to recompile or modify the server — tools are dynamically
  resolved by name.\n\n  This separation of tool definitions (`tools-list.json`) and
  implementation (`tools/your-tool.sh`) ensures clean decoupling and simplifies extensibility.\n\n>
  **Note:**  \n> Commands starting with `pty-` are not supported on Windows. These
  tools rely on POSIX-style pseudo terminals (PTY), which are not natively available
  in the Windows environment.\n\n### Running with Podman or Docker\n\nYou can build
  and run `pty-mcp-server` using either **Podman** or **Docker**.\n\n**Note:** When
  running pty-mcp-server inside a Docker container, after establishing a pty connection,
  you will be operating within the container environment. This should be taken into
  account when interacting with the server.\n\n#### 1. Build the image\n\nClone the
  repository and navigate to the `docker` directory:\n\n```bash\n$ git clone https://github.com/phoityne/pty-mcp-server.git\n$
  cd pty-mcp-server/docker\n$ podman build . -t pty-mcp-server-image\n$\n```\nRef
  : [build.sh](https://github.com/phoityne/pty-mcp-server/blob/main/docker/build.sh)\n\n####
  2. Run the container\nRun the server inside a container:\n\n```bash\n$ podman run
  --rm -i \\\n--name pty-mcp-server-container \\\n-v /path/to/dir:/path/to/dir \\\n--hostname
  pms-docker-container \\\npty-mcp-server-image \\\n-y /path/to/dir/config.yaml\n$\n```\nRef
  : [run.sh](https://github.com/phoityne/pty-mcp-server/blob/main/docker/run.sh)\n\nBelow
  is an example of how to configure `mcp.json` to run the MCP server within VSCode:\n```json\n{\n
  \ \"servers\": {\n    \"pty-mcp-server\": {\n      \"type\": \"stdio\",\n      \"command\":
  \"/path/to/run.sh\",\n      \"args\": []\n      /*\n      \"command\": \"podman\",\n
  \     \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"--name\", \"pty-mcp-server-container\",\n
  \       \"-v\", \"/path/to/dir:/path/to/dir\",\n        \"--hostname\", \"pms-docker-container\",\n
  \       \"pty-mcp-server-image\",\n        \"-y\", \"/path/to/dir/config.yaml\"\n
  \     ]\n      */\n    }\n  }\n}\n```\n\n### Binary Installation\n\nIf you prefer
  to build it yourself, make sure the following requirements are met: \n- GHC >= 9.6\n\nYou
  can install `pty-mcp-server` using `cabal`:\n\n```bash\n$ cabal install pty-mcp-server\n```\n\n###
  Installation via `.dxt` Package\n\nYou can also set up the tool using a pre-packaged
  `.dxt` file.  \nThis method is suitable for quick installation into Claude Code
  or for manual setup via extraction.\n\n> \U0001F6E0️ The `.dxt` package distribution
  is currently **in preparation**,  \n> but you can check the latest status and download
  links at:  \n> [https://github.com/phoityne/pms-dxt](https://github.com/phoityne/pms-dxt)\n\n\n###
  Binary Execution\n\nThe `pty-mcp-server` application is executed from the command
  line.\n\n#### Usage\n\n```sh\n$ pty-mcp-server -y config.yaml\n```\nWhile the server
  can be launched directly from the command line, it is typically started and managed
  by development tools that integrate an MCP client—such as Visual Studio Code. These
  tools utilize the server to enable interactive and automated command execution via
  PTY sessions.\n\n#### VSCode Integration: `.vscode/mcp.json`\n\nTo streamline development
  and server invocation from within Visual Studio Code, the project supports a `.vscode/mcp.json`
  configuration file.\n\nThis file defines how the `pty-mcp-server` should be launched
  in a development environment. Example configuration:\n\n```json\n{\n  \"servers\":
  {\n    \"pty-mcp-server\": {\n      \"type\": \"stdio\",\n      \"command\": \"pty-mcp-server\",\n
  \     \"args\": [\"-y\", \"/path/to/your/config.yaml\"]\n    }\n  }\n}\n```\n\n###
  config.yaml Configuration ([ref](https://github.com/phoityne/pms-missions/blob/main/0001_default-assets/pty-mcp-server.yaml))\n-
  `logDir`:  \n  The directory path where log files will be saved. This includes standard
  output/error logs and logs from script executions.\n\n- `logLevel`:  \n  Sets the
  logging level. Examples include `\"Debug\"`, `\"Info\"`, and `\"Error\"`.\n\n- `toolsDir`:
  \ \n  Directory containing script files (shell scripts named after tool names, e.g.,
  `ping.sh`). If a script matching the tool name exists here, it will be executed
  when the tool is called.  \n  This directory must also contain the `tools-list.json`
  file, which defines the available public tools and their metadata.\n\n- `prompts`:
  \ \n  A list of prompt strings used to detect interactive command prompts. This
  allows the AI to identify when a command is awaiting input. Examples include `\"ghci>\"`,
  `\"]$\"`, `\"password:\"`, etc.\n\n  \n---\n\n## Demonstrations\n\n### AI handles
  Binary Protocol Dialogues via pty-mcp-server\n![Demo socket telnet](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_socket_telnet.gif)
  \ \nRef : [socket-telnet-prompt](https://github.com/phoityne/pms-missions/blob/main/0004_socket_binary_com/pty-mcp-server/prompts/socket-telnet-prompt.md)\n\nThis
  video demonstrates a Telnet login sequence powered by the MCP prompt defined in
  [socket-telnet-prompt.md](https://github.com/phoityne/pms-missions/blob/main/0004_socket_binary_com/pty-mcp-server/prompts/socket-telnet-prompt.md).
  Using tools like `socket-open`, `socket-read`, `socket-write`, and `socket-message`,
  the AI performs Telnet negotiation, handles prompts, and submits credentials. Binary
  responses are parsed and displayed in human-readable form.\n\n### Network Device
  Version Check via Serial Connection — powered by pty-mcp-server.\n![Demo serial](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_serial.gif)
  \ \nRef : [serial-nw-setting-prompt](https://github.com/phoityne/pms-missions/blob/main/0005_serial_nw_setting/pty-mcp-server/prompts/serial-nw-setting-prompt.md)\n\nThis
  video demonstrates how `pty-mcp-server` enables AI-assisted automation over a serial
  connection to a network device.\n\n1. Device Setup\nThe user specifies the communication
  port and baud rate.  \n**Example:** `COM3`, 9600 baud on Windows.\n\n2. Login Interaction\nThe
  AI prompts for a username and password,  \nand uses them to log in to the network
  device.\n\n3. Device Version Retrieval\nAfter logging in, the AI sends a command
  \ \nto retrieve the installed OS or firmware version.\n\n4. Online Version Check\nThe
  AI accesses the official website to check the latest available version,  \nand compares
  it with the installed version.\n\n5. Session Termination\nOnce the check is complete,
  the AI logs out and cleanly closes the serial connection.\n\n\n### Demo: Watch AI
  Create and Launch a Web App from Scratch\n![Demo web service construct](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_web.gif)
  \ \nRef : [Web Service Construction Agent Prompt](https://github.com/phoityne/pms-missions/blob/main/0006_web_service_construction/pty-mcp-server/prompts/web-service-prompt.md)\n\n\n1.
  [Scene 1: Overview & MCP Configuration]  \nIn this demo, we’ll show how an AI agent
  builds and runs a web service inside a Docker container using the `pty-mcp-server`.
  \ \nFirst, we configure `mcp.json` to launch the MCP server using a shell script.
  \ \nThis script starts the Docker container where our PTY-based interaction will
  take place.\n2. [Scene 2: Docker Launch Configuration]  \nThe `run.sh` script includes
  volume mounts, hostname settings, and opens **port 8080**.  \nThis allows the container
  to expose a web service to the host system.\n\n3. [Scene 3: Starting the MCP Server]
  \ \nNow, the container is launched, and the `pty-mcp-server` is running inside it,
  \ \nready to handle AI-driven requests through a pseudo-terminal.\n\n4. [Scene 4:
  Connecting the AI Agent]  \nWe open the chat interface and send a prompt designed
  for a web service builder agent.  \nThe AI connects to the container’s Bash session
  via PTY and begins its preparation.\n\n5. [Scene 5: Initial Setup Commands]  \nFollowing
  the prompt, the AI starts by:  \n    - Creating a project folder  \n    - Moving
  into the working directory\n\n6. [Scene 6: AI Ready to Receive Instructions]  \nOnce
  the environment is ready, we instruct the AI to build a “Hello, world” web service.
  \ \nFrom here, the AI begins its autonomous construction process.\n\n7. [Scene 7:
  AI Executes Web Setup Commands]  \nThe AI proposes a series of terminal commands.
  \ \nAs the user, we review and approve them one by one.  \nSteps include:\n    -
  Checking for Python\n    - Installing Flask\n    - Writing the source code (`app.py`)
  to serve “Hello, world”\n    - Running the Flask server\n    - Testing via `curl
  http://localhost:8080` inside the container\n\n8. [Scene 8: Verifying from Outside
  the Container]  \nTo confirm external accessibility, we access the service from
  the host via **port 8080**.  As expected, the response is: **“Hello, world”**\n\n9.
  [Scene 9: Reviewing the Execution History]  \nFinally, we review the AI's actions
  step by step:\n    - Initialized the Bash session and created the working directory
  \ \n    - Set up the Python environment  \n    - Generated the Flask-based `app.py`
  \ \n    - Launched the web server and validated its operation\n\n10. [Scene 10:
  Conclusion]  \nThis demonstrates how AI, combined with the **PTY-MCP-Server** and
  **Docker**,  \ncan automate real development tasks — **interactively**, **intelligently**,
  and **reproducibly**.\n\n\n### Demo: Docker Execution and Host SSH Access\n![Demo
  Docker](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_docker.gif)\n\n1.
  MCP Configuration with Docke  \nThis is the mcp.json file. It defines the MCP server
  startup configuration. In this case, the pty-mcp-server will be launched using a
  shell script: run.sh. This script uses Podman to start the container.\n2. Starting
  the MCP Server  \nHere is the run.sh script. It launches the Docker container using
  podman run, with the correct volume mount, hostname, and image tag. Once executed,
  the MCP server starts inside the container.\n3. Tool List  \nNext, the list of tools
  exposed to the client is defined in tools-list.json.\nIt includes three tools: pty-message,
  pty-ssh, a shell script named hostname.sh\n4. Tool Script Directory  \nIn config.yaml,
  the path to the script directory is defined.\nThis is where tool scripts like hostname.sh
  should be placed\n5. Hostname Script  \nThe hostname.sh script simply runs the hostname
  command.\nIt is executed as a tool within the container.\n6. Executing hostname
  from Chat  \nNow, let’s run the hostname tool in the chat.\nThis shows the name
  of the current host, which is the container.  \nAs expected, the output is: pms-docker-container\nThis
  confirms that the command is executed inside the Docker container.\n7. Using pty-ssh
  to Access the Host  \nNext, we use pty-ssh to establish a pty session with the host
  OS.\nSSH connection is attempted using host.docker.internal, which resolves to the
  Docker host.  \nAfter confirming the host identity and entering the password, the
  login succeeds.\n8. Confirming Host Environment  \nNow that we are connected to
  the host, we run: cat /etc/redhat-release  \nThis confirms that we are now in the
  host OS, which is CentOS 9.  \nIn contrast, the Docker container is running AlmaLinux
  9.\n\n\n\n### Demo: Interactive Bash via PTY\n![Demo bash](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_bash.gif)\n1.
  Configure bash-mcp-server in mcp.json  \nIn this file, register bash-mcp-server
  as an MCP server.  \nSpecify the command as pty-mcp-server and pass the configuration
  file config.yaml as an argument.\n2. Settings in config.yaml  \nThe config.yaml
  file defines the log directory, the directory for tools, and prompt detection patterns.
  \ \nThese settings establish the environment for the AI to interact with bash through
  the PTY.\n3. Place tools-list.json in the toolsDir  \nYou need to place tools-list.json
  in the directory specified by toolsDir.  \nThis file declares the tools available
  to the AI, including pty-bash and pty-message.  \n4. AI Connects to Bash and Selects
  Commands Autonomously  \nThe AI connects to bash through the pseudo terminal and
  \ndecides which commands to execute based on the context.  \n5. Confirming the Command
  Execution Results  \nThe output of the getenforce command shows whether SELinux
  is in Enforcing mode.  \nThis result appears on the terminal or in logs, allowing
  the user to verify the system status.\n\n\n### Demo: Shell Script Execution\n![Demo
  shellscript](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_script.gif)\n\n1.
  mcp.json Configuration  \nStarts the pty-mcp-server in stdio mode, passing config.yaml
  as an argument.\n2. Overview of config.yaml  \nSpecifies log directory, tools directory,
  and prompt strings.  \nThe tools-list.json in toolsDir defines which tools are exposed.\n3.
  Role of tools-list.json  \nLists available script tools, with only the script_add
  tool registered here.\n4. Role and Naming Convention of the tools Folder  \nStores
  executable shell scripts called via the mcp server.  \nThe tool names in tools-list.json
  match the shell script filenames in this folder.\n5. Execution from VSCode GitHub
  Copilot  \nRuns script_add.sh with the command `#script_add 2 3`, executing the
  addition.\n6. Confirming the Result  \nReturns \"5\", indicating the operation was
  successful.\n\n\n### Demo: Haskell Debugging with `cabal repl`\n![Demo haskell cabal
  repl](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/demo_cabal.gif)
  \ \nRef : [haskell cabal debug prompt](https://github.com/phoityne/pms-missions/blob/main/0007_cabal_debugging/pty-mcp-server/prompts/haskell-cabal-debug-prompt.md)\n\n1.
  Target Code Overview  \nA function in MyLib.hs is selected to inspect its runtime
  state using cabal repl and an AI-driven debug interface.\n2. MCP Server Initialization
  \ \nThe MCP server is launched to allow structured interaction between the AI and
  the debugging commands.\n3. Debugger Prompt and Environment Setup  \nThe AI receives
  a prompt, starts cabal repl, and loads the module to prepare for runtime inspection.\n4.
  Debugging Execution Begins  \nThe target function is executed and paused at a predefined
  point for runtime observation.\n5. State Inspection and Output  \nRuntime values
  and control flow are displayed to help verify logic and observe internal behavior.\n6.
  Summary  \nIntegration with pty-msp-server enables automated runtime inspection
  for Haskell applications.\n\n---\n\n## Architecture Guide (Software Architecture
  and Technical Details)\n\n### Architectural Strategy\n\nThe architecture of the
  `pty-mcp-server` project is designed with medium-to-large scale systems in mind.
  Emphasis is placed on **modularity**, **maintainability**, and **scalability**,
  especially in environments involving multiple teams or organizations.\n\nTo achieve
  these goals, the system is structured as a collection of well-separated packages,
  each responsible for a specific concern or domain. This package-oriented design
  provides several strategic benefits.\n\nThe overall package structure adheres to
  the principles of **Onion Architecture**, reflecting a layered design that places
  the domain model at the core. Furthermore, the **internal module structure within
  each package** is also guided by a layered approach, maintaining clear separation
  between pure data definitions, domain services, and infrastructure concerns.\n\n###
  Role of `pty-mcp-server` as a Dependency Injector\n\nIn addition to managing REPL
  communication, `pty-mcp-server` is **not merely an executable module**, but also
  acts as a **dependency injector** for the entire system.\n\n- It is capable of **referencing
  all relevant PMS packages**, including those that it depends on.\n- This allows
  it to **construct and wire together application components** across multiple packages
  and modules in a unified manner.\n- By centralizing this dependency resolution,
  `pty-mcp-server` provides a single point of control over **cross-cutting dependencies**,
  improving visibility and control over the system architecture.\n\nAs a result, inter-package
  and inter-module dependencies can be **centrally coordinated and managed**, which
  promotes better encapsulation, reusability, and testability throughout the system.\n\n###
  Dependencies\n\nThis package depends on the following packages:  \n- [`pms-ui-request`](https://github.com/phoityne/pms-ui-request)\n-
  [`pms-ui-response`](https://github.com/phoityne/pms-ui-response)\n- [`pms-ui-notification`](https://github.com/phoityne/pms-ui-notification)\n-
  [`pms-infrastructure`](https://github.com/phoityne/pms-infrastructure)\n- [`pms-infra-cmdrun`](https://github.com/phoityne/pms-infra-cmdrun)\n-
  [`pms-infra-procspawn`](https://github.com/phoityne/pms-infra-procspanw)\n- [`pms-infra-serial`](https://github.com/phoityne/pms-infra-serial)\n-
  [`pms-infra-socket`](https://github.com/phoityne/pms-infra-socket)\n- [`pms-infra-watch`](https://github.com/phoityne/pms-infra-watch)\n-
  [`pms-application-service`](https://github.com/phoityne/pms-application-service)\n-
  [`pms-domain-service`](https://github.com/phoityne/pms-domain-service)\n- [`pms-domain-model`](https://github.com/phoityne/pms-domain-model)\n\n###
  Rationale for Package Separation\n\n- **Clear Interface Definition**  \n  Each package
  exposes only its minimal, well-defined public API. This enforces clean module boundaries
  and reduces unintended dependencies between components.\n\n- **Team and Vendor Ownership**
  \ \n  In larger projects, different teams or external vendors can own specific packages.
  Clear separation ensures well-defined responsibilities and supports collaborative
  development across organizational boundaries.\n\n- **Repository and Release Independence**
  \ \n  Packages can be split into separate repositories and versioned independently.
  This allows for modular development and flexible release workflows, reducing build
  times and simplifying integration.\n\n- **Improved Maintainability and Extensibility**
  \ \n  By isolating concerns, the impact of code changes is limited to relevant modules.
  This minimizes regressions and facilitates safe, incremental improvements over time.\n\n###
  Intended Use Cases\n\n- Medium-to-large scale enterprise systems involving multiple
  developers or teams  \n- Modular systems with independent development and release
  cycles for components  \n- Projects that require long-term maintainability, extensibility,
  and isolation of concerns\n\nThis architecture follows a layered and modular approach.
  Domain models, domain services, application logic, and infrastructure concerns are
  each encapsulated in their own package, enabling clean composition while preserving
  separation of responsibilities.\n\n\n### Deployment Diagram\n![Deployment Diagram](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/01_deploy_structure.png)\n\n###
  Package Structure\n![Package Structure](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/02_package_structure.png)\n\n###
  Thread Structure\n![Thread Structure](https://raw.githubusercontent.com/phoityne/pty-mcp-server/main/docs/03_thread_structure.png)\n\n\n----\n"
description-type: markdown
hash: 5f9d6b86c3f6ec433130f5073c71c7b6c83e09e6d789f3563d4d148b5f094171
homepage: https://github.com/phoityne/pty-mcp-server
latest: 0.1.5.0
license-name: Apache-2.0
maintainer: phoityne.hs@gmail.com
synopsis: pty-mcp-server
test-bench-deps: {}
