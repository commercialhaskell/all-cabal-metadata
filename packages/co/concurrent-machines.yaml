homepage: ''
changelog-type: markdown
hash: b3066bd3bf1eaa4b0fc84e44ba32dc3458ac5af1cde20fe0ec274be1e0b0a5de
test-bench-deps:
  base: ! '>=4.8 && <5'
  time: -any
  tasty-hunit: -any
  concurrent-machines: -any
  transformers: -any
  tasty: -any
  machines: -any
maintainer: acowley@gmail.com
synopsis: Concurrent networked stream transducers
changelog: ! '# 0.3.0


  - Removed `buffer` and `rolling` functions


  These functions did not properly use the buffers intended to mediate

  the connection to a downstream consumer. This functionality is

  provided by `bufferConnect` and `rollingConnect`. Thanks to Ben

  Sinclair for identifying the problem.


  The issue is that these are necessarily connectors between machines,

  and can not be treated as modifiers of a single machine in isolation.


  # 0.2.3


  - GHC-8.0.1 compatibility

  - Dropped support for GHC-7.8


  # 0.2.0


  - Fix fanout behavior (Ben SInclair)

  - Make ExampleFanout a benchmark that cabal can run

'
basic-deps:
  base: ! '>=4.8 && <5'
  time: ! '>=1.4 && <1.10'
  monad-control: ! '>=1.0 && <1.1'
  async: ! '>=2.0.1 && <2.2'
  semigroups: ! '>=0.8 && <0.19'
  containers: ! '>=0.5 && <0.6'
  lifted-async: ! '>=0.1 && <0.10'
  transformers-base: ! '>=0.4 && <0.6'
  transformers: ! '>=0.4 && <0.6'
  machines: ! '>=0.5 && <0.7'
all-versions:
- '0.1.0.0'
- '0.1.0.1'
- '0.1.0.2'
- '0.2.0'
- '0.2.1'
- '0.2.3'
- '0.2.3.1'
- '0.2.3.2'
- '0.2.3.3'
- '0.3.0'
- '0.3.1'
- '0.3.1.1'
author: Anthony Cowley
latest: '0.3.1.1'
description-type: markdown
description: ! "A simple example of a pipelined computation whose throughput is improved
  by concurrently running distinct processing stages is given in [`examples/Pipeline.hs`](http://github.com/acowley/concurrent-machines/blob/master/examples/Pipeline.hs).\n\n```haskell\nimport
  Data.Time.Clock (getCurrentTime, diffUTCTime)\nimport Control.Concurrent (threadDelay)\nimport
  Control.Monad.IO.Class (MonadIO, liftIO)\nimport Data.Machine.Concurrent\n```\n\nSuppose
  we have a worker that performs a computation on its input before producing output.
  This operation may take some time due to, say, network IO or just CPU load. Here
  we simulate an operation that takes some time with `threadDelay`.\n\n```haskell\nworker
  :: String -> Double -> ProcessT IO () ()\nworker name dt = repeatedly $ do _ <-
  await\n                                 liftIO $ do\n                                   putStrLn
  $ name ++ \" working on its input\"\n                                   threadDelay
  dt'\n                                 yield ()\n  where dt' = floor $ dt * 1000000\n```\n\nWe
  will use a little helper to time two variations of our test program.\n\n```haskell\ntimed
  :: MonadIO m => m a -> m (a, Double)\ntimed m = do t1 <- liftIO getCurrentTime\n
  \            r <- m\n             t2 <- liftIO getCurrentTime\n             return
  (r, realToFrac $ t2 `diffUTCTime` t1)\n```\n\nNow we will run a three-stage pipeline
  where each stage takes one second to process its input before yielding some output.
  A sequential execution strategy will thus take three seconds to pass an input through
  this pipeline. At the top-level, we will request three outputs, each of which will
  take three seconds to produce, resulting in a total execution time of approximately
  nine seconds.\n\n```haskell\nmain :: IO ()\nmain = do (r,dt) <- timed . runT . supply
  (repeat ()) $\n            worker \"A\" 1 ~> worker \"B\" 1 ~> worker \"C\" 1 ~>
  taking 3\n          putStrLn $ \"Sequentially produced \"++show r\n          putStrLn
  $ \"Sequential processing took \"++show dt++\"s\"\n```\n\nIf we instead run the
  same arrangement as a pipelined computation, we allow the independent stages to
  run concurrently, much like the stages in a pipelined CPU.\n\n```haskell\n          (r',dt')
  <- timed . runT . supply (repeat ()) $\n            worker \"A\" 1 >~> worker \"B\"
  1 >~> worker \"C\" 1 >~> taking 3\n          putStrLn $ \"Pipeline produced \"++show
  r'\n          putStrLn $ \"Pipeline processing took \"++show dt'++\"s\"\n```\n\nWith
  this arrangement, the first output we request takes three seconds to produce as
  we must wait for an input to pass through the entire length of the pipeline. However,
  successive outputs are following that first output through the pipeline so that
  we will produce more output at one second intervals. Therefore it takes is `3 +
  2 = 5` seconds to produce three outputs: three seconds for the first output, and
  one second for each of the following two.\n\n[![Build Status](https://travis-ci.org/acowley/concurrent-machines.png)](https://travis-ci.org/acowley/concurrent-machines)\n"
license-name: BSD3
