all-versions:
- 0.1.0.0
author: Ben Gamari
basic-deps:
  aeson: '>=0.11 && <0.12'
  ansi-wl-pprint: '>=0.6 && <0.7'
  async: '>=2.0 && <2.2'
  base: '>=4.5 && <4.10'
  binary: '>=0.7 && <0.9'
  bytestring: '>=0.10 && <0.11'
  containers: '>=0.5 && <0.6'
  distributed-process: '>=0.6 && <0.7'
  errors: '>=2.0 && <2.2'
  exceptions: '>=0.8 && <0.9'
  friendly-time: '>=0.4 && <0.5'
  ghc-prim: '>=0'
  heaps: '>=0.3 && <0.4'
  network: '>=2.4 && <2.7'
  network-transport-tcp: '>=0.4'
  optparse-applicative: '>=0.10 && <0.13'
  parsers: '>=0.12 && <0.13'
  pipes: '>=4.0 && <4.3'
  pipes-bytestring: '>=2.0 && <2.2'
  pipes-concurrency: '>=0'
  pipes-safe: '>=2.2 && <2.3'
  process: '>=1.1 && <1.5'
  stm: '>=2.4 && <2.5'
  time: '>=1.6 && <1.7'
  transformers: '>=0.3 && <0.6'
  trifecta: '>=1.5 && <1.7'
changelog: ''
changelog-type: ''
description: "# tpar â€” simple parallel job scheduling\n\n`tpar` is a simple tool for
  concurrent job scheduling. Say you have a\ndirectory full of files which need processing,\n\n```bash\n$
  ls\nfile1    file2     file3     file4    file5\n...\n```\n\nUsually one could use
  a `bash` for loop,\n\n```bash\n$ for f in *; do process $f; done;\n```\n\nBut if
  `process` is a long-running task and you have many cores at\nyour disposal, it would
  be nice to speed things up a bit,\n\n```bash\n$ tpar server -N8\n$ for f in *; do
  tpar enqueue -- process $f; done;\n```\n\nIf you have multiple machines with the
  data mounted over, say, NFS, they can\nalso help with churning through the queue,\n\n```bash\n$
  for m in worker1 worker2 worker3; do\n>   ssh $m -- tpar worker -H`hostname`;\n>
  done\n```\n\n## Commands\n\n`tpar` has several subcommands,\n\n  * `tpar server`
  starts a local queue server.\n  * `tpar worker` starts a worker associated with\n
  \   the given queue\n  * `tpar enqueue -- $cmd` enqueues a job in the given queue\n
  \ * `tpar status` allows you to query for the status of the queue. You can also
  provide a job match expression \n  * `tpar kill` kills a running task (specified
  by a job match expression)\n  * `tpar watch` is analogous `tail -f`, watching the
  output of a set of running tasks\n  * `tpar dump` dumps a JSON representation of
  the queue state.\n\nNearly all of these commands will require that the `-H` option
  be provided\nspecifying the canonical hostname of the queue server (the machine
  running\n`tpar server`).\n\n\n## Job match expressions\n\nSeveral `tpar` commands
  accept a *job match expression*, which specifies the\nsubset of jobs on which the
  command should act. For instance (note the quotes to\nensure that `bash` doesn't
  interpret our symbols),\n\n```\n$ tpar status '*'    # This is equivalent to `tpar
  status` run without an argument\n$ tpar status id=2\n$ tpar status state=running\n$
  tpar status 'name=\"my-job\" or name=\"my-other-job\"'\n```\n\nThese expressions
  consist of the primitive matches,\n * `name=\"STRING\"`, which matches on the job
  name provided in the `--name` of\n   `tpar enqueue`.\n * `id=`, which matches on
  the job ID\n * `state=`, which matches on the current state of the job (`queued`,
  `running`,\n   `finished`, `failed`, `killed`, or `code=N`)\n * `*`, which matches
  all jobs\n \nThese matches can be connected with the `and` and `or` operators, and
  inverted\nwith `!`.\n"
description-type: text
hash: c1a9b67993ae1597d00e3f873b2b4c1cab111d233ac6b30bc6af146e6d0a9fc0
homepage: http://github.com/bgamari/tpar/
latest: 0.1.0.0
license-name: BSD-3-Clause
maintainer: bgamari@gmail.com
synopsis: simple, parallel job scheduling
test-bench-deps:
  QuickCheck: '>=0'
  async: '>=0'
  base: '>=4.5 && <4.10'
  binary: '>=0'
  bytestring: '>=0'
  containers: '>=0'
  distributed-process: '>=0'
  errors: '>=0'
  exceptions: '>=0'
  ghc-prim: '>=0'
  heaps: '>=0'
  network: '>=0'
  network-transport-inmemory: '>=0'
  network-transport-tcp: '>=0'
  optparse-applicative: '>=0'
  pipes: '>=0'
  pipes-bytestring: '>=0'
  pipes-concurrency: '>=0'
  pipes-safe: '>=0'
  process: '>=0'
  stm: '>=0'
  transformers: '>=0'
  trifecta: '>=0'
